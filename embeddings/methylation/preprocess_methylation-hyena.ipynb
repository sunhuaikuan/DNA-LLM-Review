{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94159a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/48896213/ipykernel_826563/3242630166.py:8: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/home/sunhuaikuan/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using PyTorch 2.0.1\n",
    "# using PyTorch 2.0.1\n",
    "# using PyTorch 2.0.1\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from transformers import AutoModel #, AutoModelForMaskedLM\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import pickle\n",
    "# import re\n",
    "import os\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "%run hyena_utility.py\n",
    "\n",
    "%run preprocess_utility.py\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0495a5df-3a69-4196-b12d-ab504d00f4d4",
   "metadata": {},
   "source": [
    "### Load Human Chrom Sequences from .fa File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5760522-3c27-4a0c-9fe0-209a212edc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_file = \"/blue/xiaofan/sunhuaikuan/gpn/examples/msa/genome.hg38rg.fa\"\n",
    "chrom_sequences = read_fasta(fasta_file)\n",
    "\n",
    "def get_subsequence(chrom_name, start_pos, length):\n",
    "    \n",
    "    # print(chrom_name, start_pos, length)\n",
    "    if chrom_name in chrom_sequences:\n",
    "        sequence = chrom_sequences[chrom_name]\n",
    "        subsequence = sequence[start_pos:start_pos + length]\n",
    "        return subsequence\n",
    "    else:\n",
    "        raise ValueError(f\"Chromosome '{chrom_name}' not found in the FASTA file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00928314-c642-46b7-841a-401f18320873",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def Cur_Inference(model, tokenizer, max_length, device, sequence):\n",
    "def Cur_Inference(model, sequence):  # model, tokenizer, max_length, device, \n",
    "\n",
    "    '''\n",
    "    this selects which backbone to use, and grabs weights/ config from HF\n",
    "    4 options:\n",
    "      'hyenadna-tiny-1k-seqlen'   # fine-tune on colab ok\n",
    "      'hyenadna-small-32k-seqlen'\n",
    "      'hyenadna-medium-160k-seqlen'  # inference only on colab\n",
    "      'hyenadna-medium-450k-seqlen'  # inference only on colab\n",
    "      'hyenadna-large-1m-seqlen'  # inference only on colab\n",
    "    '''\n",
    "\n",
    "    # you only need to select which model to use here, we'll do the rest!\n",
    "    # pretrained_model_name = 'hyenadna-small-32k-seqlen'\n",
    "\n",
    "    # max_lengths = {\n",
    "    #     'hyenadna-tiny-1k-seqlen': 1024,\n",
    "    #     'hyenadna-small-32k-seqlen': 32768,\n",
    "    #     'hyenadna-medium-160k-seqlen': 160000,\n",
    "    #     'hyenadna-medium-450k-seqlen': 450000,  # T4 up to here\n",
    "    #     'hyenadna-large-1m-seqlen': 1_000_000,  # only A100 (paid tier)\n",
    "    # }\n",
    "\n",
    "\n",
    "    #### Single embedding example ####\n",
    "\n",
    "    # create a sample 450k long, prepare\n",
    "    # sequence = 'ACTG' * int(max_length/4)\n",
    "    tok_seq = tokenizer(sequence)\n",
    "    tok_seq = tok_seq[\"input_ids\"]  # grab ids\n",
    "\n",
    "    # place on device, convert to tensor\n",
    "    tok_seq = torch.LongTensor(tok_seq).unsqueeze(0)  # unsqueeze for batch dim\n",
    "    tok_seq = tok_seq.to(device)\n",
    "\n",
    "    # prep model and forward\n",
    "    # model.to(device)\n",
    "    # model.eval()\n",
    "    with torch.inference_mode():\n",
    "        embeddings = model(tok_seq)\n",
    "\n",
    "    # cls_embedding = embeddings.last_hidden_state[:, 0, :]\n",
    "    # cls_embedding = embeddings[:, 0, :]\n",
    "    \n",
    "    mean_embeddings = embeddings.mean(dim=1) # Mean across the sequence length dimension\n",
    "    mean_embeddings = mean_embeddings.squeeze(0)  # This will change the shape to [256]\n",
    "\n",
    "    \n",
    "    # print(embeddings.shape)  # embeddings here!\n",
    "    # return cls_embedding\n",
    "    return mean_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89af52c7-67c6-4427-b9d4-6f2fe12a34ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Subsequence2Embedding(model, tokenizer, max_length, device, subsequence):\n",
    "def Subsequence2Embedding(subsequence):\n",
    "    # embeddings = My_Inference(model, tokenizer, max_length, device, subsequence)\n",
    "    embeddings = Cur_Inference(model, subsequence)\n",
    "    # print(embeddings.shape)\n",
    "    # print (embeddings)\n",
    "    # return embeddings[0,int(max_length/2),:]\n",
    "    return embeddings  # embeddings[0,0,:]\n",
    "\n",
    "# max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bc056b3-d504-495e-852e-2851ad0d2bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4c1ea2f-6b84-4308-a4d0-4e018b1d446f",
   "metadata": {},
   "source": [
    "### Main Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d899db1-344c-4812-8392-248e309c12df",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Git LFS initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'hyenadna-medium-160k-seqlen'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights ok!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HyenaDNAModel(\n",
       "  (backbone): LMBackbone(\n",
       "    (embeddings): GPT2Embeddings(\n",
       "      (word_embeddings): Embedding(16, 256)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): Block(\n",
       "        (mixer): HyenaOperator(\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (in_proj): Linear(in_features=256, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (short_filter): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(2,), groups=768)\n",
       "          (filter_fn): HyenaFilter(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb): PositionalEmbedding()\n",
       "            (implicit_filter): Sequential(\n",
       "              (0): Linear(in_features=5, out_features=64, bias=True)\n",
       "              (1): Sin()\n",
       "              (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (3): Sin()\n",
       "              (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (5): Sin()\n",
       "              (6): Linear(in_features=64, out_features=256, bias=False)\n",
       "            )\n",
       "            (modulation): ExponentialModulation()\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1-7): 7 x Block(\n",
       "        (mixer): HyenaOperator(\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (in_proj): Linear(in_features=256, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (short_filter): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(2,), groups=768)\n",
       "          (filter_fn): HyenaFilter(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb): PositionalEmbedding()\n",
       "            (implicit_filter): Sequential(\n",
       "              (0): Linear(in_features=5, out_features=64, bias=True)\n",
       "              (1): Sin()\n",
       "              (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (3): Sin()\n",
       "              (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (5): Sin()\n",
       "              (6): Linear(in_features=64, out_features=256, bias=False)\n",
       "            )\n",
       "            (modulation): ExponentialModulation()\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (drop_f): Dropout(p=0.0, inplace=False)\n",
       "    (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = 'hyenadna-small-32k-seqlen'\n",
    "pretrained_model_name = 'hyenadna-medium-160k-seqlen'\n",
    "# pretrained_model_name = 'hyenadna-medium-450k-seqlen'\n",
    "# pretrained_model_name = 'hyenadna-large-1m-seqlen'\n",
    "model, tokenizer, max_length =  get_model_tokenizer_maxlen(pretrained_model_name)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a69720a-d062-4659-88ba-60f2ba6a5e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datafile='clinvar_20240805.noncoding'\n",
    "# datafile='clinvar_20240805.missense_matched'\n",
    "datafile='methylation'\n",
    "# datafile='GSM6637962_CpG_coverage20_GRCh38.bed.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "029d8b7c-fcdb-4390-aac3-de63631067fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHROM</th>\n",
       "      <th>START</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>788407</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>788472</td>\n",
       "      <td>128</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>788825</td>\n",
       "      <td>128</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>788844</td>\n",
       "      <td>128</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>788859</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54789</th>\n",
       "      <td>Y</td>\n",
       "      <td>56870903</td>\n",
       "      <td>128</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54790</th>\n",
       "      <td>Y</td>\n",
       "      <td>56870983</td>\n",
       "      <td>128</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54791</th>\n",
       "      <td>Y</td>\n",
       "      <td>56871109</td>\n",
       "      <td>128</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54792</th>\n",
       "      <td>Y</td>\n",
       "      <td>56871502</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54793</th>\n",
       "      <td>Y</td>\n",
       "      <td>56873899</td>\n",
       "      <td>128</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47953 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CHROM     START  SIZE    y\n",
       "0         1    788407   128  100\n",
       "1         1    788472   128   80\n",
       "2         1    788825   128   95\n",
       "3         1    788844   128   90\n",
       "4         1    788859   128  100\n",
       "...     ...       ...   ...  ...\n",
       "54789     Y  56870903   128   65\n",
       "54790     Y  56870983   128   17\n",
       "54791     Y  56871109   128   34\n",
       "54792     Y  56871502   128    0\n",
       "54793     Y  56873899   128   36\n",
       "\n",
       "[47953 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filename = '/home/sunhuaikuan/ondemand/blue_papers/DNA_LLM_REVIEW/datasets/task05-methylation/GSM6637962_CpG_coverage20_GRCh38.bed.gz' \n",
    "df = preprocess_datafile(data_filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "500232bd-1808-42fd-aa62-26f378ec9dc1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# comp = {'A':1, 'C':2, 'G':3, 'T':4}\n",
    "\n",
    "\n",
    "# max_length= 128 # 186\n",
    "\n",
    "# csv_Filename =datafile + '_with_embeddings.csv'\n",
    "# if os.path.exists(csv_Filename):\n",
    "#     os.remove(csv_Filename)\n",
    "\n",
    "\n",
    "# df=pd.read_csv(datafile+'.txt', delimiter='\\t')\n",
    "# # df=pd.read_csv('clinvar_20240805.missense_matched.txt', delimiter='\\t')\n",
    "\n",
    "# columns_to_keep=['CHROM','POS','ID','REF','ALT','Pathogenicity']\n",
    "# df = df[columns_to_keep]\n",
    "\n",
    "# # Merge CHROM=9 and '9' etc\n",
    "\n",
    "# for i in range(1,23):\n",
    "#     df.loc[df['CHROM']==i,'CHROM']=str(i)\n",
    "\n",
    "\n",
    "# df['START']= df['POS']- max_length //2 -1\n",
    "# df['END']  = df['START'] + max_length\n",
    "# df['SIZE'] = max_length\n",
    "\n",
    "# df=df[~df['CHROM'].isna()]\n",
    "\n",
    "# Pathogenicity_dict={'B':0,'P':1}\n",
    "# df['y'] = df['Pathogenicity'].map(Pathogenicity_dict)\n",
    "# # df['CHROM'].value_counts()\n",
    "# df.drop(['POS','ID','Pathogenicity','END'], axis=1, inplace=True)\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a73b5a5-247c-4cc8-8dc2-bc2d44e7f9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index = 5000 completed\n",
      "index = 10000 completed\n",
      "index = 15000 completed\n",
      "The character 'N' is present in the string.\n",
      "The character 'N' is present in the string.\n",
      "index = 20000 completed\n",
      "The character 'N' is present in the string.\n",
      "The character 'N' is present in the string.\n",
      "The character 'N' is present in the string.\n",
      "The character 'N' is present in the string.\n",
      "index = 25000 completed\n",
      "The character 'N' is present in the string.\n",
      "The character 'N' is present in the string.\n",
      "index = 30000 completed\n",
      "The character 'N' is present in the string.\n",
      "index = 35000 completed\n",
      "index = 40000 completed\n",
      "The character 'N' is present in the string.\n",
      "The character 'N' is present in the string.\n",
      "index = 45000 completed\n",
      "Create File: methylation_hyena_embedding.csv\n",
      "CPU times: user 5min 58s, sys: 163 ms, total: 5min 58s\n",
      "Wall time: 6min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "csv_Filename =datafile + '_hyena_embedding.csv'\n",
    "\n",
    "if os.path.exists(csv_Filename):\n",
    "    os.remove(csv_Filename)\n",
    "\n",
    "\n",
    "\n",
    "# column_names = [f'{i}' for i in range(1, df.shape[1])]\n",
    "# column_names.extend([ 'y'])\n",
    "# df_head = pd.DataFrame(columns=column_names)\n",
    "# df_head.to_csv(csv_Filename)\n",
    "\n",
    "\n",
    "rows=[]\n",
    "for index, row in df.iterrows():      \n",
    "    chrom=row['CHROM']\n",
    "    # pos=row['POS']\n",
    "    # pos_start=row['POS']-round(max_length / 2)\n",
    "    pos_start=row['START']\n",
    "\n",
    "    if pos_start<=1:\n",
    "        pos_start=1\n",
    "    # ref=row['REF']\n",
    "    # alt=row['ALT']        \n",
    "    y=row['y']\n",
    "    length = row['SIZE'] # max_length\n",
    "    \n",
    "    subsequence = get_subsequence(chrom, pos_start, length)\n",
    "    if 'N' in subsequence:\n",
    "        print(\"The character 'N' is present in the string.\")\n",
    "        \n",
    "    embedding = Subsequence2Embedding(subsequence)\n",
    "    # print(embedding.shape)\n",
    "\n",
    "    # feature=np.array(embedding_df.iloc[64])\n",
    "    rows.append(np.append(embedding.cpu().numpy(),  [y])) # chrom,  length,  comp[ref],comp[alt],\n",
    "\n",
    "    if index > 0 and (index % 5000) == 0:\n",
    "        append_rows_to_csv(csv_Filename, rows)\n",
    "        rows=[]\n",
    "        print (f\"index = {index} completed\")\n",
    "        \n",
    "append_rows_to_csv(csv_Filename, rows)\n",
    "\n",
    "print(f\"Create File: \"+csv_Filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93f1c14-0ef8-4efa-84df-c94596ac0b59",
   "metadata": {},
   "source": [
    "### Load CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90d6b579-726c-438b-9c2b-1c91b2e81b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.162548</td>\n",
       "      <td>-0.813792</td>\n",
       "      <td>-0.502185</td>\n",
       "      <td>-0.825777</td>\n",
       "      <td>-0.877710</td>\n",
       "      <td>-0.901205</td>\n",
       "      <td>1.084889</td>\n",
       "      <td>-0.752337</td>\n",
       "      <td>-0.211693</td>\n",
       "      <td>0.480058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536883</td>\n",
       "      <td>0.422926</td>\n",
       "      <td>-1.036571</td>\n",
       "      <td>-1.505365</td>\n",
       "      <td>-1.542530</td>\n",
       "      <td>1.273687</td>\n",
       "      <td>0.541963</td>\n",
       "      <td>0.330082</td>\n",
       "      <td>-0.782260</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.545844</td>\n",
       "      <td>-0.499106</td>\n",
       "      <td>-0.211811</td>\n",
       "      <td>-0.605006</td>\n",
       "      <td>-0.363712</td>\n",
       "      <td>-0.115525</td>\n",
       "      <td>0.974813</td>\n",
       "      <td>-0.903288</td>\n",
       "      <td>-0.637590</td>\n",
       "      <td>0.212635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.576334</td>\n",
       "      <td>0.362970</td>\n",
       "      <td>-0.771966</td>\n",
       "      <td>-1.256579</td>\n",
       "      <td>-1.035106</td>\n",
       "      <td>1.435116</td>\n",
       "      <td>0.312089</td>\n",
       "      <td>0.661820</td>\n",
       "      <td>-0.845981</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.607656</td>\n",
       "      <td>-0.510390</td>\n",
       "      <td>-0.237946</td>\n",
       "      <td>-0.559285</td>\n",
       "      <td>-0.386759</td>\n",
       "      <td>-0.082885</td>\n",
       "      <td>0.962740</td>\n",
       "      <td>-0.900656</td>\n",
       "      <td>-0.646205</td>\n",
       "      <td>0.154209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558357</td>\n",
       "      <td>0.384656</td>\n",
       "      <td>-0.830481</td>\n",
       "      <td>-1.283214</td>\n",
       "      <td>-1.037074</td>\n",
       "      <td>1.399000</td>\n",
       "      <td>0.265083</td>\n",
       "      <td>0.666149</td>\n",
       "      <td>-0.886538</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.522967</td>\n",
       "      <td>-0.544051</td>\n",
       "      <td>-0.275782</td>\n",
       "      <td>-0.638263</td>\n",
       "      <td>-0.471732</td>\n",
       "      <td>-0.228838</td>\n",
       "      <td>1.009440</td>\n",
       "      <td>-0.955511</td>\n",
       "      <td>-0.494366</td>\n",
       "      <td>0.158926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464206</td>\n",
       "      <td>0.379089</td>\n",
       "      <td>-0.885517</td>\n",
       "      <td>-1.393619</td>\n",
       "      <td>-1.167201</td>\n",
       "      <td>1.349000</td>\n",
       "      <td>0.287169</td>\n",
       "      <td>0.557183</td>\n",
       "      <td>-0.955191</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.547458</td>\n",
       "      <td>-0.516419</td>\n",
       "      <td>-0.256440</td>\n",
       "      <td>-0.622132</td>\n",
       "      <td>-0.409509</td>\n",
       "      <td>-0.208485</td>\n",
       "      <td>0.989845</td>\n",
       "      <td>-0.941072</td>\n",
       "      <td>-0.492761</td>\n",
       "      <td>0.190209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468198</td>\n",
       "      <td>0.383017</td>\n",
       "      <td>-0.850792</td>\n",
       "      <td>-1.364307</td>\n",
       "      <td>-1.135328</td>\n",
       "      <td>1.340600</td>\n",
       "      <td>0.339875</td>\n",
       "      <td>0.563152</td>\n",
       "      <td>-0.898098</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47947</th>\n",
       "      <td>-0.204415</td>\n",
       "      <td>-0.610424</td>\n",
       "      <td>-0.525940</td>\n",
       "      <td>-0.834108</td>\n",
       "      <td>-1.071689</td>\n",
       "      <td>-0.866407</td>\n",
       "      <td>1.295794</td>\n",
       "      <td>-0.787243</td>\n",
       "      <td>-0.093626</td>\n",
       "      <td>0.270392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469020</td>\n",
       "      <td>0.538909</td>\n",
       "      <td>-1.000904</td>\n",
       "      <td>-1.556431</td>\n",
       "      <td>-1.477009</td>\n",
       "      <td>1.182108</td>\n",
       "      <td>0.483010</td>\n",
       "      <td>0.468306</td>\n",
       "      <td>-1.007607</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47948</th>\n",
       "      <td>-0.191999</td>\n",
       "      <td>-0.571596</td>\n",
       "      <td>-0.412285</td>\n",
       "      <td>-0.903216</td>\n",
       "      <td>-1.231649</td>\n",
       "      <td>-0.926968</td>\n",
       "      <td>1.293870</td>\n",
       "      <td>-0.727409</td>\n",
       "      <td>-0.031014</td>\n",
       "      <td>0.126409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491232</td>\n",
       "      <td>0.636665</td>\n",
       "      <td>-0.939041</td>\n",
       "      <td>-1.525331</td>\n",
       "      <td>-1.463316</td>\n",
       "      <td>1.163905</td>\n",
       "      <td>0.463123</td>\n",
       "      <td>0.561148</td>\n",
       "      <td>-1.014437</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47949</th>\n",
       "      <td>-0.007314</td>\n",
       "      <td>-0.681754</td>\n",
       "      <td>-0.413436</td>\n",
       "      <td>-0.843044</td>\n",
       "      <td>-0.748679</td>\n",
       "      <td>-0.847264</td>\n",
       "      <td>1.296018</td>\n",
       "      <td>-0.867100</td>\n",
       "      <td>-0.041741</td>\n",
       "      <td>0.354103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.579400</td>\n",
       "      <td>0.478063</td>\n",
       "      <td>-0.936292</td>\n",
       "      <td>-1.452830</td>\n",
       "      <td>-1.407930</td>\n",
       "      <td>1.272913</td>\n",
       "      <td>0.476933</td>\n",
       "      <td>0.465113</td>\n",
       "      <td>-0.959612</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47950</th>\n",
       "      <td>-0.167239</td>\n",
       "      <td>-0.801911</td>\n",
       "      <td>-0.522504</td>\n",
       "      <td>-0.799539</td>\n",
       "      <td>-0.921501</td>\n",
       "      <td>-0.894758</td>\n",
       "      <td>1.127078</td>\n",
       "      <td>-0.804274</td>\n",
       "      <td>-0.197577</td>\n",
       "      <td>0.462455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476291</td>\n",
       "      <td>0.385570</td>\n",
       "      <td>-1.059132</td>\n",
       "      <td>-1.483167</td>\n",
       "      <td>-1.471666</td>\n",
       "      <td>1.242552</td>\n",
       "      <td>0.524794</td>\n",
       "      <td>0.329107</td>\n",
       "      <td>-0.814684</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47951</th>\n",
       "      <td>-0.158429</td>\n",
       "      <td>-0.788524</td>\n",
       "      <td>-0.495577</td>\n",
       "      <td>-0.875821</td>\n",
       "      <td>-0.859388</td>\n",
       "      <td>-0.913251</td>\n",
       "      <td>1.204481</td>\n",
       "      <td>-0.850310</td>\n",
       "      <td>-0.090559</td>\n",
       "      <td>0.351819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482680</td>\n",
       "      <td>0.479921</td>\n",
       "      <td>-0.964537</td>\n",
       "      <td>-1.542126</td>\n",
       "      <td>-1.528360</td>\n",
       "      <td>1.228688</td>\n",
       "      <td>0.526495</td>\n",
       "      <td>0.438827</td>\n",
       "      <td>-0.950966</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47952 rows × 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1         2         3         4         5         6         7  \\\n",
       "0     -0.162548 -0.813792 -0.502185 -0.825777 -0.877710 -0.901205  1.084889   \n",
       "1      0.545844 -0.499106 -0.211811 -0.605006 -0.363712 -0.115525  0.974813   \n",
       "2      0.607656 -0.510390 -0.237946 -0.559285 -0.386759 -0.082885  0.962740   \n",
       "3      0.522967 -0.544051 -0.275782 -0.638263 -0.471732 -0.228838  1.009440   \n",
       "4      0.547458 -0.516419 -0.256440 -0.622132 -0.409509 -0.208485  0.989845   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "47947 -0.204415 -0.610424 -0.525940 -0.834108 -1.071689 -0.866407  1.295794   \n",
       "47948 -0.191999 -0.571596 -0.412285 -0.903216 -1.231649 -0.926968  1.293870   \n",
       "47949 -0.007314 -0.681754 -0.413436 -0.843044 -0.748679 -0.847264  1.296018   \n",
       "47950 -0.167239 -0.801911 -0.522504 -0.799539 -0.921501 -0.894758  1.127078   \n",
       "47951 -0.158429 -0.788524 -0.495577 -0.875821 -0.859388 -0.913251  1.204481   \n",
       "\n",
       "              8         9        10  ...       248       249       250  \\\n",
       "0     -0.752337 -0.211693  0.480058  ...  0.536883  0.422926 -1.036571   \n",
       "1     -0.903288 -0.637590  0.212635  ...  0.576334  0.362970 -0.771966   \n",
       "2     -0.900656 -0.646205  0.154209  ...  0.558357  0.384656 -0.830481   \n",
       "3     -0.955511 -0.494366  0.158926  ...  0.464206  0.379089 -0.885517   \n",
       "4     -0.941072 -0.492761  0.190209  ...  0.468198  0.383017 -0.850792   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "47947 -0.787243 -0.093626  0.270392  ...  0.469020  0.538909 -1.000904   \n",
       "47948 -0.727409 -0.031014  0.126409  ...  0.491232  0.636665 -0.939041   \n",
       "47949 -0.867100 -0.041741  0.354103  ...  0.579400  0.478063 -0.936292   \n",
       "47950 -0.804274 -0.197577  0.462455  ...  0.476291  0.385570 -1.059132   \n",
       "47951 -0.850310 -0.090559  0.351819  ...  0.482680  0.479921 -0.964537   \n",
       "\n",
       "            251       252       253       254       255       256      y  \n",
       "0     -1.505365 -1.542530  1.273687  0.541963  0.330082 -0.782260   80.0  \n",
       "1     -1.256579 -1.035106  1.435116  0.312089  0.661820 -0.845981   95.0  \n",
       "2     -1.283214 -1.037074  1.399000  0.265083  0.666149 -0.886538   90.0  \n",
       "3     -1.393619 -1.167201  1.349000  0.287169  0.557183 -0.955191  100.0  \n",
       "4     -1.364307 -1.135328  1.340600  0.339875  0.563152 -0.898098   96.0  \n",
       "...         ...       ...       ...       ...       ...       ...    ...  \n",
       "47947 -1.556431 -1.477009  1.182108  0.483010  0.468306 -1.007607   65.0  \n",
       "47948 -1.525331 -1.463316  1.163905  0.463123  0.561148 -1.014437   17.0  \n",
       "47949 -1.452830 -1.407930  1.272913  0.476933  0.465113 -0.959612   34.0  \n",
       "47950 -1.483167 -1.471666  1.242552  0.524794  0.329107 -0.814684    0.0  \n",
       "47951 -1.542126 -1.528360  1.228688  0.526495  0.438827 -0.950966   36.0  \n",
       "\n",
       "[47952 rows x 257 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv_Filename =datafile + '_hyena_embedding.csv'\n",
    "df = load_embedding_file(csv_Filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba02fc7a-4795-4d96-a844-4339a5f59f75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-2.0.1",
   "language": "python",
   "name": "pytorch-2.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
