{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94159a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from transformers import AutoModel #, AutoModelForMaskedLM\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "%run hyena_utility.py\n",
    "%run preprocess_utility.py\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0495a5df-3a69-4196-b12d-ab504d00f4d4",
   "metadata": {},
   "source": [
    "### Load Human Chrom Sequences from .fa File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5760522-3c27-4a0c-9fe0-209a212edc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_file = \"../genome.hg38rg.fa\"\n",
    "chrom_sequences = read_fasta(fasta_file)\n",
    "\n",
    "def get_subsequence(chrom_name, start_pos, length):\n",
    "    \n",
    "    if chrom_name in chrom_sequences:\n",
    "        sequence = chrom_sequences[chrom_name]\n",
    "        subsequence = sequence[start_pos:start_pos + length]\n",
    "        return subsequence\n",
    "    else:\n",
    "        raise ValueError(f\"Chromosome '{chrom_name}' not found in the FASTA file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89af52c7-67c6-4427-b9d4-6f2fe12a34ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Subsequence2Embedding(subsequence):\n",
    "    tok_seq = tokenizer(subsequence)\n",
    "    tok_seq = tok_seq[\"input_ids\"]  # grab ids\n",
    "\n",
    "    # place on device, convert to tensor\n",
    "    tok_seq = torch.LongTensor(tok_seq).unsqueeze(0)  # unsqueeze for batch dim\n",
    "    tok_seq = tok_seq.to(device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        embeddings = model(tok_seq)\n",
    "\n",
    "    # cls_embedding = embeddings.last_hidden_state[:, 0, :]\n",
    "    # cls_embedding = embeddings[:, 0, :]\n",
    "    \n",
    "    mean_embeddings = embeddings.mean(dim=1) # Mean across the sequence length dimension\n",
    "    mean_embeddings = mean_embeddings.squeeze(0)  # This will change the shape to [256]\n",
    "\n",
    "    \n",
    "    # print(embeddings.shape)  # embeddings here!\n",
    "    # return cls_embedding\n",
    "    return mean_embeddings\n",
    "\n",
    "# max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c1ea2f-6b84-4308-a4d0-4e018b1d446f",
   "metadata": {},
   "source": [
    "### Main Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d899db1-344c-4812-8392-248e309c12df",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pretrained_model_name = 'hyenadna-small-32k-seqlen'\n",
    "pretrained_model_name = 'hyenadna-medium-160k-seqlen'\n",
    "# pretrained_model_name = 'hyenadna-medium-450k-seqlen'\n",
    "# pretrained_model_name = 'hyenadna-large-1m-seqlen'\n",
    "model, tokenizer, max_length =  get_model_tokenizer_maxlen(pretrained_model_name)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a69720a-d062-4659-88ba-60f2ba6a5e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile='methylation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d8b7c-fcdb-4390-aac3-de63631067fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filename = '../../datasets/task05-methylation/GSM6637962_CpG_coverage20_GRCh38.bed.gz'     \n",
    "df = preprocess_datafile(data_filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a73b5a5-247c-4cc8-8dc2-bc2d44e7f9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "csv_Filename =datafile + '_hyena_embedding.csv'\n",
    "\n",
    "if os.path.exists(csv_Filename):\n",
    "    os.remove(csv_Filename)\n",
    "\n",
    "\n",
    "rows=[]\n",
    "for index, row in df.iterrows():      \n",
    "    chrom=row['CHROM']\n",
    "    pos_start=row['START']\n",
    "\n",
    "    if pos_start<=1:\n",
    "        pos_start=1\n",
    "    y=row['y']\n",
    "    length = row['SIZE'] # max_length\n",
    "    \n",
    "    subsequence = get_subsequence(chrom, pos_start, length)\n",
    "    if 'N' in subsequence:\n",
    "        print(\"The character 'N' is present in the string.\")\n",
    "        \n",
    "    embedding = Subsequence2Embedding(subsequence)\n",
    "    # print(embedding.shape)\n",
    "\n",
    "    # feature=np.array(embedding_df.iloc[64])\n",
    "    rows.append(np.append(embedding.cpu().numpy(),  [y])) # chrom,  length,  comp[ref],comp[alt],\n",
    "\n",
    "    if index > 0 and (index % 5000) == 0:\n",
    "        append_rows_to_csv(csv_Filename, rows)\n",
    "        rows=[]\n",
    "        print (f\"index = {index} completed\")\n",
    "        \n",
    "append_rows_to_csv(csv_Filename, rows)\n",
    "\n",
    "print(f\"Create File: \"+csv_Filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93f1c14-0ef8-4efa-84df-c94596ac0b59",
   "metadata": {},
   "source": [
    "### Load CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d6b579-726c-438b-9c2b-1c91b2e81b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_embedding_file(csv_Filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba02fc7a-4795-4d96-a844-4339a5f59f75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
