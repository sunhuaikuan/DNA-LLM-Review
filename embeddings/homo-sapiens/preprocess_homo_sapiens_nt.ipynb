{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95346cfc-20f3-4774-8faf-7d5c16a38ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import jax\n",
    "import haiku as hk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from datasets import Dataset, DatasetDict\n",
    "from nucleotide_transformer.pretrained import get_pretrained_model\n",
    "\n",
    "%run preprocess_utility.py\n",
    "\n",
    "print(jax.devices())\n",
    "\n",
    "# device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1caa05-0f9a-4eea-92e0-5264dca56a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import nucleotide_transformer\n",
    "except:\n",
    "    !pip install numpy==1.23.5\n",
    "    !pip install git+https://github.com/instadeepai/nucleotide-transformer@main |tail -n 1\n",
    "    import nucleotide_transformer\n",
    "\n",
    "if \"COLAB_TPU_ADDR\" in os.environ:\n",
    "    from jax.tools import colab_tpu\n",
    "\n",
    "    colab_tpu.setup_tpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b4634-4739-459f-bbf7-ab2b3d7bf974",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = {'A':1, 'C':2, 'G':3, 'T':4}\n",
    "\n",
    "#@title Select a model\n",
    "#@markdown ---\n",
    "model_name = '500M_human_ref'\n",
    "#@markdown ---\n",
    "\n",
    "# Get pretrained model\n",
    "parameters, forward_fn, tokenizer, config = get_pretrained_model(\n",
    "    model_name=model_name,\n",
    "    embeddings_layers_to_save=(20,),\n",
    "    attention_maps_to_save=((1, 4), (7, 18)),\n",
    "    max_positions=32,\n",
    "    # If the progress bar gets stuck at the start of the model wieghts download,\n",
    "    # you can set verbose=False to download without the progress bar.\n",
    "    verbose=False\n",
    ")\n",
    "forward_fn = hk.transform(forward_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3ddf34-3abf-401b-8a00-945559cd4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_file = \"../genome.hg38rg.fa\"\n",
    "chrom_sequences = read_fasta(fasta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa866967-1741-48a1-8005-d6e392d357c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subsequence(sequences, chrom_name, start_pos, length):\n",
    "    \n",
    "    if chrom_name in sequences:\n",
    "        sequence = sequences[chrom_name]\n",
    "        subsequence = sequence[start_pos:start_pos + length]\n",
    "        return subsequence\n",
    "    else:\n",
    "        raise ValueError(f\"Chromosome '{chrom_name}' not found in the FASTA file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9979447-a187-42c3-932f-ed92895db9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_data(final_df, sub_df, sub_embedding_df):\n",
    "    \n",
    "    sub_df = sub_df.reset_index(drop=True)\n",
    "    sub_embedding_df = sub_embedding_df.reset_index(drop=True)\n",
    "    \n",
    "    sub_final_df = pd.concat([sub_embedding_df, sub_df],  axis=1, ignore_index=True)\n",
    "    final_df = pd.concat([final_df, sub_final_df],  axis=0, ignore_index=True) \n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7971a80d-1979-4f6c-9ee6-47a24d7aebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(df):\n",
    "    sequences = []\n",
    "    for index, row in df.iterrows():      \n",
    "        chrom=row['CHROM']\n",
    "        pos_start=row['START']\n",
    "        rowid=row['ROWID']\n",
    "        y=row['y']\n",
    "        if row['SIZE'] % 6 == 0:\n",
    "            length = row['SIZE']\n",
    "        else:\n",
    "            length = 6 * round(row['SIZE'] / 6)\n",
    "    \n",
    "        subsequence = get_subsequence(chrom_sequences, chrom, pos_start, length)\n",
    "        if 'N' in subsequence:\n",
    "            print(\"The character 'N' is present in the string.\")\n",
    "    \n",
    "        sequences.append(subsequence)\n",
    "\n",
    "    try:\n",
    "        tokens_ids = [b[1] for b in tokenizer.batch_tokenize(sequences)]\n",
    "        tokens_str = [b[0] for b in tokenizer.batch_tokenize(sequences)]\n",
    "        tokens = jnp.asarray(tokens_ids, dtype=jnp.int32)   \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"exception caught: {e}\"+str(row['CHROM'])+'-'+str(row['START'])+'-'+str(row['SIZE']))\n",
    "        tokens=None\n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c86476-724f-4798-8906-c9b6c0b30eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(tokens):\n",
    "\n",
    "    # Initialize random key\n",
    "    random_key = jax.random.PRNGKey(0)\n",
    "    \n",
    "    # Infer\n",
    "    outs = forward_fn.apply(parameters, random_key, tokens)    \n",
    "    # print(outs.keys())    \n",
    "\n",
    "    my_embedding=outs[\"embeddings_20\"][:,0,:]\n",
    "    \n",
    "    my_embedding.shape\n",
    "    column_names = [f'{i}' for i in range(0, my_embedding.shape[1])]\n",
    "    embedding_df = pd.DataFrame(my_embedding, columns=column_names)\n",
    "    return embedding_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1afbb68-fb6f-403c-b330-2c099c50676c",
   "metadata": {},
   "source": [
    "### Process datafile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65952f79-5ccd-4fdb-ba31-81749f3dc27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length= 186\n",
    "\n",
    "datafile_path = '../../datasets/task03-homo-sapiens/Homo_sapiens.GRCh38.109.txt.gz'  \n",
    "df = preprocess_home_sapiens_datafile(datafile_path)\n",
    "\n",
    "df.loc[df['SIZE'] > max_length, 'END'] = df['START'] + max_length\n",
    "df.loc[df['SIZE'] > max_length, 'SIZE'] = max_length\n",
    "\n",
    "df.drop(columns=['END','TYPE','CLUSTER'], inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0e6596-a93b-40a0-bdfe-74d2975268e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sub_df = pd.DataFrame()    \n",
    "final_df = pd.DataFrame()\n",
    "segment=2000\n",
    "\n",
    "\n",
    "csv_Filename = './homo_sapiens_nt_embedding.csv'\n",
    "if os.path.exists(csv_Filename):\n",
    "    os.remove(csv_Filename)\n",
    "\n",
    "\n",
    "cnt=0\n",
    "for index, row in df.iterrows():\n",
    "    cnt+=1\n",
    "    sub_df = sub_df.drop(sub_df.index)\n",
    "    \n",
    "    if (cnt % segment==0):\n",
    "        sub_df = df.iloc[cnt-segment:cnt]\n",
    "        sub_tokens = get_tokens(sub_df)\n",
    "        sub_embedding_df = get_embeddings(sub_tokens)       \n",
    "        final_df = append_data(final_df, sub_df, sub_embedding_df)\n",
    "        \n",
    "        sub_df = sub_df.reset_index(drop=True)\n",
    "        print(f\"complete batch...... {cnt}\")\n",
    "\n",
    "\n",
    "print(f\"last index...... {(cnt)}\")\n",
    "sub_df = df.iloc[cnt-(cnt % segment):cnt]\n",
    "sub_tokens = get_tokens(sub_df)\n",
    "sub_embedding_df = get_embeddings(sub_tokens)        \n",
    "final_df = append_data(final_df, sub_df, sub_embedding_df)\n",
    "\n",
    "\n",
    "column_names = [f'{i}' for i in range(0, final_df.shape[1]-5)]\n",
    "column_names.extend(['CHROM', 'START', 'SIZE', 'ROWID',  'y'])\n",
    "final_df.columns = column_names\n",
    "final_df = final_df.drop(columns=['CHROM','START','SIZE'])\n",
    "\n",
    "final_df.to_csv(csv_Filename, sep=',', index=False,  header=True, na_rep='NaN')\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b655bb-9f26-488b-af6c-336a964924d6",
   "metadata": {},
   "source": [
    "### Load CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a58831-49e1-4ff6-8bd1-1e3204ee49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding_file(csv_filename):\n",
    "\n",
    "    df=pd.read_csv(csv_filename)\n",
    "    return df\n",
    "\n",
    "df = load_embedding_file('./homo_sapiens_nt_embedding.csv')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
