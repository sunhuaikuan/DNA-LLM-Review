{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94159a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from transformers import AutoModel #, AutoModelForMaskedLM\n",
    "\n",
    "# import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "%run hyena_utility.py\n",
    "\n",
    "%run preprocess_utility.py\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0495a5df-3a69-4196-b12d-ab504d00f4d4",
   "metadata": {},
   "source": [
    "### Load Human Chrom Sequences from .fa File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5760522-3c27-4a0c-9fe0-209a212edc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_file = \"../genome.hg38rg.fa\"\n",
    "chrom_sequences = read_fasta(fasta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89af52c7-67c6-4427-b9d4-6f2fe12a34ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Subsequence2Embedding(subsequence):\n",
    "    tok_seq = tokenizer(subsequence)\n",
    "    tok_seq = tok_seq[\"input_ids\"]  \n",
    "\n",
    "    # place on device, convert to tensor\n",
    "    tok_seq = torch.LongTensor(tok_seq).unsqueeze(0)  # unsqueeze for batch dim\n",
    "    tok_seq = tok_seq.to(device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        embeddings = model(tok_seq)\n",
    "\n",
    "    mean_embeddings = embeddings.mean(dim=1) # Mean across the sequence length dimension\n",
    "    mean_embeddings = mean_embeddings.squeeze(0)  # This will change the shape to [256]\n",
    "    \n",
    "    return mean_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc056b3-d504-495e-852e-2851ad0d2bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_rows_to_csv(csv_Filename, rows):\n",
    "    with open(csv_Filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for row in rows:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c1ea2f-6b84-4308-a4d0-4e018b1d446f",
   "metadata": {},
   "source": [
    "### Main Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d899db1-344c-4812-8392-248e309c12df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pretrained_model_name = 'hyenadna-medium-160k-seqlen'\n",
    "model, tokenizer, max_length =  get_model_tokenizer_maxlen(pretrained_model_name)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6553147-bfc8-48e8-9045-604061d2b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subsequence(chrom_name, start_pos, length):\n",
    "    \n",
    "    if chrom_name in chrom_sequences:\n",
    "        sequence = chrom_sequences[chrom_name]\n",
    "        subsequence = sequence[start_pos:start_pos + length]\n",
    "        return subsequence\n",
    "    else:\n",
    "        raise ValueError(f\"Chromosome '{chrom_name}' not found in the FASTA file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a73b5a5-247c-4cc8-8dc2-bc2d44e7f9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "comp = {'A':1, 'C':2, 'G':3, 'T':4}\n",
    "\n",
    "max_length = 128\n",
    "\n",
    "csv_Filename = './homo_sapiens_hyena_embedding.csv'\n",
    "if os.path.exists(csv_Filename):\n",
    "    os.remove(csv_Filename)\n",
    "\n",
    "datafile_path = '../../datasets/task03-homo-sapiens/Homo_sapiens.GRCh38.109.txt.gz'  \n",
    "df = preprocess_home_sapiens_datafile(datafile_path)\n",
    "\n",
    "\n",
    "df.loc[df['SIZE'] > max_length, 'END'] = df['START'] + max_length\n",
    "df.loc[df['SIZE'] > max_length, 'SIZE'] = max_length\n",
    "df.drop(columns=['END','TYPE','CLUSTER'], inplace=True)\n",
    "# df\n",
    "\n",
    "\n",
    "rows=[]\n",
    "for index, row in df.iterrows():      \n",
    "    chrom=row['CHROM']\n",
    "    rowid=row['ROWID']\n",
    "    pos_start=row['START']\n",
    "\n",
    "    if pos_start<=1:\n",
    "        pos_start=1\n",
    "    y=row['y']\n",
    "    length = row['SIZE'] # max_length\n",
    "    \n",
    "    subsequence = get_subsequence(chrom, pos_start, length)\n",
    "    if 'N' in subsequence:\n",
    "        print(\"The character 'N' is present in the string.\")\n",
    "        \n",
    "    embedding = Subsequence2Embedding(subsequence)\n",
    "    # print (embedding)\n",
    "\n",
    "    # feature=np.array(embedding_df.iloc[64])\n",
    "    rows.append(np.append(embedding.cpu().numpy(),  [rowid, y]))  #chrom, length,  \n",
    "\n",
    "\n",
    "    if index > 0 and (index % 2000) == 0:\n",
    "        append_rows_to_csv(csv_Filename, rows)\n",
    "        rows=[]\n",
    "        print (f\"index = {index} completed\")\n",
    "        \n",
    "append_rows_to_csv(csv_Filename, rows)\n",
    "\n",
    "print(f\"Create File: \"+csv_Filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93f1c14-0ef8-4efa-84df-c94596ac0b59",
   "metadata": {},
   "source": [
    "### Load CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d6b579-726c-438b-9c2b-1c91b2e81b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_embedding_file(csv_filename):\n",
    "\n",
    "    df=pd.read_csv(csv_filename)\n",
    "    \n",
    "    column_names = [f'{i}' for i in range(1, df.shape[1]-1)]\n",
    "    column_names.extend(['ROWID', 'y'])\n",
    "    \n",
    "    df.columns = column_names\n",
    "    return df\n",
    "df = load_embedding_file('./homo_sapiens_hyena_embedding.csv')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
