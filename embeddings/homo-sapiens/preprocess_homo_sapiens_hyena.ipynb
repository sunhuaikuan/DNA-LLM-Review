{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0d11a89-1cc9-4384-ac3c-ccc24a66f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install genomic_benchmarks\n",
    "# !pip install omegaconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94159a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/48992548/ipykernel_1145272/1527746069.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/home/sunhuaikuan/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Kernal PyTorch-2.0.1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from transformers import AutoModel #, AutoModelForMaskedLM\n",
    "\n",
    "# import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import pickle\n",
    "# import re\n",
    "import os\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "%run hyena_utility.py\n",
    "\n",
    "%run preprocess_utility.py\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0495a5df-3a69-4196-b12d-ab504d00f4d4",
   "metadata": {},
   "source": [
    "### Load Human Chrom Sequences from .fa File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5760522-3c27-4a0c-9fe0-209a212edc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_file = \"/blue/xiaofan/sunhuaikuan/gpn/examples/msa/genome.hg38rg.fa\"\n",
    "chrom_sequences = read_fasta(fasta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00928314-c642-46b7-841a-401f18320873",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def Cur_Inference(model, tokenizer, max_length, device, sequence):\n",
    "def Cur_Inference(model, sequence):  # model, tokenizer, max_length, device, \n",
    "\n",
    "    '''\n",
    "    this selects which backbone to use, and grabs weights/ config from HF\n",
    "    4 options:\n",
    "      'hyenadna-tiny-1k-seqlen'   # fine-tune on colab ok\n",
    "      'hyenadna-small-32k-seqlen'\n",
    "      'hyenadna-medium-160k-seqlen'  # inference only on colab\n",
    "      'hyenadna-medium-450k-seqlen'  # inference only on colab\n",
    "      'hyenadna-large-1m-seqlen'  # inference only on colab\n",
    "    '''\n",
    "\n",
    "    # you only need to select which model to use here, we'll do the rest!\n",
    "    # pretrained_model_name = 'hyenadna-small-32k-seqlen'\n",
    "\n",
    "    # max_lengths = {\n",
    "    #     'hyenadna-tiny-1k-seqlen': 1024,\n",
    "    #     'hyenadna-small-32k-seqlen': 32768,\n",
    "    #     'hyenadna-medium-160k-seqlen': 160000,\n",
    "    #     'hyenadna-medium-450k-seqlen': 450000,  # T4 up to here\n",
    "    #     'hyenadna-large-1m-seqlen': 1_000_000,  # only A100 (paid tier)\n",
    "    # }\n",
    "\n",
    "\n",
    "    #### Single embedding example ####\n",
    "\n",
    "    # create a sample 450k long, prepare\n",
    "    # sequence = 'ACTG' * int(max_length/4)\n",
    "    tok_seq = tokenizer(sequence)\n",
    "    tok_seq = tok_seq[\"input_ids\"]  # grab ids\n",
    "\n",
    "    # place on device, convert to tensor\n",
    "    tok_seq = torch.LongTensor(tok_seq).unsqueeze(0)  # unsqueeze for batch dim\n",
    "    tok_seq = tok_seq.to(device)\n",
    "\n",
    "    # prep model and forward\n",
    "    # model.to(device)\n",
    "    # model.eval()\n",
    "    with torch.inference_mode():\n",
    "        embeddings = model(tok_seq)\n",
    "\n",
    "    # cls_embedding = embeddings.last_hidden_state[:, 0, :]\n",
    "    # cls_embedding = embeddings[:, 0, :]\n",
    "    \n",
    "    mean_embeddings = embeddings.mean(dim=1) # Mean across the sequence length dimension\n",
    "    mean_embeddings = mean_embeddings.squeeze(0)  # This will change the shape to [256]\n",
    "\n",
    "    \n",
    "    # print(embeddings.shape)  # embeddings here!\n",
    "    # return cls_embedding\n",
    "    return mean_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89af52c7-67c6-4427-b9d4-6f2fe12a34ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Subsequence2Embedding(model, tokenizer, max_length, device, subsequence):\n",
    "def Subsequence2Embedding(subsequence):\n",
    "    # embeddings = My_Inference(model, tokenizer, max_length, device, subsequence)\n",
    "    embeddings = Cur_Inference(model, subsequence)\n",
    "    # print(embeddings.shape)\n",
    "    # print (embeddings)\n",
    "    # return embeddings[0,int(max_length/2),:]\n",
    "    return embeddings  # embeddings[0,0,:]\n",
    "\n",
    "# max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bc056b3-d504-495e-852e-2851ad0d2bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_rows_to_csv(csv_Filename, rows):\n",
    "    with open(csv_Filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # writer.writerow(rows)\n",
    "        for row in rows:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c1ea2f-6b84-4308-a4d0-4e018b1d446f",
   "metadata": {},
   "source": [
    "### Main Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d899db1-344c-4812-8392-248e309c12df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Git LFS initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'hyenadna-medium-160k-seqlen'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights ok!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HyenaDNAModel(\n",
       "  (backbone): LMBackbone(\n",
       "    (embeddings): GPT2Embeddings(\n",
       "      (word_embeddings): Embedding(16, 256)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): Block(\n",
       "        (mixer): HyenaOperator(\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (in_proj): Linear(in_features=256, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (short_filter): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(2,), groups=768)\n",
       "          (filter_fn): HyenaFilter(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb): PositionalEmbedding()\n",
       "            (implicit_filter): Sequential(\n",
       "              (0): Linear(in_features=5, out_features=64, bias=True)\n",
       "              (1): Sin()\n",
       "              (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (3): Sin()\n",
       "              (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (5): Sin()\n",
       "              (6): Linear(in_features=64, out_features=256, bias=False)\n",
       "            )\n",
       "            (modulation): ExponentialModulation()\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1-7): 7 x Block(\n",
       "        (mixer): HyenaOperator(\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (in_proj): Linear(in_features=256, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (short_filter): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(2,), groups=768)\n",
       "          (filter_fn): HyenaFilter(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb): PositionalEmbedding()\n",
       "            (implicit_filter): Sequential(\n",
       "              (0): Linear(in_features=5, out_features=64, bias=True)\n",
       "              (1): Sin()\n",
       "              (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (3): Sin()\n",
       "              (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (5): Sin()\n",
       "              (6): Linear(in_features=64, out_features=256, bias=False)\n",
       "            )\n",
       "            (modulation): ExponentialModulation()\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (drop_f): Dropout(p=0.0, inplace=False)\n",
       "    (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = 'hyenadna-small-32k-seqlen'\n",
    "pretrained_model_name = 'hyenadna-medium-160k-seqlen'\n",
    "# pretrained_model_name = 'hyenadna-medium-450k-seqlen'\n",
    "# pretrained_model_name = 'hyenadna-large-1m-seqlen'\n",
    "model, tokenizer, max_length =  get_model_tokenizer_maxlen(pretrained_model_name)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6553147-bfc8-48e8-9045-604061d2b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subsequence(chrom_name, start_pos, length):\n",
    "    \n",
    "    # print(chrom_name, start_pos, length)\n",
    "    if chrom_name in chrom_sequences:\n",
    "        sequence = chrom_sequences[chrom_name]\n",
    "        subsequence = sequence[start_pos:start_pos + length]\n",
    "        return subsequence\n",
    "    else:\n",
    "        raise ValueError(f\"Chromosome '{chrom_name}' not found in the FASTA file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a73b5a5-247c-4cc8-8dc2-bc2d44e7f9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index = 2000 completed\n",
      "index = 4000 completed\n",
      "index = 6000 completed\n",
      "index = 8000 completed\n",
      "index = 10000 completed\n",
      "index = 12000 completed\n",
      "index = 14000 completed\n",
      "index = 16000 completed\n",
      "index = 18000 completed\n",
      "index = 20000 completed\n",
      "index = 22000 completed\n",
      "index = 24000 completed\n",
      "index = 26000 completed\n",
      "index = 28000 completed\n",
      "index = 30000 completed\n",
      "index = 32000 completed\n",
      "index = 34000 completed\n",
      "Create File: ./homo_sapiens_hyena_embedding.csv\n",
      "CPU times: user 4min 29s, sys: 398 ms, total: 4min 29s\n",
      "Wall time: 4min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "comp = {'A':1, 'C':2, 'G':3, 'T':4}\n",
    "\n",
    "max_length = 128\n",
    "\n",
    "csv_Filename = './homo_sapiens_hyena_embedding.csv'\n",
    "if os.path.exists(csv_Filename):\n",
    "    os.remove(csv_Filename)\n",
    "\n",
    "datafile_path = '/blue/xiaofan/chenyuanhan/data/Homo_sapiens.GRCh38.109.txt.gz'  \n",
    "df = preprocess_home_sapiens_datafile(datafile_path)\n",
    "\n",
    "\n",
    "df.loc[df['SIZE'] > max_length, 'END'] = df['START'] + max_length\n",
    "df.loc[df['SIZE'] > max_length, 'SIZE'] = max_length\n",
    "df.drop(columns=['END','TYPE','CLUSTER'], inplace=True)\n",
    "# df\n",
    "\n",
    "\n",
    "rows=[]\n",
    "for index, row in df.iterrows():      \n",
    "    chrom=row['CHROM']\n",
    "    rowid=row['ROWID']\n",
    "    # pos_start=row['POS']-round(max_length / 2)\n",
    "    pos_start=row['START']\n",
    "\n",
    "    if pos_start<=1:\n",
    "        pos_start=1\n",
    "    # ref=row['REF']\n",
    "    # alt=row['ALT']        \n",
    "    y=row['y']\n",
    "    length = row['SIZE'] # max_length\n",
    "    \n",
    "    subsequence = get_subsequence(chrom, pos_start, length)\n",
    "    if 'N' in subsequence:\n",
    "        print(\"The character 'N' is present in the string.\")\n",
    "        \n",
    "    embedding = Subsequence2Embedding(subsequence)\n",
    "    # print(embedding.shape)\n",
    "    # print (embedding)\n",
    "\n",
    "    # feature=np.array(embedding_df.iloc[64])\n",
    "    rows.append(np.append(embedding.cpu().numpy(),  [rowid, y]))  #chrom, length,  \n",
    "\n",
    "\n",
    "    if index > 0 and (index % 2000) == 0:\n",
    "        append_rows_to_csv(csv_Filename, rows)\n",
    "        rows=[]\n",
    "        print (f\"index = {index} completed\")\n",
    "        \n",
    "append_rows_to_csv(csv_Filename, rows)\n",
    "\n",
    "print(f\"Create File: \"+csv_Filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93f1c14-0ef8-4efa-84df-c94596ac0b59",
   "metadata": {},
   "source": [
    "### Load CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d6b579-726c-438b-9c2b-1c91b2e81b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/48992548/ipykernel_1322225/1530850494.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>ROWID</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.098259</td>\n",
       "      <td>-0.778371</td>\n",
       "      <td>-0.567632</td>\n",
       "      <td>-0.864359</td>\n",
       "      <td>-0.912805</td>\n",
       "      <td>-0.907104</td>\n",
       "      <td>1.634788</td>\n",
       "      <td>-0.941197</td>\n",
       "      <td>0.169670</td>\n",
       "      <td>0.114994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455128</td>\n",
       "      <td>-0.650662</td>\n",
       "      <td>-1.605736</td>\n",
       "      <td>-1.492585</td>\n",
       "      <td>1.182727</td>\n",
       "      <td>0.519747</td>\n",
       "      <td>0.673476</td>\n",
       "      <td>-1.080819</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.225349</td>\n",
       "      <td>-0.772242</td>\n",
       "      <td>-0.580955</td>\n",
       "      <td>-1.056253</td>\n",
       "      <td>-1.319412</td>\n",
       "      <td>-0.937095</td>\n",
       "      <td>1.204180</td>\n",
       "      <td>-0.703993</td>\n",
       "      <td>-0.227651</td>\n",
       "      <td>0.182004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496497</td>\n",
       "      <td>-1.000214</td>\n",
       "      <td>-1.584138</td>\n",
       "      <td>-1.652526</td>\n",
       "      <td>1.257367</td>\n",
       "      <td>0.468274</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>-0.962163</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000942</td>\n",
       "      <td>-0.598621</td>\n",
       "      <td>-0.672390</td>\n",
       "      <td>-0.641442</td>\n",
       "      <td>-1.040335</td>\n",
       "      <td>-0.755668</td>\n",
       "      <td>1.274980</td>\n",
       "      <td>-0.978171</td>\n",
       "      <td>-0.042830</td>\n",
       "      <td>0.124320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494047</td>\n",
       "      <td>-0.849385</td>\n",
       "      <td>-1.569252</td>\n",
       "      <td>-1.409305</td>\n",
       "      <td>1.183825</td>\n",
       "      <td>0.358066</td>\n",
       "      <td>0.373570</td>\n",
       "      <td>-1.182730</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.120756</td>\n",
       "      <td>-0.799536</td>\n",
       "      <td>-0.620240</td>\n",
       "      <td>-0.805628</td>\n",
       "      <td>-1.006669</td>\n",
       "      <td>-0.907013</td>\n",
       "      <td>1.548830</td>\n",
       "      <td>-0.936683</td>\n",
       "      <td>0.091012</td>\n",
       "      <td>0.218409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447258</td>\n",
       "      <td>-0.846772</td>\n",
       "      <td>-1.625529</td>\n",
       "      <td>-1.477122</td>\n",
       "      <td>1.251898</td>\n",
       "      <td>0.502077</td>\n",
       "      <td>0.407137</td>\n",
       "      <td>-1.082190</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.087019</td>\n",
       "      <td>-0.803882</td>\n",
       "      <td>-0.531570</td>\n",
       "      <td>-0.888757</td>\n",
       "      <td>-1.351001</td>\n",
       "      <td>-0.758447</td>\n",
       "      <td>1.058772</td>\n",
       "      <td>-0.702686</td>\n",
       "      <td>-0.500163</td>\n",
       "      <td>0.162552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480105</td>\n",
       "      <td>-1.057028</td>\n",
       "      <td>-1.528152</td>\n",
       "      <td>-1.568092</td>\n",
       "      <td>1.297123</td>\n",
       "      <td>0.465277</td>\n",
       "      <td>0.306736</td>\n",
       "      <td>-0.968242</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34785</th>\n",
       "      <td>0.274643</td>\n",
       "      <td>-0.629633</td>\n",
       "      <td>-0.364290</td>\n",
       "      <td>-0.470770</td>\n",
       "      <td>-1.037111</td>\n",
       "      <td>-0.344028</td>\n",
       "      <td>0.983549</td>\n",
       "      <td>-0.706644</td>\n",
       "      <td>-0.610683</td>\n",
       "      <td>-0.003416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450930</td>\n",
       "      <td>-0.982729</td>\n",
       "      <td>-1.377394</td>\n",
       "      <td>-1.215747</td>\n",
       "      <td>1.303958</td>\n",
       "      <td>0.193141</td>\n",
       "      <td>0.440559</td>\n",
       "      <td>-0.997618</td>\n",
       "      <td>34832.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34786</th>\n",
       "      <td>-0.120933</td>\n",
       "      <td>-0.795169</td>\n",
       "      <td>-0.486470</td>\n",
       "      <td>-0.896732</td>\n",
       "      <td>-0.729815</td>\n",
       "      <td>-0.907107</td>\n",
       "      <td>1.312369</td>\n",
       "      <td>-0.878555</td>\n",
       "      <td>-0.061940</td>\n",
       "      <td>0.434641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478314</td>\n",
       "      <td>-0.906501</td>\n",
       "      <td>-1.576636</td>\n",
       "      <td>-1.562356</td>\n",
       "      <td>1.228592</td>\n",
       "      <td>0.552661</td>\n",
       "      <td>0.454011</td>\n",
       "      <td>-0.952927</td>\n",
       "      <td>34833.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34787</th>\n",
       "      <td>-0.214810</td>\n",
       "      <td>-0.918239</td>\n",
       "      <td>-0.492211</td>\n",
       "      <td>-0.741898</td>\n",
       "      <td>-0.633027</td>\n",
       "      <td>-1.155706</td>\n",
       "      <td>1.678414</td>\n",
       "      <td>-0.957490</td>\n",
       "      <td>0.181382</td>\n",
       "      <td>0.355271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178224</td>\n",
       "      <td>-0.777092</td>\n",
       "      <td>-1.570812</td>\n",
       "      <td>-1.401757</td>\n",
       "      <td>1.297300</td>\n",
       "      <td>0.631772</td>\n",
       "      <td>0.571384</td>\n",
       "      <td>-0.866733</td>\n",
       "      <td>34834.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34788</th>\n",
       "      <td>-0.144414</td>\n",
       "      <td>-0.804913</td>\n",
       "      <td>-0.485522</td>\n",
       "      <td>-0.898138</td>\n",
       "      <td>-0.753247</td>\n",
       "      <td>-0.915142</td>\n",
       "      <td>1.296546</td>\n",
       "      <td>-0.867254</td>\n",
       "      <td>-0.063795</td>\n",
       "      <td>0.437570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474064</td>\n",
       "      <td>-0.915721</td>\n",
       "      <td>-1.579077</td>\n",
       "      <td>-1.566750</td>\n",
       "      <td>1.219721</td>\n",
       "      <td>0.559222</td>\n",
       "      <td>0.440362</td>\n",
       "      <td>-0.949460</td>\n",
       "      <td>34835.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34789</th>\n",
       "      <td>-0.024038</td>\n",
       "      <td>-0.438704</td>\n",
       "      <td>-0.351695</td>\n",
       "      <td>-0.306513</td>\n",
       "      <td>-0.677396</td>\n",
       "      <td>-0.250702</td>\n",
       "      <td>0.856295</td>\n",
       "      <td>-0.338614</td>\n",
       "      <td>-0.955879</td>\n",
       "      <td>0.242296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520498</td>\n",
       "      <td>-0.696467</td>\n",
       "      <td>-0.755959</td>\n",
       "      <td>-0.641644</td>\n",
       "      <td>1.196435</td>\n",
       "      <td>0.280678</td>\n",
       "      <td>0.846985</td>\n",
       "      <td>-0.515176</td>\n",
       "      <td>34836.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34790 rows × 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1         2         3         4         5         6         7  \\\n",
       "0     -0.098259 -0.778371 -0.567632 -0.864359 -0.912805 -0.907104  1.634788   \n",
       "1     -0.225349 -0.772242 -0.580955 -1.056253 -1.319412 -0.937095  1.204180   \n",
       "2      0.000942 -0.598621 -0.672390 -0.641442 -1.040335 -0.755668  1.274980   \n",
       "3     -0.120756 -0.799536 -0.620240 -0.805628 -1.006669 -0.907013  1.548830   \n",
       "4     -0.087019 -0.803882 -0.531570 -0.888757 -1.351001 -0.758447  1.058772   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "34785  0.274643 -0.629633 -0.364290 -0.470770 -1.037111 -0.344028  0.983549   \n",
       "34786 -0.120933 -0.795169 -0.486470 -0.896732 -0.729815 -0.907107  1.312369   \n",
       "34787 -0.214810 -0.918239 -0.492211 -0.741898 -0.633027 -1.155706  1.678414   \n",
       "34788 -0.144414 -0.804913 -0.485522 -0.898138 -0.753247 -0.915142  1.296546   \n",
       "34789 -0.024038 -0.438704 -0.351695 -0.306513 -0.677396 -0.250702  0.856295   \n",
       "\n",
       "              8         9        10  ...       249       250       251  \\\n",
       "0     -0.941197  0.169670  0.114994  ...  0.455128 -0.650662 -1.605736   \n",
       "1     -0.703993 -0.227651  0.182004  ...  0.496497 -1.000214 -1.584138   \n",
       "2     -0.978171 -0.042830  0.124320  ...  0.494047 -0.849385 -1.569252   \n",
       "3     -0.936683  0.091012  0.218409  ...  0.447258 -0.846772 -1.625529   \n",
       "4     -0.702686 -0.500163  0.162552  ...  0.480105 -1.057028 -1.528152   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "34785 -0.706644 -0.610683 -0.003416  ...  0.450930 -0.982729 -1.377394   \n",
       "34786 -0.878555 -0.061940  0.434641  ...  0.478314 -0.906501 -1.576636   \n",
       "34787 -0.957490  0.181382  0.355271  ...  0.178224 -0.777092 -1.570812   \n",
       "34788 -0.867254 -0.063795  0.437570  ...  0.474064 -0.915721 -1.579077   \n",
       "34789 -0.338614 -0.955879  0.242296  ...  0.520498 -0.696467 -0.755959   \n",
       "\n",
       "            252       253       254       255       256    ROWID    y  \n",
       "0     -1.492585  1.182727  0.519747  0.673476 -1.080819      1.0  0.0  \n",
       "1     -1.652526  1.257367  0.468274  0.278431 -0.962163      2.0  0.0  \n",
       "2     -1.409305  1.183825  0.358066  0.373570 -1.182730      3.0  0.0  \n",
       "3     -1.477122  1.251898  0.502077  0.407137 -1.082190      4.0  0.0  \n",
       "4     -1.568092  1.297123  0.465277  0.306736 -0.968242      5.0  0.0  \n",
       "...         ...       ...       ...       ...       ...      ...  ...  \n",
       "34785 -1.215747  1.303958  0.193141  0.440559 -0.997618  34832.0  6.0  \n",
       "34786 -1.562356  1.228592  0.552661  0.454011 -0.952927  34833.0  6.0  \n",
       "34787 -1.401757  1.297300  0.631772  0.571384 -0.866733  34834.0  6.0  \n",
       "34788 -1.566750  1.219721  0.559222  0.440362 -0.949460  34835.0  6.0  \n",
       "34789 -0.641644  1.196435  0.280678  0.846985 -0.515176  34836.0  6.0  \n",
       "\n",
       "[34790 rows x 258 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_embedding_file(csv_filename):\n",
    "\n",
    "    df=pd.read_csv(csv_filename)\n",
    "    \n",
    "    column_names = [f'{i}' for i in range(1, df.shape[1]-1)]\n",
    "    column_names.extend(['ROWID', 'y'])\n",
    "    \n",
    "    df.columns = column_names\n",
    "    return df\n",
    "df = load_embedding_file('./homo_sapiens_hyena_embedding.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0c84b0-a857-4285-9b5c-cac3cc2577d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-2.0.1",
   "language": "python",
   "name": "pytorch-2.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
