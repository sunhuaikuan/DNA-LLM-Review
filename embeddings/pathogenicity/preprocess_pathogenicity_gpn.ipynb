{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cacbfc-bb6d-4a47-8944-82230b5e94a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpn.data import GenomeMSA #, Tokenizer\n",
    "import gpn.model\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from transformers import AutoModel #, AutoModelForMaskedLM\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a662182d-8566-4312-8f56-3a1cbb72dfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"songlab/gpn-msa-sapiens\"\n",
    "msa_path = \"zip:///::/home/sunhuaikuan/ondemand/blue_gpn/examples/msa/89.zarr.zip\"\n",
    "genome_msa = GenomeMSA(msa_path)\n",
    "model = AutoModel.from_pretrained(model_path).to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f1f950-2739-44b5-b7c0-f666d3c80d6a",
   "metadata": {},
   "source": [
    "### Main Function to get Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8d7807-85ad-44b3-9447-63e55064a87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = {'A':1, 'C':2, 'G':3, 'T':4}\n",
    "\n",
    "max_seqlen=128\n",
    "\n",
    "def Genosome2Embedding(chrom, pos_start, pos_end,  y):  # ref,alt,\n",
    "    msa = genome_msa.get_msa(str(chrom), pos_start, pos_end, strand=\"+\", tokenize=True)\n",
    "    # print(msa.shape)\n",
    "\n",
    "    msa = torch.tensor(np.expand_dims(msa, 0).astype(np.int64))\n",
    "    # msa\n",
    "\n",
    "    # separating human from rest of species\n",
    "    input_ids, aux_features = msa[:, :, 0], msa[:, :, 1:]\n",
    "    \n",
    "    input_ids = input_ids.to(device)\n",
    "    aux_features = aux_features.to(device)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(input_ids=input_ids, aux_features=aux_features).last_hidden_state\n",
    "        \n",
    "        # Mean Pooling: Compute the mean across the sequence length (dim=1)\n",
    "        mean_pooled = last_hidden_state.mean(dim=1)  # Shape: (batch_size, embedding_dim)\n",
    "\n",
    "    feature=np.append(mean_pooled.cpu().numpy(),  [y]) # chrom,  pos_end-pos_start, comp[ref],comp[alt],\n",
    "    \n",
    "    return feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477b3f25-8134-4403-840b-1ee587329800",
   "metadata": {},
   "source": [
    "### Output CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c65f65-0068-44a6-aacb-efb384aabe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output2CSV(df, csv_Filename):\n",
    "\n",
    "    if os.path.exists(csv_Filename):\n",
    "        os.remove(csv_Filename)\n",
    "\n",
    "    rows=[]\n",
    "    # progress_bar = tqdm(total=df.shape[0], desc=\"Processing\")\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        chrom=row['CHROM']\n",
    "        pos_start=row['START']\n",
    "        pos_end=row['END']\n",
    "        y=row['y']\n",
    "        try:\n",
    "            embedding  =  Genosome2Embedding(chrom, pos_start,pos_end, y) # ref,alt,\n",
    "            rows.append(embedding)\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"exception caught: {e}\"+str(row['CHROM'])+'-'+str(row['START']))\n",
    "    \n",
    "\n",
    "        if ((index % 5000) ==0):\n",
    "            with open(csv_Filename, mode='a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                # writer.writerow(rows)\n",
    "                for row in rows:\n",
    "                    writer.writerow(row)\n",
    "            rows=[]\n",
    "            # progress_bar.update(1)\n",
    "            print(f\"complete index={index}\")\n",
    "\n",
    "\n",
    "    with open(csv_Filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for row in rows:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f\"Create File: \"+csv_Filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14719867-8daf-47b6-8957-4f78881c9b1a",
   "metadata": {},
   "source": [
    "### Load Homo_Sapiens data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de9326f-4bb1-4d5a-8490-064f30d689d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seqlen=128\n",
    "\n",
    "\n",
    "pathogenecity_type='noncoding'\n",
    "datafile='/home/sunhuaikuan/ondemand/blue_papers/DNA_LLM_REVIEW/datasets/task04-pathogenecity/clinvar_20240805.'+pathogenecity_type+'.txt'\n",
    "\n",
    "# pathogenecity_type='missense'\n",
    "# datafile='/home/sunhuaikuan/ondemand/blue_papers/DNA_LLM_REVIEW/datasets/task04-pathogenecity/clinvar_20240805.'+pathogenecity_type+'_matched.txt'\n",
    "\n",
    "\n",
    "df=pd.read_csv(datafile, delimiter='\\t')\n",
    "\n",
    "columns_to_keep=['CHROM','POS','Pathogenicity'] # 'ID', 'REF','ALT',\n",
    "df = df[columns_to_keep]\n",
    "\n",
    "# Merge CHROM=9 and '9' etc\n",
    "for i in range(1,23):\n",
    "    df.loc[df['CHROM']==i,'CHROM']=str(i)\n",
    "\n",
    "df=df[~df['CHROM'].isna()]\n",
    "df = df[~df['CHROM'].str.contains('KI')]\n",
    "df = df[~df['CHROM'].str.contains('GL')]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "df['START']=df['POS']- max_seqlen //2 -1\n",
    "\n",
    "df['END']=df['START'] + max_seqlen\n",
    "\n",
    "df=df[~df['CHROM'].isna()]\n",
    "\n",
    "Pathogenicity_dict={'B':0,'P':1}\n",
    "df['y'] = df['Pathogenicity'].map(Pathogenicity_dict)\n",
    "\n",
    "df=df.drop(columns=['POS','Pathogenicity'])\n",
    "# df['CHROM'].value_counts()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26ed760-7a6c-4caf-a16b-bad70f3fb76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "now = datetime.now()\n",
    "formatted_time = now.strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "csv_filename = './pathogenecity_gpn_'+pathogenecity_type+'_'+formatted_time+'.csv'\n",
    "\n",
    "output2CSV(df,csv_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ae207-fd2a-40ec-9c03-a88b14504d6c",
   "metadata": {},
   "source": [
    "### Load CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb2e37-e973-43e7-b7ea-429c62e1b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_embedding_file(csv_filename):\n",
    "\n",
    "    df=pd.read_csv(csv_filename)\n",
    "     \n",
    "    column_names = [f'{i}' for i in range(1, df.shape[1])]\n",
    "    column_names.extend([ 'y'])\n",
    "    \n",
    "    df.columns = column_names\n",
    "    return df\n",
    "\n",
    "df = load_embedding_file(csv_filename)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
