{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94159a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from transformers import AutoModel #, AutoModelForMaskedLM\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import pickle\n",
    "# import re\n",
    "import os\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "%run hyena_utility.py\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00928314-c642-46b7-841a-401f18320873",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def Cur_Inference(model, tokenizer, max_length, device, sequence):\n",
    "def Cur_Inference(model, sequence):  # model, tokenizer, max_length, device, \n",
    "\n",
    "    '''\n",
    "    this selects which backbone to use, and grabs weights/ config from HF\n",
    "    4 options:\n",
    "      'hyenadna-tiny-1k-seqlen'   # fine-tune on colab ok\n",
    "      'hyenadna-small-32k-seqlen'\n",
    "      'hyenadna-medium-160k-seqlen'  # inference only on colab\n",
    "      'hyenadna-medium-450k-seqlen'  # inference only on colab\n",
    "      'hyenadna-large-1m-seqlen'  # inference only on colab\n",
    "    '''\n",
    "\n",
    "    # you only need to select which model to use here, we'll do the rest!\n",
    "    # pretrained_model_name = 'hyenadna-small-32k-seqlen'\n",
    "\n",
    "    # max_lengths = {\n",
    "    #     'hyenadna-tiny-1k-seqlen': 1024,\n",
    "    #     'hyenadna-small-32k-seqlen': 32768,\n",
    "    #     'hyenadna-medium-160k-seqlen': 160000,\n",
    "    #     'hyenadna-medium-450k-seqlen': 450000,  # T4 up to here\n",
    "    #     'hyenadna-large-1m-seqlen': 1_000_000,  # only A100 (paid tier)\n",
    "    # }\n",
    "\n",
    "\n",
    "    #### Single embedding example ####\n",
    "\n",
    "    # create a sample 450k long, prepare\n",
    "    # sequence = 'ACTG' * int(max_length/4)\n",
    "    tok_seq = tokenizer(sequence)\n",
    "    tok_seq = tok_seq[\"input_ids\"]  # grab ids\n",
    "\n",
    "    # place on device, convert to tensor\n",
    "    tok_seq = torch.LongTensor(tok_seq).unsqueeze(0)  # unsqueeze for batch dim\n",
    "    tok_seq = tok_seq.to(device)\n",
    "\n",
    "    # prep model and forward\n",
    "    # model.to(device)\n",
    "    # model.eval()\n",
    "    with torch.inference_mode():\n",
    "        embeddings = model(tok_seq)\n",
    "\n",
    "    # cls_embedding = embeddings.last_hidden_state[:, 0, :]\n",
    "    # cls_embedding = embeddings[:, 0, :]\n",
    "    \n",
    "    mean_embeddings = embeddings.mean(dim=1) # Mean across the sequence length dimension\n",
    "    mean_embeddings = mean_embeddings.squeeze(0)  # This will change the shape to [256]\n",
    "\n",
    "    \n",
    "    # print(embeddings.shape)  # embeddings here!\n",
    "    # return cls_embedding\n",
    "    return mean_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89af52c7-67c6-4427-b9d4-6f2fe12a34ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Subsequence2Embedding(model, tokenizer, max_length, device, subsequence):\n",
    "def Subsequence2Embedding(subsequence):\n",
    "    # embeddings = My_Inference(model, tokenizer, max_length, device, subsequence)\n",
    "    embeddings = Cur_Inference(model, subsequence)\n",
    "    # print(embeddings.shape)\n",
    "    # return embeddings[0,int(max_length/2),:]\n",
    "    return embeddings  # embeddings[0,0,:]\n",
    "\n",
    "# max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc056b3-d504-495e-852e-2851ad0d2bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_rows_to_csv(csv_Filename, rows):\n",
    "    with open(csv_Filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # writer.writerow(rows)\n",
    "        for row in rows:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c1ea2f-6b84-4308-a4d0-4e018b1d446f",
   "metadata": {},
   "source": [
    "### Main Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d899db1-344c-4812-8392-248e309c12df",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pretrained_model_name = 'hyenadna-small-32k-seqlen'\n",
    "pretrained_model_name = 'hyenadna-medium-160k-seqlen'\n",
    "# pretrained_model_name = 'hyenadna-medium-450k-seqlen'\n",
    "# pretrained_model_name = 'hyenadna-large-1m-seqlen'\n",
    "model, tokenizer, max_length =  get_model_tokenizer_maxlen(pretrained_model_name)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b67207-2b10-4f1d-b209-a401767c91e9",
   "metadata": {},
   "source": [
    "## Load dna segment data file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb6e8b6-7a92-4d7f-9e53-0bf3e3fae92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# pathogenecity_type='noncoding'\n",
    "pathogenecity_type='missense'\n",
    "\n",
    "df=pd.read_csv('dna_segment_'+pathogenecity_type+'.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a73b5a5-247c-4cc8-8dc2-bc2d44e7f9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "now = datetime.now()\n",
    "formatted_time = now.strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "csv_filename = '/home/sunhuaikuan/ondemand/blue_papers/DNA_LLM_REVIEW/preprocess/pathogenecity/pathogenecity_hyena_'+pathogenecity_type+'_'+formatted_time+'.csv'\n",
    "\n",
    "\n",
    "rows=[]\n",
    "for index, row in df.iterrows():      \n",
    "        \n",
    "    y=row['y']\n",
    "\n",
    "    subsequence = row['sequence']\n",
    "    if 'N' in subsequence:\n",
    "        print(\"The character 'N' is present in the string.\")\n",
    "        \n",
    "    embedding = Subsequence2Embedding(subsequence)\n",
    "    # print(embedding.shape)\n",
    "\n",
    "    # feature=np.array(embedding_df.iloc[64])\n",
    "    rows.append(np.append(embedding.cpu().numpy(),  [ y]))\n",
    "\n",
    "\n",
    "    if index > 0 and (index % 2000) == 0:\n",
    "        append_rows_to_csv(csv_filename, rows)\n",
    "        rows=[]\n",
    "        print (f\"index = {index} completed\")\n",
    "        \n",
    "append_rows_to_csv(csv_filename, rows)\n",
    "\n",
    "print(f\"Create File: \"+csv_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93f1c14-0ef8-4efa-84df-c94596ac0b59",
   "metadata": {},
   "source": [
    "### Load CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d6b579-726c-438b-9c2b-1c91b2e81b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_embedding_file(csv_filename):\n",
    "\n",
    "    df=pd.read_csv(csv_filename)\n",
    "    \n",
    "    column_names = [f'{i}' for i in range(1, df.shape[1])]\n",
    "    column_names.extend([ 'y'])\n",
    "    \n",
    "    df.columns = column_names\n",
    "    return df\n",
    "    \n",
    "\n",
    "df = load_embedding_file(csv_filename)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
