{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0d11a89-1cc9-4384-ac3c-ccc24a66f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install genomic_benchmarks\n",
    "# !pip install omegaconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94159a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/48855325/ipykernel_3108526/1965316763.py:7: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/home/sunhuaikuan/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Kernal PyTorch-2.0.1\n",
    "\n",
    "# from gpn.data import GenomeMSA #, Tokenizer\n",
    "# import gpn.model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from transformers import AutoModel #, AutoModelForMaskedLM\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import pickle\n",
    "# import re\n",
    "import os\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "%run hyena_utility.py\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00928314-c642-46b7-841a-401f18320873",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def Cur_Inference(model, tokenizer, max_length, device, sequence):\n",
    "def Cur_Inference(model, sequence):  # model, tokenizer, max_length, device, \n",
    "\n",
    "    '''\n",
    "    this selects which backbone to use, and grabs weights/ config from HF\n",
    "    4 options:\n",
    "      'hyenadna-tiny-1k-seqlen'   # fine-tune on colab ok\n",
    "      'hyenadna-small-32k-seqlen'\n",
    "      'hyenadna-medium-160k-seqlen'  # inference only on colab\n",
    "      'hyenadna-medium-450k-seqlen'  # inference only on colab\n",
    "      'hyenadna-large-1m-seqlen'  # inference only on colab\n",
    "    '''\n",
    "\n",
    "    # you only need to select which model to use here, we'll do the rest!\n",
    "    # pretrained_model_name = 'hyenadna-small-32k-seqlen'\n",
    "\n",
    "    # max_lengths = {\n",
    "    #     'hyenadna-tiny-1k-seqlen': 1024,\n",
    "    #     'hyenadna-small-32k-seqlen': 32768,\n",
    "    #     'hyenadna-medium-160k-seqlen': 160000,\n",
    "    #     'hyenadna-medium-450k-seqlen': 450000,  # T4 up to here\n",
    "    #     'hyenadna-large-1m-seqlen': 1_000_000,  # only A100 (paid tier)\n",
    "    # }\n",
    "\n",
    "\n",
    "    #### Single embedding example ####\n",
    "\n",
    "    # create a sample 450k long, prepare\n",
    "    # sequence = 'ACTG' * int(max_length/4)\n",
    "    tok_seq = tokenizer(sequence)\n",
    "    tok_seq = tok_seq[\"input_ids\"]  # grab ids\n",
    "\n",
    "    # place on device, convert to tensor\n",
    "    tok_seq = torch.LongTensor(tok_seq).unsqueeze(0)  # unsqueeze for batch dim\n",
    "    tok_seq = tok_seq.to(device)\n",
    "\n",
    "    # prep model and forward\n",
    "    # model.to(device)\n",
    "    # model.eval()\n",
    "    with torch.inference_mode():\n",
    "        embeddings = model(tok_seq)\n",
    "\n",
    "    # cls_embedding = embeddings.last_hidden_state[:, 0, :]\n",
    "    # cls_embedding = embeddings[:, 0, :]\n",
    "    \n",
    "    mean_embeddings = embeddings.mean(dim=1) # Mean across the sequence length dimension\n",
    "    mean_embeddings = mean_embeddings.squeeze(0)  # This will change the shape to [256]\n",
    "\n",
    "    \n",
    "    # print(embeddings.shape)  # embeddings here!\n",
    "    # return cls_embedding\n",
    "    return mean_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89af52c7-67c6-4427-b9d4-6f2fe12a34ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Subsequence2Embedding(model, tokenizer, max_length, device, subsequence):\n",
    "def Subsequence2Embedding(subsequence):\n",
    "    # embeddings = My_Inference(model, tokenizer, max_length, device, subsequence)\n",
    "    embeddings = Cur_Inference(model, subsequence)\n",
    "    # print(embeddings.shape)\n",
    "    # return embeddings[0,int(max_length/2),:]\n",
    "    return embeddings  # embeddings[0,0,:]\n",
    "\n",
    "# max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bc056b3-d504-495e-852e-2851ad0d2bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_rows_to_csv(csv_Filename, rows):\n",
    "    with open(csv_Filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # writer.writerow(rows)\n",
    "        for row in rows:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c1ea2f-6b84-4308-a4d0-4e018b1d446f",
   "metadata": {},
   "source": [
    "### Main Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d899db1-344c-4812-8392-248e309c12df",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Git LFS initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'hyenadna-medium-160k-seqlen'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights ok!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HyenaDNAModel(\n",
       "  (backbone): LMBackbone(\n",
       "    (embeddings): GPT2Embeddings(\n",
       "      (word_embeddings): Embedding(16, 256)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): Block(\n",
       "        (mixer): HyenaOperator(\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (in_proj): Linear(in_features=256, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (short_filter): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(2,), groups=768)\n",
       "          (filter_fn): HyenaFilter(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb): PositionalEmbedding()\n",
       "            (implicit_filter): Sequential(\n",
       "              (0): Linear(in_features=5, out_features=64, bias=True)\n",
       "              (1): Sin()\n",
       "              (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (3): Sin()\n",
       "              (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (5): Sin()\n",
       "              (6): Linear(in_features=64, out_features=256, bias=False)\n",
       "            )\n",
       "            (modulation): ExponentialModulation()\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1-7): 7 x Block(\n",
       "        (mixer): HyenaOperator(\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (in_proj): Linear(in_features=256, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (short_filter): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(2,), groups=768)\n",
       "          (filter_fn): HyenaFilter(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb): PositionalEmbedding()\n",
       "            (implicit_filter): Sequential(\n",
       "              (0): Linear(in_features=5, out_features=64, bias=True)\n",
       "              (1): Sin()\n",
       "              (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (3): Sin()\n",
       "              (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (5): Sin()\n",
       "              (6): Linear(in_features=64, out_features=256, bias=False)\n",
       "            )\n",
       "            (modulation): ExponentialModulation()\n",
       "          )\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (drop_f): Dropout(p=0.0, inplace=False)\n",
       "    (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = 'hyenadna-small-32k-seqlen'\n",
    "pretrained_model_name = 'hyenadna-medium-160k-seqlen'\n",
    "# pretrained_model_name = 'hyenadna-medium-450k-seqlen'\n",
    "# pretrained_model_name = 'hyenadna-large-1m-seqlen'\n",
    "model, tokenizer, max_length =  get_model_tokenizer_maxlen(pretrained_model_name)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b67207-2b10-4f1d-b209-a401767c91e9",
   "metadata": {},
   "source": [
    "## Load dna segment data file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeb6e8b6-7a92-4d7f-9e53-0bf3e3fae92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCCTGTCCAGTCCCGTCCCCGGCGCGGCCCGCGCGCTCCTCCGCCG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCTGTCCAGTCCCGTCCCCGGCGCGGCCCGCGCGCTCCTCCGCCGC...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GTCCCGTCCCCGGCGCGGCCCGCGCGCTCCTCCGCCGCCTCTCGCC...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CGGCGCGGCCCGCGCGCTCCTCCGCCGCCTCTCGCCTGCGCCATGG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CGCGGCCCGCGCGCTCCTCCGCCGCCTCTCGCCTGCGCCATGGCCG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560183</th>\n",
       "      <td>ACAGCTTTCAGTGCAAAGGAAGGAAGAGCTTCTCCGGAGAGCGGGA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560184</th>\n",
       "      <td>CAGCTTTCAGTGCAAAGGAAGGAAGAGCTTCTCCGGAGAGCGGGAA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560185</th>\n",
       "      <td>TCCGGAGAGCGGGAATATTCTCTTGCACAGCTGGACTGTAATCATC...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560186</th>\n",
       "      <td>CGGAGAGCGGGAATATTCTCTTGCACAGCTGGACTGTAATCATCGC...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560187</th>\n",
       "      <td>AGAGCGGGAATATTCTCTTGCACAGCTGGACTGTAATCATCGCTGT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560188 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sequence  y\n",
       "0       TCCTGTCCAGTCCCGTCCCCGGCGCGGCCCGCGCGCTCCTCCGCCG...  0\n",
       "1       CCTGTCCAGTCCCGTCCCCGGCGCGGCCCGCGCGCTCCTCCGCCGC...  0\n",
       "2       GTCCCGTCCCCGGCGCGGCCCGCGCGCTCCTCCGCCGCCTCTCGCC...  0\n",
       "3       CGGCGCGGCCCGCGCGCTCCTCCGCCGCCTCTCGCCTGCGCCATGG...  0\n",
       "4       CGCGGCCCGCGCGCTCCTCCGCCGCCTCTCGCCTGCGCCATGGCCG...  0\n",
       "...                                                   ... ..\n",
       "560183  ACAGCTTTCAGTGCAAAGGAAGGAAGAGCTTCTCCGGAGAGCGGGA...  0\n",
       "560184  CAGCTTTCAGTGCAAAGGAAGGAAGAGCTTCTCCGGAGAGCGGGAA...  0\n",
       "560185  TCCGGAGAGCGGGAATATTCTCTTGCACAGCTGGACTGTAATCATC...  0\n",
       "560186  CGGAGAGCGGGAATATTCTCTTGCACAGCTGGACTGTAATCATCGC...  0\n",
       "560187  AGAGCGGGAATATTCTCTTGCACAGCTGGACTGTAATCATCGCTGT...  0\n",
       "\n",
       "[560188 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# pathogenecity_type='noncoding'\n",
    "pathogenecity_type='missense'\n",
    "\n",
    "df=pd.read_csv('dna_segment_'+pathogenecity_type+'.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a73b5a5-247c-4cc8-8dc2-bc2d44e7f9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index = 2000 completed\n",
      "index = 4000 completed\n",
      "index = 6000 completed\n",
      "index = 8000 completed\n",
      "index = 10000 completed\n",
      "index = 12000 completed\n",
      "index = 14000 completed\n",
      "index = 16000 completed\n",
      "index = 18000 completed\n",
      "index = 20000 completed\n",
      "index = 22000 completed\n",
      "index = 24000 completed\n",
      "index = 26000 completed\n",
      "index = 28000 completed\n",
      "index = 30000 completed\n",
      "index = 32000 completed\n",
      "index = 34000 completed\n",
      "index = 36000 completed\n",
      "index = 38000 completed\n",
      "index = 40000 completed\n",
      "index = 42000 completed\n",
      "index = 44000 completed\n",
      "index = 46000 completed\n",
      "index = 48000 completed\n",
      "index = 50000 completed\n",
      "index = 52000 completed\n",
      "index = 54000 completed\n",
      "index = 56000 completed\n",
      "index = 58000 completed\n",
      "index = 60000 completed\n",
      "index = 62000 completed\n",
      "index = 64000 completed\n",
      "index = 66000 completed\n",
      "index = 68000 completed\n",
      "index = 70000 completed\n",
      "index = 72000 completed\n",
      "index = 74000 completed\n",
      "index = 76000 completed\n",
      "index = 78000 completed\n",
      "index = 80000 completed\n",
      "index = 82000 completed\n",
      "index = 84000 completed\n",
      "index = 86000 completed\n",
      "index = 88000 completed\n",
      "index = 90000 completed\n",
      "index = 92000 completed\n",
      "index = 94000 completed\n",
      "index = 96000 completed\n",
      "index = 98000 completed\n",
      "index = 100000 completed\n",
      "index = 102000 completed\n",
      "index = 104000 completed\n",
      "index = 106000 completed\n",
      "index = 108000 completed\n",
      "index = 110000 completed\n",
      "index = 112000 completed\n",
      "index = 114000 completed\n",
      "index = 116000 completed\n",
      "index = 118000 completed\n",
      "index = 120000 completed\n",
      "index = 122000 completed\n",
      "index = 124000 completed\n",
      "index = 126000 completed\n",
      "index = 128000 completed\n",
      "index = 130000 completed\n",
      "index = 132000 completed\n",
      "index = 134000 completed\n",
      "index = 136000 completed\n",
      "index = 138000 completed\n",
      "index = 140000 completed\n",
      "index = 142000 completed\n",
      "index = 144000 completed\n",
      "index = 146000 completed\n",
      "index = 148000 completed\n",
      "index = 150000 completed\n",
      "index = 152000 completed\n",
      "index = 154000 completed\n",
      "index = 156000 completed\n",
      "index = 158000 completed\n",
      "index = 160000 completed\n",
      "index = 162000 completed\n",
      "index = 164000 completed\n",
      "index = 166000 completed\n",
      "index = 168000 completed\n",
      "index = 170000 completed\n",
      "index = 172000 completed\n",
      "index = 174000 completed\n",
      "index = 176000 completed\n",
      "index = 178000 completed\n",
      "index = 180000 completed\n",
      "index = 182000 completed\n",
      "index = 184000 completed\n",
      "index = 186000 completed\n",
      "index = 188000 completed\n",
      "index = 190000 completed\n",
      "index = 192000 completed\n",
      "index = 194000 completed\n",
      "index = 196000 completed\n",
      "index = 198000 completed\n",
      "index = 200000 completed\n",
      "index = 202000 completed\n",
      "index = 204000 completed\n",
      "index = 206000 completed\n",
      "index = 208000 completed\n",
      "index = 210000 completed\n",
      "index = 212000 completed\n",
      "index = 214000 completed\n",
      "index = 216000 completed\n",
      "index = 218000 completed\n",
      "index = 220000 completed\n",
      "index = 222000 completed\n",
      "index = 224000 completed\n",
      "index = 226000 completed\n",
      "index = 228000 completed\n",
      "index = 230000 completed\n",
      "index = 232000 completed\n",
      "index = 234000 completed\n",
      "index = 236000 completed\n",
      "index = 238000 completed\n",
      "index = 240000 completed\n",
      "index = 242000 completed\n",
      "index = 244000 completed\n",
      "index = 246000 completed\n",
      "index = 248000 completed\n",
      "index = 250000 completed\n",
      "index = 252000 completed\n",
      "index = 254000 completed\n",
      "index = 256000 completed\n",
      "index = 258000 completed\n",
      "index = 260000 completed\n",
      "index = 262000 completed\n",
      "index = 264000 completed\n",
      "index = 266000 completed\n",
      "index = 268000 completed\n",
      "index = 270000 completed\n",
      "index = 272000 completed\n",
      "index = 274000 completed\n",
      "index = 276000 completed\n",
      "index = 278000 completed\n",
      "index = 280000 completed\n",
      "index = 282000 completed\n",
      "index = 284000 completed\n",
      "index = 286000 completed\n",
      "index = 288000 completed\n",
      "index = 290000 completed\n",
      "index = 292000 completed\n",
      "index = 294000 completed\n",
      "index = 296000 completed\n",
      "index = 298000 completed\n",
      "index = 300000 completed\n",
      "index = 302000 completed\n",
      "index = 304000 completed\n",
      "index = 306000 completed\n",
      "index = 308000 completed\n",
      "index = 310000 completed\n",
      "index = 312000 completed\n",
      "index = 314000 completed\n",
      "index = 316000 completed\n",
      "index = 318000 completed\n",
      "index = 320000 completed\n",
      "index = 322000 completed\n",
      "index = 324000 completed\n",
      "index = 326000 completed\n",
      "index = 328000 completed\n",
      "index = 330000 completed\n",
      "index = 332000 completed\n",
      "index = 334000 completed\n",
      "index = 336000 completed\n",
      "index = 338000 completed\n",
      "index = 340000 completed\n",
      "index = 342000 completed\n",
      "index = 344000 completed\n",
      "index = 346000 completed\n",
      "index = 348000 completed\n",
      "index = 350000 completed\n",
      "index = 352000 completed\n",
      "index = 354000 completed\n",
      "index = 356000 completed\n",
      "index = 358000 completed\n",
      "index = 360000 completed\n",
      "index = 362000 completed\n",
      "index = 364000 completed\n",
      "index = 366000 completed\n",
      "index = 368000 completed\n",
      "index = 370000 completed\n",
      "index = 372000 completed\n",
      "index = 374000 completed\n",
      "index = 376000 completed\n",
      "index = 378000 completed\n",
      "index = 380000 completed\n",
      "index = 382000 completed\n",
      "index = 384000 completed\n",
      "index = 386000 completed\n",
      "index = 388000 completed\n",
      "index = 390000 completed\n",
      "index = 392000 completed\n",
      "index = 394000 completed\n",
      "index = 396000 completed\n",
      "index = 398000 completed\n",
      "index = 400000 completed\n",
      "index = 402000 completed\n",
      "index = 404000 completed\n",
      "index = 406000 completed\n",
      "index = 408000 completed\n",
      "index = 410000 completed\n",
      "index = 412000 completed\n",
      "index = 414000 completed\n",
      "index = 416000 completed\n",
      "index = 418000 completed\n",
      "index = 420000 completed\n",
      "index = 422000 completed\n",
      "index = 424000 completed\n",
      "index = 426000 completed\n",
      "index = 428000 completed\n",
      "index = 430000 completed\n",
      "index = 432000 completed\n",
      "index = 434000 completed\n",
      "index = 436000 completed\n",
      "index = 438000 completed\n",
      "index = 440000 completed\n",
      "index = 442000 completed\n",
      "index = 444000 completed\n",
      "index = 446000 completed\n",
      "index = 448000 completed\n",
      "index = 450000 completed\n",
      "index = 452000 completed\n",
      "index = 454000 completed\n",
      "index = 456000 completed\n",
      "index = 458000 completed\n",
      "index = 460000 completed\n",
      "index = 462000 completed\n",
      "index = 464000 completed\n",
      "index = 466000 completed\n",
      "index = 468000 completed\n",
      "index = 470000 completed\n",
      "index = 472000 completed\n",
      "index = 474000 completed\n",
      "index = 476000 completed\n",
      "index = 478000 completed\n",
      "index = 480000 completed\n",
      "index = 482000 completed\n",
      "index = 484000 completed\n",
      "index = 486000 completed\n",
      "index = 488000 completed\n",
      "index = 490000 completed\n",
      "index = 492000 completed\n",
      "index = 494000 completed\n",
      "index = 496000 completed\n",
      "index = 498000 completed\n",
      "index = 500000 completed\n",
      "index = 502000 completed\n",
      "index = 504000 completed\n",
      "index = 506000 completed\n",
      "index = 508000 completed\n",
      "index = 510000 completed\n",
      "index = 512000 completed\n",
      "index = 514000 completed\n",
      "index = 516000 completed\n",
      "index = 518000 completed\n",
      "index = 520000 completed\n",
      "index = 522000 completed\n",
      "index = 524000 completed\n",
      "index = 526000 completed\n",
      "index = 528000 completed\n",
      "index = 530000 completed\n",
      "index = 532000 completed\n",
      "index = 534000 completed\n",
      "index = 536000 completed\n",
      "index = 538000 completed\n",
      "index = 540000 completed\n",
      "index = 542000 completed\n",
      "index = 544000 completed\n",
      "index = 546000 completed\n",
      "index = 548000 completed\n",
      "index = 550000 completed\n",
      "index = 552000 completed\n",
      "index = 554000 completed\n",
      "index = 556000 completed\n",
      "index = 558000 completed\n",
      "index = 560000 completed\n",
      "Create File: /home/sunhuaikuan/ondemand/blue_papers/DNA_LLM_REVIEW/preprocess/pathogenecity/pathogenecity_hyena_missense_24-10-29-21-12-23.csv\n",
      "CPU times: user 1h 12min 11s, sys: 2.11 s, total: 1h 12min 13s\n",
      "Wall time: 1h 15min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "now = datetime.now()\n",
    "formatted_time = now.strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "csv_filename = '/home/sunhuaikuan/ondemand/blue_papers/DNA_LLM_REVIEW/preprocess/pathogenecity/pathogenecity_hyena_'+pathogenecity_type+'_'+formatted_time+'.csv'\n",
    "\n",
    "\n",
    "rows=[]\n",
    "for index, row in df.iterrows():      \n",
    "        \n",
    "    y=row['y']\n",
    "\n",
    "    subsequence = row['sequence']\n",
    "    if 'N' in subsequence:\n",
    "        print(\"The character 'N' is present in the string.\")\n",
    "        \n",
    "    embedding = Subsequence2Embedding(subsequence)\n",
    "    # print(embedding.shape)\n",
    "\n",
    "    # feature=np.array(embedding_df.iloc[64])\n",
    "    rows.append(np.append(embedding.cpu().numpy(),  [ y]))\n",
    "\n",
    "\n",
    "    if index > 0 and (index % 2000) == 0:\n",
    "        append_rows_to_csv(csv_filename, rows)\n",
    "        rows=[]\n",
    "        print (f\"index = {index} completed\")\n",
    "        \n",
    "append_rows_to_csv(csv_filename, rows)\n",
    "\n",
    "print(f\"Create File: \"+csv_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93f1c14-0ef8-4efa-84df-c94596ac0b59",
   "metadata": {},
   "source": [
    "### Load CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90d6b579-726c-438b-9c2b-1c91b2e81b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.165760</td>\n",
       "      <td>-0.775195</td>\n",
       "      <td>-0.615126</td>\n",
       "      <td>-0.971025</td>\n",
       "      <td>-1.913011</td>\n",
       "      <td>-0.801352</td>\n",
       "      <td>1.159068</td>\n",
       "      <td>-0.685350</td>\n",
       "      <td>-0.653669</td>\n",
       "      <td>-0.096608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310376</td>\n",
       "      <td>0.456689</td>\n",
       "      <td>-1.007345</td>\n",
       "      <td>-1.606998</td>\n",
       "      <td>-1.618424</td>\n",
       "      <td>1.240193</td>\n",
       "      <td>0.473080</td>\n",
       "      <td>0.256684</td>\n",
       "      <td>-0.935613</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.137474</td>\n",
       "      <td>-0.788819</td>\n",
       "      <td>-0.607544</td>\n",
       "      <td>-0.950123</td>\n",
       "      <td>-1.989848</td>\n",
       "      <td>-0.770073</td>\n",
       "      <td>1.134804</td>\n",
       "      <td>-0.698152</td>\n",
       "      <td>-0.754873</td>\n",
       "      <td>-0.122203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384797</td>\n",
       "      <td>0.452388</td>\n",
       "      <td>-1.012480</td>\n",
       "      <td>-1.564671</td>\n",
       "      <td>-1.634364</td>\n",
       "      <td>1.239771</td>\n",
       "      <td>0.449268</td>\n",
       "      <td>0.295268</td>\n",
       "      <td>-0.885379</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.057533</td>\n",
       "      <td>-0.791069</td>\n",
       "      <td>-0.616168</td>\n",
       "      <td>-0.836501</td>\n",
       "      <td>-1.967007</td>\n",
       "      <td>-0.733224</td>\n",
       "      <td>1.111632</td>\n",
       "      <td>-0.683399</td>\n",
       "      <td>-0.791432</td>\n",
       "      <td>-0.109900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378847</td>\n",
       "      <td>0.415309</td>\n",
       "      <td>-1.069680</td>\n",
       "      <td>-1.575123</td>\n",
       "      <td>-1.551741</td>\n",
       "      <td>1.206547</td>\n",
       "      <td>0.393325</td>\n",
       "      <td>0.321506</td>\n",
       "      <td>-0.889493</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.059399</td>\n",
       "      <td>-0.755095</td>\n",
       "      <td>-0.629050</td>\n",
       "      <td>-0.842900</td>\n",
       "      <td>-1.939599</td>\n",
       "      <td>-0.740944</td>\n",
       "      <td>1.113892</td>\n",
       "      <td>-0.703221</td>\n",
       "      <td>-0.720661</td>\n",
       "      <td>-0.143797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358683</td>\n",
       "      <td>0.422459</td>\n",
       "      <td>-1.065204</td>\n",
       "      <td>-1.585578</td>\n",
       "      <td>-1.554344</td>\n",
       "      <td>1.212077</td>\n",
       "      <td>0.379778</td>\n",
       "      <td>0.301417</td>\n",
       "      <td>-0.937824</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.071139</td>\n",
       "      <td>-0.729199</td>\n",
       "      <td>-0.606902</td>\n",
       "      <td>-0.829894</td>\n",
       "      <td>-1.892584</td>\n",
       "      <td>-0.728332</td>\n",
       "      <td>1.110167</td>\n",
       "      <td>-0.698343</td>\n",
       "      <td>-0.722920</td>\n",
       "      <td>-0.116437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378509</td>\n",
       "      <td>0.431281</td>\n",
       "      <td>-1.067796</td>\n",
       "      <td>-1.594991</td>\n",
       "      <td>-1.537138</td>\n",
       "      <td>1.223300</td>\n",
       "      <td>0.392155</td>\n",
       "      <td>0.332627</td>\n",
       "      <td>-0.926249</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560182</th>\n",
       "      <td>-0.148571</td>\n",
       "      <td>-0.792183</td>\n",
       "      <td>-0.521046</td>\n",
       "      <td>-0.929553</td>\n",
       "      <td>-0.910005</td>\n",
       "      <td>-0.921572</td>\n",
       "      <td>1.201978</td>\n",
       "      <td>-0.803206</td>\n",
       "      <td>-0.155598</td>\n",
       "      <td>0.485060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492746</td>\n",
       "      <td>0.479940</td>\n",
       "      <td>-0.994844</td>\n",
       "      <td>-1.504475</td>\n",
       "      <td>-1.514782</td>\n",
       "      <td>1.257350</td>\n",
       "      <td>0.534343</td>\n",
       "      <td>0.462038</td>\n",
       "      <td>-0.826865</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560183</th>\n",
       "      <td>-0.125961</td>\n",
       "      <td>-0.783654</td>\n",
       "      <td>-0.528770</td>\n",
       "      <td>-0.899592</td>\n",
       "      <td>-0.896188</td>\n",
       "      <td>-0.903221</td>\n",
       "      <td>1.209326</td>\n",
       "      <td>-0.833910</td>\n",
       "      <td>-0.120305</td>\n",
       "      <td>0.475503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498197</td>\n",
       "      <td>0.465864</td>\n",
       "      <td>-1.018678</td>\n",
       "      <td>-1.494310</td>\n",
       "      <td>-1.495789</td>\n",
       "      <td>1.259540</td>\n",
       "      <td>0.528486</td>\n",
       "      <td>0.434672</td>\n",
       "      <td>-0.848990</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560184</th>\n",
       "      <td>-0.030807</td>\n",
       "      <td>-0.759196</td>\n",
       "      <td>-0.487905</td>\n",
       "      <td>-0.758114</td>\n",
       "      <td>-0.790885</td>\n",
       "      <td>-0.849533</td>\n",
       "      <td>1.267575</td>\n",
       "      <td>-0.909575</td>\n",
       "      <td>-0.073220</td>\n",
       "      <td>0.375187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557983</td>\n",
       "      <td>0.488931</td>\n",
       "      <td>-0.927740</td>\n",
       "      <td>-1.476444</td>\n",
       "      <td>-1.447461</td>\n",
       "      <td>1.198302</td>\n",
       "      <td>0.481330</td>\n",
       "      <td>0.553817</td>\n",
       "      <td>-0.920865</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560185</th>\n",
       "      <td>-0.010619</td>\n",
       "      <td>-0.762725</td>\n",
       "      <td>-0.473467</td>\n",
       "      <td>-0.705690</td>\n",
       "      <td>-0.751864</td>\n",
       "      <td>-0.809319</td>\n",
       "      <td>1.249628</td>\n",
       "      <td>-0.890070</td>\n",
       "      <td>-0.093685</td>\n",
       "      <td>0.397889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617771</td>\n",
       "      <td>0.488129</td>\n",
       "      <td>-0.951747</td>\n",
       "      <td>-1.440598</td>\n",
       "      <td>-1.383776</td>\n",
       "      <td>1.210845</td>\n",
       "      <td>0.476213</td>\n",
       "      <td>0.580937</td>\n",
       "      <td>-0.887212</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560186</th>\n",
       "      <td>-0.077911</td>\n",
       "      <td>-0.780443</td>\n",
       "      <td>-0.469067</td>\n",
       "      <td>-0.797718</td>\n",
       "      <td>-0.721153</td>\n",
       "      <td>-0.887560</td>\n",
       "      <td>1.249541</td>\n",
       "      <td>-0.892740</td>\n",
       "      <td>-0.050044</td>\n",
       "      <td>0.430056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553733</td>\n",
       "      <td>0.475915</td>\n",
       "      <td>-0.893670</td>\n",
       "      <td>-1.478640</td>\n",
       "      <td>-1.443776</td>\n",
       "      <td>1.221623</td>\n",
       "      <td>0.532454</td>\n",
       "      <td>0.532317</td>\n",
       "      <td>-0.876381</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560187 rows × 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               1         2         3         4         5         6         7  \\\n",
       "0      -0.165760 -0.775195 -0.615126 -0.971025 -1.913011 -0.801352  1.159068   \n",
       "1      -0.137474 -0.788819 -0.607544 -0.950123 -1.989848 -0.770073  1.134804   \n",
       "2      -0.057533 -0.791069 -0.616168 -0.836501 -1.967007 -0.733224  1.111632   \n",
       "3      -0.059399 -0.755095 -0.629050 -0.842900 -1.939599 -0.740944  1.113892   \n",
       "4      -0.071139 -0.729199 -0.606902 -0.829894 -1.892584 -0.728332  1.110167   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "560182 -0.148571 -0.792183 -0.521046 -0.929553 -0.910005 -0.921572  1.201978   \n",
       "560183 -0.125961 -0.783654 -0.528770 -0.899592 -0.896188 -0.903221  1.209326   \n",
       "560184 -0.030807 -0.759196 -0.487905 -0.758114 -0.790885 -0.849533  1.267575   \n",
       "560185 -0.010619 -0.762725 -0.473467 -0.705690 -0.751864 -0.809319  1.249628   \n",
       "560186 -0.077911 -0.780443 -0.469067 -0.797718 -0.721153 -0.887560  1.249541   \n",
       "\n",
       "               8         9        10  ...       248       249       250  \\\n",
       "0      -0.685350 -0.653669 -0.096608  ...  0.310376  0.456689 -1.007345   \n",
       "1      -0.698152 -0.754873 -0.122203  ...  0.384797  0.452388 -1.012480   \n",
       "2      -0.683399 -0.791432 -0.109900  ...  0.378847  0.415309 -1.069680   \n",
       "3      -0.703221 -0.720661 -0.143797  ...  0.358683  0.422459 -1.065204   \n",
       "4      -0.698343 -0.722920 -0.116437  ...  0.378509  0.431281 -1.067796   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "560182 -0.803206 -0.155598  0.485060  ...  0.492746  0.479940 -0.994844   \n",
       "560183 -0.833910 -0.120305  0.475503  ...  0.498197  0.465864 -1.018678   \n",
       "560184 -0.909575 -0.073220  0.375187  ...  0.557983  0.488931 -0.927740   \n",
       "560185 -0.890070 -0.093685  0.397889  ...  0.617771  0.488129 -0.951747   \n",
       "560186 -0.892740 -0.050044  0.430056  ...  0.553733  0.475915 -0.893670   \n",
       "\n",
       "             251       252       253       254       255       256    y  \n",
       "0      -1.606998 -1.618424  1.240193  0.473080  0.256684 -0.935613  0.0  \n",
       "1      -1.564671 -1.634364  1.239771  0.449268  0.295268 -0.885379  0.0  \n",
       "2      -1.575123 -1.551741  1.206547  0.393325  0.321506 -0.889493  0.0  \n",
       "3      -1.585578 -1.554344  1.212077  0.379778  0.301417 -0.937824  0.0  \n",
       "4      -1.594991 -1.537138  1.223300  0.392155  0.332627 -0.926249  0.0  \n",
       "...          ...       ...       ...       ...       ...       ...  ...  \n",
       "560182 -1.504475 -1.514782  1.257350  0.534343  0.462038 -0.826865  0.0  \n",
       "560183 -1.494310 -1.495789  1.259540  0.528486  0.434672 -0.848990  0.0  \n",
       "560184 -1.476444 -1.447461  1.198302  0.481330  0.553817 -0.920865  0.0  \n",
       "560185 -1.440598 -1.383776  1.210845  0.476213  0.580937 -0.887212  0.0  \n",
       "560186 -1.478640 -1.443776  1.221623  0.532454  0.532317 -0.876381  0.0  \n",
       "\n",
       "[560187 rows x 257 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# csv_filename='/home/sunhuaikuan/ondemand/blue_papers/DNA_LLM_REVIEW/preprocess/pathogenecity/pathogenecity_hyena_noncoding_24-10-29-16-31-33.csv'\n",
    "\n",
    "def load_embedding_file(csv_filename):\n",
    "\n",
    "    df=pd.read_csv(csv_filename)\n",
    "    \n",
    "    column_names = [f'{i}' for i in range(1, df.shape[1])]\n",
    "    column_names.extend([ 'y'])\n",
    "    \n",
    "    df.columns = column_names\n",
    "    return df\n",
    "    \n",
    "\n",
    "df = load_embedding_file(csv_filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc71bbe-8521-4270-bae4-58f80231df2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-2.0.1",
   "language": "python",
   "name": "pytorch-2.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
