{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5d00d8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Kernal PyTorch-1.7.1\n",
    "# using Kernal PyTorch-1.7.1\n",
    "# using Kernal PyTorch-1.7.1 \n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit # train_test_split, \n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%run utility.py\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b16e00d-5625-4743-814b-9080b51d3e16",
   "metadata": {},
   "source": [
    "### Main Homo-Sapiens Classification Algorightm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86e000d",
   "metadata": {},
   "source": [
    "### Build ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "537d2740",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the MLP model (from previous examples)\n",
    "class TwoLayerMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1,hidden_size2, num_classes):\n",
    "        super(TwoLayerMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# # Model parameters\n",
    "# input_size = 768\n",
    "# hidden_size1 = 384\n",
    "# hidden_size2 = 64\n",
    "# num_classes = 7\n",
    "# num_epochs = 10\n",
    "# batch_size = 32\n",
    "# learning_rate = 0.001\n",
    "\n",
    "\n",
    "# # Initialize the model and move it to GPU if available\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = TwoLayerMLP(input_size, hidden_size1,hidden_size2,  num_classes).to(device)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "        \n",
    "# criterion = nn.BCELoss()\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor)\n",
    "# criterion = nn.BCELoss(weight=class_weights_tensor)\n",
    "\n",
    "# Define Matthews correlation coefficient as a custom loss function\n",
    "# class MatthewsCorrelationCoefficientLoss(nn.Module):\n",
    "#     def forward(self, y_pred, y_true):\n",
    "#         mcc = 1 - matthews_corrcoef(y_true.cpu().detach().numpy(), torch.round(y_pred).cpu().detach().numpy())\n",
    "#         return torch.tensor(mcc, dtype=torch.float32, requires_grad=True)\n",
    "# criterion = MatthewsCorrelationCoefficientLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66875217-839f-4bb6-9622-53aec45d486b",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "302b9866-faae-47a0-a772-b9073c0f7989",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training and validation loop\n",
    "\n",
    "def  trainModel(model, train_loader, val_loader):\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()  # Zero the parameter gradients\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, targets)  # Compute loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update parameters\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)  # Move data to GPU\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "    \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = correct / total\n",
    "    \n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy * 100:.2f}%')\n",
    "    \n",
    "    \n",
    "    print('Training completed.')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e5e310-9d34-41bd-86ea-21e95172deab",
   "metadata": {},
   "source": [
    "### Overall Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beb3ce1e-39ae-4e35-bb88-bf74ff4f1efb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Overall_Evaluate(model, test_loader):\n",
    "    # Evaluation on test data\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)  # Move data to GPU\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy on test data: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ede763-e03d-432f-8823-269cf82cb549",
   "metadata": {},
   "source": [
    "### Accuracty Evaluation Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e7a93a4-fd5c-421a-a573-b70daf1b306b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def Breakdown_Evaluate(model, test_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    class_correct = [0] * num_classes\n",
    "    class_total = [0] * num_classes\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)  # Move data to GPU\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Update total count for each class\n",
    "            for i in range(targets.size(0)):\n",
    "                label = targets[i]\n",
    "                class_total[label] += 1\n",
    "                class_correct[label] += (predicted[i] == label).item()\n",
    "\n",
    "    acc_data=[]\n",
    "    \n",
    "    # Calculate and print accuracy for each class\n",
    "    for i in range(num_classes):\n",
    "        if class_total[i] > 0:  # Avoid division by zero\n",
    "            accuracy = class_correct[i] / class_total[i]\n",
    "            print(f'Accuracy of class {i}: {accuracy * 100:.2f}%')\n",
    "            acc_data.append(accuracy)\n",
    "        else:\n",
    "            print(f'No samples for class {i} in the test set.')\n",
    "\n",
    "    return acc_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e081f1e-371e-41cc-a8cc-c806c6eb8931",
   "metadata": {},
   "source": [
    "### AUC(Area Under the Curve) Evaluation Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6dfa48b-61ef-4a23-a562-1ab4e07d5e80",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def Breakdown_Evaluate_AUC(model, test_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_targets = []\n",
    "    all_outputs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)  # Move data to GPU\n",
    "            \n",
    "            # Get model outputs and apply softmax to get class probabilities\n",
    "            outputs = model(inputs)\n",
    "            probabilities = F.softmax(outputs, dim=1)  # Probabilities for each class\n",
    "            \n",
    "            # Collect all targets and probabilities\n",
    "            all_targets.append(targets.cpu())\n",
    "            all_outputs.append(probabilities.cpu())\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    all_targets = torch.cat(all_targets)\n",
    "    all_outputs = torch.cat(all_outputs)\n",
    "\n",
    "    auc_data = []\n",
    "    \n",
    "    # Compute AUC for each class (one-vs-rest)\n",
    "    for i in range(num_classes):\n",
    "        # Binarize the targets for class 'i'\n",
    "        binarized_targets = (all_targets == i).int()  # 1 if target is 'i', else 0\n",
    "        \n",
    "        # Get the predicted probabilities for class 'i'\n",
    "        class_probabilities = all_outputs[:, i]\n",
    "        \n",
    "        # Compute AUC for class 'i'\n",
    "        if len(set(binarized_targets.tolist())) > 1:  # Ensure we have both classes in the test set\n",
    "            auc = roc_auc_score(binarized_targets, class_probabilities)\n",
    "            print(f'AUC of class {i}: {auc:.2f}')\n",
    "            auc_data.append(auc)\n",
    "            \n",
    "        else:\n",
    "            print(f'Not enough data for class {i} to compute AUC.')\n",
    "    \n",
    "    return auc_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d263a6-90bf-4e88-9273-e824bc76208d",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f2cbe9b-5593-47fe-a1a2-9c0acfb298a3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "hidden_size1 = 120\n",
    "hidden_size2 = 64\n",
    "num_classes = 7\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b37afc-97da-496d-bbae-02d801f54b83",
   "metadata": {},
   "source": [
    "### Accuracy Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "467a0f64-b93d-4140-8322-05cb5aadca1e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "columns = [f'class{i}' for i in range(7)]  \n",
    "df_acc_nt = pd.DataFrame(columns=columns)\n",
    "df_acc_gpn = pd.DataFrame(columns=columns)\n",
    "df_acc_dnabert2 = pd.DataFrame(columns=columns)\n",
    "df_acc_hyena = pd.DataFrame(columns=columns)\n",
    "df_acc_caduceus = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd777935-0bc4-4189-a45a-3df59826a78c",
   "metadata": {},
   "source": [
    "### T-Test Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "976c63a7-cdd5-4a74-9686-caf1b0964360",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "columns = [f'class{i}' for i in range(7)]  \n",
    "df_auc_nt = pd.DataFrame(columns=columns)\n",
    "df_auc_gpn = pd.DataFrame(columns=columns)\n",
    "df_auc_dnabert2 = pd.DataFrame(columns=columns)\n",
    "df_auc_hyena = pd.DataFrame(columns=columns)\n",
    "df_auc_caduceus = pd.DataFrame(columns=columns)\n",
    "\n",
    "runcount=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1769521e-46f8-4d15-9bd6-faa097c220b8",
   "metadata": {},
   "source": [
    "### split dataframe into 3 parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6099ccc-0fac-4caa-bcca-239e1c4d57a2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def run_test(runcount, model, train_loader,val_loader, test_loader, df_acc, df_auc):\n",
    "    \n",
    "    # df_acc=df_acc.drop(df_acc.index)\n",
    "    # df_auc= df_auc.drop(df_auc.index)\n",
    "    \n",
    "    for i in range(0, runcount):\n",
    "        # train_loader,val_loader,test_loader =prepare_dataloader(data_array)\n",
    "        model = trainModel(model, train_loader,val_loader)\n",
    "        \n",
    "        Overall_Evaluate(model, test_loader)\n",
    "    \n",
    "        acc_data=Breakdown_Evaluate(model,test_loader)\n",
    "        df_acc.loc[len(df_acc)] = acc_data  \n",
    "        \n",
    "        auc_data = Breakdown_Evaluate_AUC(model,test_loader)\n",
    "        df_auc.loc[len(df_auc)] = auc_data\n",
    "\n",
    "    return df_acc, df_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6024d0c-c387-4c0d-b711-75446b4aea69",
   "metadata": {},
   "source": [
    "### Filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ce77982-db30-49ee-98b4-5e8f46be10a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(dfA,dfB):\n",
    "    return dfA[dfA[['ROWID']].isin(dfB[['ROWID']].to_dict(orient='list')).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ab2cd2-e089-4ce4-aa18-235158d567d0",
   "metadata": {},
   "source": [
    "### Dataframe to dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8894486-6f84-4beb-9ade-cdced6c39398",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def df2dataloader(df_train, df_val, df_test):\n",
    "\n",
    "    X_train, y_train = df_train.iloc[:, :-1].values, df_train.iloc[:, -1].values\n",
    "    X_val, y_val = df_val.iloc[:, :-1].values, df_val.iloc[:, -1].values\n",
    "    X_test, y_test = df_test.iloc[:, :-1].values, df_test.iloc[:, -1].values\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)  # assuming labels are integers\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "    \n",
    "    # Create TensorDatasets\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # adjust batch_size as needed\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)     # shuffle can be False for validation\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)   # shuffle can be False for testing\n",
    "\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96012dd3-fb45-4284-9961-2ae11e976b18",
   "metadata": {},
   "source": [
    "### Set base directory for embedding file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2896cae5-27b1-426e-b456-1970aad7b38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../embeddings/homo-sapiens/embedding-csv/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08baabe7-3f9b-48f6-a40c-2492e22c47fb",
   "metadata": {},
   "source": [
    "### NT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fda7e49-fa89-4972-98ce-63c6b19e60c7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.4462, Val Loss: 1.2357, Val Accuracy: 50.49%\n",
      "Epoch [2/20], Loss: 1.2391, Val Loss: 1.2013, Val Accuracy: 52.72%\n",
      "Epoch [3/20], Loss: 1.2154, Val Loss: 1.2107, Val Accuracy: 50.93%\n",
      "Epoch [4/20], Loss: 1.1837, Val Loss: 1.1546, Val Accuracy: 53.92%\n",
      "Epoch [5/20], Loss: 1.1630, Val Loss: 1.1781, Val Accuracy: 52.53%\n",
      "Epoch [6/20], Loss: 1.1508, Val Loss: 1.1624, Val Accuracy: 53.55%\n",
      "Epoch [7/20], Loss: 1.1313, Val Loss: 1.1193, Val Accuracy: 55.79%\n",
      "Epoch [8/20], Loss: 1.1177, Val Loss: 1.1226, Val Accuracy: 55.75%\n",
      "Epoch [9/20], Loss: 1.1125, Val Loss: 1.0936, Val Accuracy: 56.38%\n",
      "Epoch [10/20], Loss: 1.1005, Val Loss: 1.1146, Val Accuracy: 55.99%\n",
      "Epoch [11/20], Loss: 1.0991, Val Loss: 1.1117, Val Accuracy: 55.35%\n",
      "Epoch [12/20], Loss: 1.1000, Val Loss: 1.1874, Val Accuracy: 50.22%\n",
      "Epoch [13/20], Loss: 1.1255, Val Loss: 1.1887, Val Accuracy: 52.39%\n",
      "Epoch [14/20], Loss: 1.1103, Val Loss: 1.1102, Val Accuracy: 54.44%\n",
      "Epoch [15/20], Loss: 1.0960, Val Loss: 1.1182, Val Accuracy: 55.26%\n",
      "Epoch [16/20], Loss: 1.0859, Val Loss: 1.1445, Val Accuracy: 53.85%\n",
      "Epoch [17/20], Loss: 1.0845, Val Loss: 1.1059, Val Accuracy: 55.62%\n",
      "Epoch [18/20], Loss: 1.0667, Val Loss: 1.1495, Val Accuracy: 53.88%\n",
      "Epoch [19/20], Loss: 1.0592, Val Loss: 1.1489, Val Accuracy: 54.46%\n",
      "Epoch [20/20], Loss: 1.0665, Val Loss: 1.1834, Val Accuracy: 53.75%\n",
      "Training completed.\n",
      "Accuracy on test data: 53.97%\n",
      "Accuracy of class 0: 51.50%\n",
      "Accuracy of class 1: 42.50%\n",
      "Accuracy of class 2: 39.44%\n",
      "Accuracy of class 3: 57.96%\n",
      "Accuracy of class 4: 39.48%\n",
      "Accuracy of class 5: 59.40%\n",
      "Accuracy of class 6: 88.70%\n",
      "AUC of class 0: 0.89\n",
      "AUC of class 1: 0.85\n",
      "AUC of class 2: 0.89\n",
      "AUC of class 3: 0.86\n",
      "AUC of class 4: 0.83\n",
      "AUC of class 5: 0.89\n",
      "AUC of class 6: 0.99\n",
      "20874\n",
      "6958\n",
      "6959\n",
      "    class0  class1    class2   class3   class4  class5    class6\n",
      "0  0.51503   0.425  0.394394  0.57958  0.39479   0.594  0.887047\n",
      "\n",
      "\n",
      "     class0    class1    class2    class3    class4    class5    class6\n",
      "0  0.893644  0.852118  0.886082  0.860642  0.831137  0.887213  0.990483\n"
     ]
    }
   ],
   "source": [
    "def to_dataloader(X, y, batch_size=32, shuffle=True):\n",
    "    # Convert NumPy arrays to PyTorch tensors\n",
    "    X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y.values, dtype=torch.long)\n",
    "    \n",
    "    # Create TensorDataset\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    \n",
    "    # Create DataLoader\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    return loader\n",
    "    \n",
    "\n",
    "def load_embedding_file_NT(csv_filename):\n",
    "\n",
    "    df=pd.read_csv(csv_filename)\n",
    "    \n",
    "    column_names = [f'{i}' for i in range(0, df.shape[1]-2)]\n",
    "    column_names.extend(['ROWID',  'y']) \n",
    "    df.columns = column_names\n",
    "    \n",
    "    # Split the dataframe into features (X) and labels (y)\n",
    "    features = df.iloc[:, :-1]  \n",
    "    labels = df.iloc[:, -1]     \n",
    "    \n",
    "    # Initialize Stratified Shuffle Split\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=None)\n",
    "    \n",
    "    for train_index, test_index in split.split(features, labels):\n",
    "        # Use pandas indexing to split data\n",
    "        X_train_val, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "        y_train_val, y_test = labels.iloc[train_index], labels.iloc[test_index]\n",
    "    \n",
    "    # Now split the training set into training and validation sets\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=None)\n",
    "    \n",
    "    for train_index, val_index in split.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val.iloc[train_index], X_train_val.iloc[val_index]\n",
    "        y_train, y_val = y_train_val.iloc[train_index], y_train_val.iloc[val_index]    \n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "    # return df\n",
    "\n",
    "\n",
    "\n",
    "def One_Run_NT(input_size, df_acc_nt, df_auc_nt):\n",
    "    \n",
    "    X_train_df, X_val_df, X_test_df, y_train, y_val, y_test =  load_embedding_file_NT(base_dir + 'homo_sapiens_nt_embedding.csv') \n",
    "    \n",
    "    dropcolumnns=['ROWID'] \n",
    "    X_train = X_train_df.drop(dropcolumnns, axis=1)\n",
    "    X_val   = X_val_df.drop(dropcolumnns, axis=1)\n",
    "    X_test  = X_test_df.drop(dropcolumnns, axis=1)\n",
    "    \n",
    "    train_loader = to_dataloader(X_train, y_train)\n",
    "    val_loader = to_dataloader(X_val, y_val)\n",
    "    test_loader = to_dataloader(X_test, y_test)\n",
    "    \n",
    "    model = TwoLayerMLP(input_size, hidden_size1,hidden_size2,  num_classes).to(device)    \n",
    "\n",
    "    df_acc_nt, df_auc_nt = run_test(1,model, train_loader,val_loader, test_loader, df_acc_nt, df_auc_nt)\n",
    "    return df_acc_nt, df_auc_nt, X_train_df, X_val_df, X_test_df\n",
    "    \n",
    "\n",
    "df_acc_nt, df_auc_nt, X_train_df, X_val_df, X_test_df = One_Run_NT(1280, df_acc_nt, df_auc_nt)\n",
    "\n",
    "print(len(X_train_df))\n",
    "print(len(X_val_df))\n",
    "print(len(X_test_df))\n",
    "\n",
    "print(df_acc_nt)\n",
    "print('\\n')\n",
    "print(df_auc_nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "210d86a4-20af-4987-98b4-a5bbd51ce926",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df=pd.read_csv(base_dir + 'homo_sapiens_nt_embedding.csv')\n",
    "# column_names = [f'{i}' for i in range(1, df.shape[1]-1)]\n",
    "# column_names.extend(['ROWID', 'y'])\n",
    "# df.columns = column_names\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efffb61c-494c-44a2-95a2-3d34d3fcbca2",
   "metadata": {},
   "source": [
    "##  load embedding file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bcc1394-5aba-4c0a-866d-05b9aee1ff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding_file(csv_filename, X_train_df,X_val_df,X_test_df):\n",
    "\n",
    "    df=pd.read_csv(csv_filename)\n",
    "    \n",
    "    column_names = [f'{i}' for i in range(0, df.shape[1]-2)]\n",
    "    column_names.extend(['ROWID', 'y'])\n",
    "    df.columns = column_names\n",
    "                   \n",
    "    df_train= filter(df, X_train_df)\n",
    "    df_val  = filter(df, X_val_df)\n",
    "    df_test = filter(df, X_test_df)\n",
    "\n",
    "    dropcolumns=['ROWID']\n",
    "    df_train= df_train.drop(dropcolumns, axis=1) \n",
    "    df_val  = df_val.drop(dropcolumns, axis=1) \n",
    "    df_test = df_test.drop(dropcolumns, axis=1) \n",
    "\n",
    "    return df2dataloader(df_train, df_val, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250f5491",
   "metadata": {},
   "source": [
    "### GPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32d93792-5aa4-4ab8-872a-0c5d0bd377f0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.1378, Val Loss: 1.0099, Val Accuracy: 60.69%\n",
      "Epoch [2/20], Loss: 1.0054, Val Loss: 0.9805, Val Accuracy: 61.63%\n",
      "Epoch [3/20], Loss: 0.9716, Val Loss: 0.9608, Val Accuracy: 62.86%\n",
      "Epoch [4/20], Loss: 0.9415, Val Loss: 0.9948, Val Accuracy: 62.40%\n",
      "Epoch [5/20], Loss: 0.9270, Val Loss: 0.9557, Val Accuracy: 63.15%\n",
      "Epoch [6/20], Loss: 0.9079, Val Loss: 0.9308, Val Accuracy: 63.70%\n",
      "Epoch [7/20], Loss: 0.8907, Val Loss: 1.0121, Val Accuracy: 61.87%\n",
      "Epoch [8/20], Loss: 0.8739, Val Loss: 0.9046, Val Accuracy: 64.79%\n",
      "Epoch [9/20], Loss: 0.8574, Val Loss: 0.9068, Val Accuracy: 64.89%\n",
      "Epoch [10/20], Loss: 0.8490, Val Loss: 0.9314, Val Accuracy: 64.72%\n",
      "Epoch [11/20], Loss: 0.8396, Val Loss: 0.8944, Val Accuracy: 64.65%\n",
      "Epoch [12/20], Loss: 0.8283, Val Loss: 0.9436, Val Accuracy: 63.24%\n",
      "Epoch [13/20], Loss: 0.8141, Val Loss: 0.9037, Val Accuracy: 64.99%\n",
      "Epoch [14/20], Loss: 0.8082, Val Loss: 0.8870, Val Accuracy: 65.78%\n",
      "Epoch [15/20], Loss: 0.8034, Val Loss: 0.9031, Val Accuracy: 65.46%\n",
      "Epoch [16/20], Loss: 0.7857, Val Loss: 0.9117, Val Accuracy: 66.08%\n",
      "Epoch [17/20], Loss: 0.7819, Val Loss: 0.9083, Val Accuracy: 65.51%\n",
      "Epoch [18/20], Loss: 0.7694, Val Loss: 0.8913, Val Accuracy: 66.15%\n",
      "Epoch [19/20], Loss: 0.7627, Val Loss: 0.8822, Val Accuracy: 66.25%\n",
      "Epoch [20/20], Loss: 0.7550, Val Loss: 0.9749, Val Accuracy: 63.15%\n",
      "Training completed.\n",
      "Accuracy on test data: 63.86%\n",
      "Accuracy of class 0: 79.86%\n",
      "Accuracy of class 1: 60.10%\n",
      "Accuracy of class 2: 60.36%\n",
      "Accuracy of class 3: 45.25%\n",
      "Accuracy of class 4: 69.74%\n",
      "Accuracy of class 5: 91.30%\n",
      "Accuracy of class 6: 39.59%\n",
      "AUC of class 0: 0.96\n",
      "AUC of class 1: 0.89\n",
      "AUC of class 2: 0.93\n",
      "AUC of class 3: 0.90\n",
      "AUC of class 4: 0.87\n",
      "AUC of class 5: 0.99\n",
      "AUC of class 6: 0.95\n",
      "     class0  class1    class2    class3    class4  class5    class6\n",
      "0  0.798597   0.601  0.603604  0.452452  0.697395   0.913  0.395855\n",
      "\n",
      "\n",
      "     class0    class1   class2    class3    class4    class5    class6\n",
      "0  0.960639  0.889591  0.92604  0.897399  0.869567  0.986147  0.952121\n"
     ]
    }
   ],
   "source": [
    "def One_Run_GPN(input_size, df_acc, df_auc):\n",
    "\n",
    "    train_loader, val_loader, test_loader=load_embedding_file(base_dir + 'homo_sapiens_gpn_embedding.csv', X_train_df,X_val_df,X_test_df)   \n",
    "    model = TwoLayerMLP(input_size, hidden_size1,hidden_size2,  num_classes).to(device)    \n",
    "    df_acc, df_auc = run_test(1,model, train_loader,val_loader, test_loader, df_acc, df_auc)\n",
    "    return df_acc, df_auc\n",
    "\n",
    "# input_size = 768\n",
    "df_acc_gpn, df_auc_gpn = One_Run_GPN(768, df_acc_gpn, df_auc_gpn)\n",
    "\n",
    "print(df_acc_gpn)\n",
    "print('\\n')\n",
    "print(df_auc_gpn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7058c258-f55c-4621-9214-2da150828219",
   "metadata": {},
   "source": [
    "### DNABERT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bceb7b19-62f3-4b5b-8432-37049dfba26d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.2090, Val Loss: 1.0510, Val Accuracy: 59.21%\n",
      "Epoch [2/20], Loss: 0.9806, Val Loss: 1.0205, Val Accuracy: 60.76%\n",
      "Epoch [3/20], Loss: 0.9102, Val Loss: 0.9602, Val Accuracy: 62.75%\n",
      "Epoch [4/20], Loss: 0.8530, Val Loss: 0.9375, Val Accuracy: 63.62%\n",
      "Epoch [5/20], Loss: 0.8037, Val Loss: 0.9534, Val Accuracy: 63.28%\n",
      "Epoch [6/20], Loss: 0.7613, Val Loss: 0.9646, Val Accuracy: 63.44%\n",
      "Epoch [7/20], Loss: 0.7216, Val Loss: 0.9783, Val Accuracy: 62.85%\n",
      "Epoch [8/20], Loss: 0.6758, Val Loss: 1.0260, Val Accuracy: 62.59%\n",
      "Epoch [9/20], Loss: 0.6343, Val Loss: 1.0014, Val Accuracy: 63.48%\n",
      "Epoch [10/20], Loss: 0.5901, Val Loss: 1.0058, Val Accuracy: 63.75%\n",
      "Epoch [11/20], Loss: 0.5422, Val Loss: 1.0738, Val Accuracy: 62.81%\n",
      "Epoch [12/20], Loss: 0.4990, Val Loss: 1.1036, Val Accuracy: 62.88%\n",
      "Epoch [13/20], Loss: 0.4610, Val Loss: 1.1443, Val Accuracy: 62.20%\n",
      "Epoch [14/20], Loss: 0.4200, Val Loss: 1.2495, Val Accuracy: 62.09%\n",
      "Epoch [15/20], Loss: 0.3855, Val Loss: 1.2745, Val Accuracy: 62.30%\n",
      "Epoch [16/20], Loss: 0.3530, Val Loss: 1.3824, Val Accuracy: 62.01%\n",
      "Epoch [17/20], Loss: 0.3192, Val Loss: 1.4508, Val Accuracy: 60.82%\n",
      "Epoch [18/20], Loss: 0.2914, Val Loss: 1.5285, Val Accuracy: 61.27%\n",
      "Epoch [19/20], Loss: 0.2660, Val Loss: 1.6328, Val Accuracy: 59.90%\n",
      "Epoch [20/20], Loss: 0.2394, Val Loss: 1.6740, Val Accuracy: 60.87%\n",
      "Training completed.\n",
      "Accuracy on test data: 61.24%\n",
      "Accuracy of class 0: 73.55%\n",
      "Accuracy of class 1: 50.30%\n",
      "Accuracy of class 2: 53.25%\n",
      "Accuracy of class 3: 57.06%\n",
      "Accuracy of class 4: 58.22%\n",
      "Accuracy of class 5: 62.60%\n",
      "Accuracy of class 6: 74.20%\n",
      "AUC of class 0: 0.96\n",
      "AUC of class 1: 0.88\n",
      "AUC of class 2: 0.88\n",
      "AUC of class 3: 0.87\n",
      "AUC of class 4: 0.90\n",
      "AUC of class 5: 0.92\n",
      "AUC of class 6: 0.98\n",
      "     class0  class1    class2    class3    class4  class5    class6\n",
      "0  0.735471   0.503  0.532533  0.570571  0.582164   0.626  0.741969\n",
      "\n",
      "\n",
      "    class0    class1    class2    class3    class4    class5    class6\n",
      "0  0.95912  0.878146  0.880663  0.871233  0.897145  0.919936  0.976689\n"
     ]
    }
   ],
   "source": [
    "def One_Run_DNABERT2(input_size, df_acc, df_auc):\n",
    "\n",
    "    train_loader, val_loader, test_loader=load_embedding_file(base_dir + 'homo_sapiens_dnabert2_embedding.csv', X_train_df,X_val_df,X_test_df)    \n",
    "    model = TwoLayerMLP(input_size, hidden_size1,hidden_size2,  num_classes).to(device)    \n",
    "    df_acc, df_auc = run_test(1,model, train_loader,val_loader, test_loader, df_acc, df_auc)\n",
    "    return df_acc, df_auc\n",
    "\n",
    "# input_size = 768\n",
    "df_acc_dnabert2, df_auc_dnabert2 = One_Run_DNABERT2(768, df_acc_dnabert2, df_auc_dnabert2)\n",
    "\n",
    "print(df_acc_dnabert2)\n",
    "print('\\n')\n",
    "print(df_auc_dnabert2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46c637ac-7920-47ba-a520-7ef3ccbf2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv(base_dir + 'homo_sapiens_dnabert2_embedding.csv')\n",
    "# column_names = [f'{i}' for i in range(1, df.shape[1]-1)]\n",
    "# column_names.extend(['ROWID', 'y'])\n",
    "# df.columns = column_names\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25928e08-41d6-4a21-8fb0-9babc1b71fe6",
   "metadata": {},
   "source": [
    "### HyenaDNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f44484b0-9a25-4826-8ed1-a3f80b8a91ea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.6007, Val Loss: 1.5001, Val Accuracy: 38.29%\n",
      "Epoch [2/20], Loss: 1.4561, Val Loss: 1.4261, Val Accuracy: 41.59%\n",
      "Epoch [3/20], Loss: 1.4210, Val Loss: 1.4113, Val Accuracy: 41.78%\n",
      "Epoch [4/20], Loss: 1.4099, Val Loss: 1.4811, Val Accuracy: 42.34%\n",
      "Epoch [5/20], Loss: 1.3920, Val Loss: 1.3831, Val Accuracy: 42.87%\n",
      "Epoch [6/20], Loss: 1.3795, Val Loss: 1.3776, Val Accuracy: 44.44%\n",
      "Epoch [7/20], Loss: 1.3684, Val Loss: 1.3576, Val Accuracy: 45.50%\n",
      "Epoch [8/20], Loss: 1.3610, Val Loss: 1.4098, Val Accuracy: 41.25%\n",
      "Epoch [9/20], Loss: 1.3569, Val Loss: 1.4045, Val Accuracy: 43.89%\n",
      "Epoch [10/20], Loss: 1.3517, Val Loss: 1.3730, Val Accuracy: 44.51%\n",
      "Epoch [11/20], Loss: 1.3471, Val Loss: 1.3779, Val Accuracy: 46.48%\n",
      "Epoch [12/20], Loss: 1.3390, Val Loss: 1.3226, Val Accuracy: 47.25%\n",
      "Epoch [13/20], Loss: 1.3325, Val Loss: 1.3821, Val Accuracy: 44.22%\n",
      "Epoch [14/20], Loss: 1.3261, Val Loss: 1.3975, Val Accuracy: 43.88%\n",
      "Epoch [15/20], Loss: 1.3206, Val Loss: 1.3357, Val Accuracy: 47.59%\n",
      "Epoch [16/20], Loss: 1.3159, Val Loss: 1.3337, Val Accuracy: 47.07%\n",
      "Epoch [17/20], Loss: 1.3099, Val Loss: 1.3029, Val Accuracy: 47.80%\n",
      "Epoch [18/20], Loss: 1.3056, Val Loss: 1.3182, Val Accuracy: 46.59%\n",
      "Epoch [19/20], Loss: 1.3001, Val Loss: 1.2936, Val Accuracy: 47.20%\n",
      "Epoch [20/20], Loss: 1.3026, Val Loss: 1.3039, Val Accuracy: 47.38%\n",
      "Training completed.\n",
      "Accuracy on test data: 48.21%\n",
      "Accuracy of class 0: 38.98%\n",
      "Accuracy of class 1: 32.00%\n",
      "Accuracy of class 2: 39.24%\n",
      "Accuracy of class 3: 47.85%\n",
      "Accuracy of class 4: 36.27%\n",
      "Accuracy of class 5: 65.50%\n",
      "Accuracy of class 6: 78.65%\n",
      "AUC of class 0: 0.81\n",
      "AUC of class 1: 0.84\n",
      "AUC of class 2: 0.84\n",
      "AUC of class 3: 0.82\n",
      "AUC of class 4: 0.82\n",
      "AUC of class 5: 0.84\n",
      "AUC of class 6: 0.97\n",
      "    class0  class1    class2    class3    class4  class5    class6\n",
      "0  0.38978    0.32  0.392392  0.478478  0.362725   0.655  0.786528\n",
      "\n",
      "\n",
      "     class0    class1    class2    class3    class4    class5   class6\n",
      "0  0.806289  0.843351  0.835406  0.817242  0.818679  0.837104  0.96677\n"
     ]
    }
   ],
   "source": [
    "def One_Run_HYENADNA(input_size, df_acc, df_auc):\n",
    "\n",
    "    train_loader, val_loader, test_loader=load_embedding_file(base_dir + 'homo_sapiens_hyena_embedding.csv', X_train_df,X_val_df,X_test_df)    \n",
    "    model = TwoLayerMLP(input_size, hidden_size1,hidden_size2,  num_classes).to(device)    \n",
    "    df_acc, df_auc = run_test(1,model,train_loader,val_loader, test_loader, df_acc, df_auc)\n",
    "    return df_acc, df_auc\n",
    "\n",
    "# input_size = 256\n",
    "df_acc_hyena, df_auc_hyena = One_Run_HYENADNA(256, df_acc_hyena, df_auc_hyena)\n",
    "\n",
    "print(df_acc_hyena)\n",
    "print('\\n')\n",
    "print(df_auc_hyena)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f739e9-2ff0-46c2-8382-9c58f867dbb8",
   "metadata": {},
   "source": [
    "### Caduceus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41f1662d-a31e-41aa-ba8f-b6ca639be31c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# csv_filename= base_dir + 'homo_sapiens_caduceus_embedding.csv'\n",
    "# df=pd.read_csv(csv_filename)\n",
    "# # df = df.drop(['chromosome','ref_forward_sequence','alt_forward_sequence','position','ROWID'], axis=1) \n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adab5dfc-68e2-40d9-a671-7624e6520d79",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.7426, Val Loss: 1.6742, Val Accuracy: 29.45%\n",
      "Epoch [2/20], Loss: 1.6222, Val Loss: 1.5983, Val Accuracy: 34.05%\n",
      "Epoch [3/20], Loss: 1.5109, Val Loss: 1.4504, Val Accuracy: 40.51%\n",
      "Epoch [4/20], Loss: 1.4289, Val Loss: 1.4328, Val Accuracy: 40.70%\n",
      "Epoch [5/20], Loss: 1.3816, Val Loss: 1.3534, Val Accuracy: 45.01%\n",
      "Epoch [6/20], Loss: 1.3475, Val Loss: 1.3354, Val Accuracy: 44.68%\n",
      "Epoch [7/20], Loss: 1.3233, Val Loss: 1.3068, Val Accuracy: 46.71%\n",
      "Epoch [8/20], Loss: 1.3084, Val Loss: 1.2859, Val Accuracy: 47.01%\n",
      "Epoch [9/20], Loss: 1.2884, Val Loss: 1.2987, Val Accuracy: 48.68%\n",
      "Epoch [10/20], Loss: 1.2715, Val Loss: 1.2550, Val Accuracy: 49.80%\n",
      "Epoch [11/20], Loss: 1.2580, Val Loss: 1.2486, Val Accuracy: 47.83%\n",
      "Epoch [12/20], Loss: 1.2415, Val Loss: 1.2299, Val Accuracy: 48.97%\n",
      "Epoch [13/20], Loss: 1.2299, Val Loss: 1.2154, Val Accuracy: 50.29%\n",
      "Epoch [14/20], Loss: 1.2137, Val Loss: 1.2587, Val Accuracy: 47.64%\n",
      "Epoch [15/20], Loss: 1.2028, Val Loss: 1.1927, Val Accuracy: 51.08%\n",
      "Epoch [16/20], Loss: 1.1893, Val Loss: 1.1749, Val Accuracy: 51.60%\n",
      "Epoch [17/20], Loss: 1.1780, Val Loss: 1.1700, Val Accuracy: 52.43%\n",
      "Epoch [18/20], Loss: 1.1650, Val Loss: 1.1774, Val Accuracy: 54.15%\n",
      "Epoch [19/20], Loss: 1.1533, Val Loss: 1.1461, Val Accuracy: 54.04%\n",
      "Epoch [20/20], Loss: 1.1453, Val Loss: 1.1386, Val Accuracy: 53.48%\n",
      "Training completed.\n",
      "Accuracy on test data: 53.87%\n",
      "Accuracy of class 0: 70.04%\n",
      "Accuracy of class 1: 36.70%\n",
      "Accuracy of class 2: 43.84%\n",
      "Accuracy of class 3: 29.53%\n",
      "Accuracy of class 4: 36.57%\n",
      "Accuracy of class 5: 67.30%\n",
      "Accuracy of class 6: 94.51%\n",
      "AUC of class 0: 0.88\n",
      "AUC of class 1: 0.86\n",
      "AUC of class 2: 0.87\n",
      "AUC of class 3: 0.85\n",
      "AUC of class 4: 0.88\n",
      "AUC of class 5: 0.87\n",
      "AUC of class 6: 0.99\n",
      "     class0  class1    class2    class3    class4  class5    class6\n",
      "0  0.700401   0.367  0.438438  0.295295  0.365731   0.673  0.945078\n",
      "\n",
      "\n",
      "     class0  class1    class2    class3   class4    class5    class6\n",
      "0  0.876011  0.8615  0.870111  0.846925  0.87878  0.872086  0.994999\n"
     ]
    }
   ],
   "source": [
    "def One_Run_CADUCEUS(input_size, df_acc, df_auc):\n",
    "\n",
    "    train_loader, val_loader, test_loader=load_embedding_file(base_dir + 'homo_sapiens_caduceus_embedding.csv', X_train_df,X_val_df,X_test_df)    \n",
    "    model = TwoLayerMLP(input_size, hidden_size1,hidden_size2,  num_classes).to(device)    \n",
    "    df_acc, df_auc = run_test(1,model,train_loader,val_loader, test_loader, df_acc, df_auc)\n",
    "    return df_acc, df_auc\n",
    "\n",
    "# input_size = 256\n",
    "df_acc_caduceus, df_auc_caduceus = One_Run_CADUCEUS(256, df_acc_caduceus, df_auc_caduceus)\n",
    "\n",
    "print(df_acc_caduceus)\n",
    "print('\\n')\n",
    "print(df_auc_caduceus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf31557-f402-45ce-9966-13b956164de0",
   "metadata": {},
   "source": [
    "## Perfrom T-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42864f49-3032-4bbe-bea3-7c37abcdfa0b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====round 1======\n",
      "Epoch [1/20], Loss: 1.4256, Val Loss: 1.2223, Val Accuracy: 50.49%\n",
      "Epoch [2/20], Loss: 1.2453, Val Loss: 1.2194, Val Accuracy: 50.10%\n",
      "Epoch [3/20], Loss: 1.2040, Val Loss: 1.1815, Val Accuracy: 51.34%\n",
      "Epoch [4/20], Loss: 1.1770, Val Loss: 1.2492, Val Accuracy: 51.71%\n",
      "Epoch [5/20], Loss: 1.1574, Val Loss: 1.1821, Val Accuracy: 52.39%\n",
      "Epoch [6/20], Loss: 1.1387, Val Loss: 1.2277, Val Accuracy: 52.66%\n",
      "Epoch [7/20], Loss: 1.1502, Val Loss: 1.2057, Val Accuracy: 51.42%\n",
      "Epoch [8/20], Loss: 1.1211, Val Loss: 1.1914, Val Accuracy: 52.10%\n",
      "Epoch [9/20], Loss: 1.1100, Val Loss: 1.1673, Val Accuracy: 51.60%\n",
      "Epoch [10/20], Loss: 1.1048, Val Loss: 1.1431, Val Accuracy: 54.56%\n",
      "Epoch [11/20], Loss: 1.0940, Val Loss: 1.1345, Val Accuracy: 54.10%\n",
      "Epoch [12/20], Loss: 1.0850, Val Loss: 1.1387, Val Accuracy: 54.14%\n",
      "Epoch [13/20], Loss: 1.0810, Val Loss: 1.1717, Val Accuracy: 52.69%\n",
      "Epoch [14/20], Loss: 1.0740, Val Loss: 1.1142, Val Accuracy: 55.68%\n",
      "Epoch [15/20], Loss: 1.0800, Val Loss: 1.1083, Val Accuracy: 55.07%\n",
      "Epoch [16/20], Loss: 1.0707, Val Loss: 1.2553, Val Accuracy: 52.11%\n",
      "Epoch [17/20], Loss: 1.0677, Val Loss: 1.1308, Val Accuracy: 55.38%\n",
      "Epoch [18/20], Loss: 1.0570, Val Loss: 1.1392, Val Accuracy: 53.58%\n",
      "Epoch [19/20], Loss: 1.0518, Val Loss: 1.1656, Val Accuracy: 53.08%\n",
      "Epoch [20/20], Loss: 1.0412, Val Loss: 1.1361, Val Accuracy: 55.07%\n",
      "Training completed.\n",
      "Accuracy on test data: 55.17%\n",
      "Accuracy of class 0: 68.34%\n",
      "Accuracy of class 1: 25.30%\n",
      "Accuracy of class 2: 57.86%\n",
      "Accuracy of class 3: 56.96%\n",
      "Accuracy of class 4: 24.65%\n",
      "Accuracy of class 5: 68.00%\n",
      "Accuracy of class 6: 86.11%\n",
      "AUC of class 0: 0.90\n",
      "AUC of class 1: 0.86\n",
      "AUC of class 2: 0.88\n",
      "AUC of class 3: 0.86\n",
      "AUC of class 4: 0.86\n",
      "AUC of class 5: 0.89\n",
      "AUC of class 6: 0.99\n",
      "Epoch [1/20], Loss: 1.1274, Val Loss: 1.0634, Val Accuracy: 57.66%\n",
      "Epoch [2/20], Loss: 1.0012, Val Loss: 1.0148, Val Accuracy: 61.45%\n",
      "Epoch [3/20], Loss: 0.9598, Val Loss: 1.0018, Val Accuracy: 61.68%\n",
      "Epoch [4/20], Loss: 0.9324, Val Loss: 0.9543, Val Accuracy: 63.84%\n",
      "Epoch [5/20], Loss: 0.9136, Val Loss: 0.9493, Val Accuracy: 63.50%\n",
      "Epoch [6/20], Loss: 0.8971, Val Loss: 0.9378, Val Accuracy: 63.97%\n",
      "Epoch [7/20], Loss: 0.8832, Val Loss: 0.9346, Val Accuracy: 63.87%\n",
      "Epoch [8/20], Loss: 0.8599, Val Loss: 0.9374, Val Accuracy: 64.65%\n",
      "Epoch [9/20], Loss: 0.8574, Val Loss: 0.9435, Val Accuracy: 64.73%\n",
      "Epoch [10/20], Loss: 0.8395, Val Loss: 0.9302, Val Accuracy: 64.43%\n",
      "Epoch [11/20], Loss: 0.8328, Val Loss: 0.9145, Val Accuracy: 64.72%\n",
      "Epoch [12/20], Loss: 0.8198, Val Loss: 0.9101, Val Accuracy: 65.25%\n",
      "Epoch [13/20], Loss: 0.8085, Val Loss: 0.9337, Val Accuracy: 64.08%\n",
      "Epoch [14/20], Loss: 0.8011, Val Loss: 0.9177, Val Accuracy: 64.89%\n",
      "Epoch [15/20], Loss: 0.7915, Val Loss: 0.9327, Val Accuracy: 64.89%\n",
      "Epoch [16/20], Loss: 0.7811, Val Loss: 0.9258, Val Accuracy: 65.06%\n",
      "Epoch [17/20], Loss: 0.7692, Val Loss: 0.9136, Val Accuracy: 65.59%\n",
      "Epoch [18/20], Loss: 0.7665, Val Loss: 0.9281, Val Accuracy: 64.47%\n",
      "Epoch [19/20], Loss: 0.7559, Val Loss: 0.9174, Val Accuracy: 65.56%\n",
      "Epoch [20/20], Loss: 0.7485, Val Loss: 0.9498, Val Accuracy: 64.72%\n",
      "Training completed.\n",
      "Accuracy on test data: 66.40%\n",
      "Accuracy of class 0: 81.86%\n",
      "Accuracy of class 1: 62.20%\n",
      "Accuracy of class 2: 83.38%\n",
      "Accuracy of class 3: 29.33%\n",
      "Accuracy of class 4: 45.89%\n",
      "Accuracy of class 5: 89.10%\n",
      "Accuracy of class 6: 73.26%\n",
      "AUC of class 0: 0.96\n",
      "AUC of class 1: 0.89\n",
      "AUC of class 2: 0.94\n",
      "AUC of class 3: 0.89\n",
      "AUC of class 4: 0.88\n",
      "AUC of class 5: 0.99\n",
      "AUC of class 6: 0.95\n",
      "Epoch [1/20], Loss: 1.1876, Val Loss: 1.0476, Val Accuracy: 59.82%\n",
      "Epoch [2/20], Loss: 0.9745, Val Loss: 0.9990, Val Accuracy: 62.06%\n",
      "Epoch [3/20], Loss: 0.8991, Val Loss: 0.9766, Val Accuracy: 62.45%\n",
      "Epoch [4/20], Loss: 0.8469, Val Loss: 0.9901, Val Accuracy: 62.53%\n",
      "Epoch [5/20], Loss: 0.7962, Val Loss: 0.9622, Val Accuracy: 63.58%\n",
      "Epoch [6/20], Loss: 0.7530, Val Loss: 0.9912, Val Accuracy: 62.29%\n",
      "Epoch [7/20], Loss: 0.7095, Val Loss: 0.9681, Val Accuracy: 63.24%\n",
      "Epoch [8/20], Loss: 0.6659, Val Loss: 1.0036, Val Accuracy: 63.25%\n",
      "Epoch [9/20], Loss: 0.6271, Val Loss: 0.9982, Val Accuracy: 63.25%\n",
      "Epoch [10/20], Loss: 0.5820, Val Loss: 1.0584, Val Accuracy: 62.43%\n",
      "Epoch [11/20], Loss: 0.5392, Val Loss: 1.0859, Val Accuracy: 62.35%\n",
      "Epoch [12/20], Loss: 0.4974, Val Loss: 1.1609, Val Accuracy: 62.72%\n",
      "Epoch [13/20], Loss: 0.4614, Val Loss: 1.1853, Val Accuracy: 62.14%\n",
      "Epoch [14/20], Loss: 0.4201, Val Loss: 1.2587, Val Accuracy: 61.34%\n",
      "Epoch [15/20], Loss: 0.3919, Val Loss: 1.3496, Val Accuracy: 60.87%\n",
      "Epoch [16/20], Loss: 0.3546, Val Loss: 1.4191, Val Accuracy: 60.55%\n",
      "Epoch [17/20], Loss: 0.3248, Val Loss: 1.4800, Val Accuracy: 60.97%\n",
      "Epoch [18/20], Loss: 0.2975, Val Loss: 1.6600, Val Accuracy: 59.57%\n",
      "Epoch [19/20], Loss: 0.2714, Val Loss: 1.6168, Val Accuracy: 61.30%\n",
      "Epoch [20/20], Loss: 0.2511, Val Loss: 1.7677, Val Accuracy: 60.55%\n",
      "Training completed.\n",
      "Accuracy on test data: 61.57%\n",
      "Accuracy of class 0: 76.25%\n",
      "Accuracy of class 1: 55.20%\n",
      "Accuracy of class 2: 47.35%\n",
      "Accuracy of class 3: 50.35%\n",
      "Accuracy of class 4: 57.11%\n",
      "Accuracy of class 5: 69.60%\n",
      "Accuracy of class 6: 75.65%\n",
      "AUC of class 0: 0.95\n",
      "AUC of class 1: 0.89\n",
      "AUC of class 2: 0.88\n",
      "AUC of class 3: 0.88\n",
      "AUC of class 4: 0.89\n",
      "AUC of class 5: 0.92\n",
      "AUC of class 6: 0.98\n",
      "Epoch [1/20], Loss: 1.5958, Val Loss: 1.5190, Val Accuracy: 37.24%\n",
      "Epoch [2/20], Loss: 1.4511, Val Loss: 1.4632, Val Accuracy: 40.67%\n",
      "Epoch [3/20], Loss: 1.4242, Val Loss: 1.4193, Val Accuracy: 41.89%\n",
      "Epoch [4/20], Loss: 1.4080, Val Loss: 1.4431, Val Accuracy: 42.15%\n",
      "Epoch [5/20], Loss: 1.3990, Val Loss: 1.3991, Val Accuracy: 42.89%\n",
      "Epoch [6/20], Loss: 1.3881, Val Loss: 1.4045, Val Accuracy: 43.50%\n",
      "Epoch [7/20], Loss: 1.3745, Val Loss: 1.3824, Val Accuracy: 44.21%\n",
      "Epoch [8/20], Loss: 1.3616, Val Loss: 1.3799, Val Accuracy: 43.72%\n",
      "Epoch [9/20], Loss: 1.3560, Val Loss: 1.3921, Val Accuracy: 43.33%\n",
      "Epoch [10/20], Loss: 1.3528, Val Loss: 1.4911, Val Accuracy: 40.44%\n",
      "Epoch [11/20], Loss: 1.3393, Val Loss: 1.3726, Val Accuracy: 44.47%\n",
      "Epoch [12/20], Loss: 1.3346, Val Loss: 1.3832, Val Accuracy: 43.98%\n",
      "Epoch [13/20], Loss: 1.3265, Val Loss: 1.3793, Val Accuracy: 44.41%\n",
      "Epoch [14/20], Loss: 1.3300, Val Loss: 1.3732, Val Accuracy: 44.71%\n",
      "Epoch [15/20], Loss: 1.3202, Val Loss: 1.3550, Val Accuracy: 44.91%\n",
      "Epoch [16/20], Loss: 1.3161, Val Loss: 1.3424, Val Accuracy: 46.46%\n",
      "Epoch [17/20], Loss: 1.3136, Val Loss: 1.3376, Val Accuracy: 47.17%\n",
      "Epoch [18/20], Loss: 1.3115, Val Loss: 1.3560, Val Accuracy: 45.39%\n",
      "Epoch [19/20], Loss: 1.3020, Val Loss: 1.4290, Val Accuracy: 42.79%\n",
      "Epoch [20/20], Loss: 1.3005, Val Loss: 1.3647, Val Accuracy: 44.32%\n",
      "Training completed.\n",
      "Accuracy on test data: 46.49%\n",
      "Accuracy of class 0: 17.33%\n",
      "Accuracy of class 1: 11.50%\n",
      "Accuracy of class 2: 72.47%\n",
      "Accuracy of class 3: 65.47%\n",
      "Accuracy of class 4: 30.86%\n",
      "Accuracy of class 5: 48.60%\n",
      "Accuracy of class 6: 80.31%\n",
      "AUC of class 0: 0.81\n",
      "AUC of class 1: 0.83\n",
      "AUC of class 2: 0.84\n",
      "AUC of class 3: 0.82\n",
      "AUC of class 4: 0.83\n",
      "AUC of class 5: 0.84\n",
      "AUC of class 6: 0.97\n",
      "Epoch [1/20], Loss: 1.7353, Val Loss: 1.6872, Val Accuracy: 30.27%\n",
      "Epoch [2/20], Loss: 1.6277, Val Loss: 1.5778, Val Accuracy: 38.40%\n",
      "Epoch [3/20], Loss: 1.5220, Val Loss: 1.4638, Val Accuracy: 42.56%\n",
      "Epoch [4/20], Loss: 1.4246, Val Loss: 1.4052, Val Accuracy: 43.17%\n",
      "Epoch [5/20], Loss: 1.3677, Val Loss: 1.3663, Val Accuracy: 44.93%\n",
      "Epoch [6/20], Loss: 1.3332, Val Loss: 1.3284, Val Accuracy: 46.48%\n",
      "Epoch [7/20], Loss: 1.3090, Val Loss: 1.3136, Val Accuracy: 47.47%\n",
      "Epoch [8/20], Loss: 1.2930, Val Loss: 1.2906, Val Accuracy: 46.77%\n",
      "Epoch [9/20], Loss: 1.2772, Val Loss: 1.2770, Val Accuracy: 49.32%\n",
      "Epoch [10/20], Loss: 1.2644, Val Loss: 1.2852, Val Accuracy: 46.81%\n",
      "Epoch [11/20], Loss: 1.2496, Val Loss: 1.2519, Val Accuracy: 49.15%\n",
      "Epoch [12/20], Loss: 1.2346, Val Loss: 1.2445, Val Accuracy: 49.87%\n",
      "Epoch [13/20], Loss: 1.2167, Val Loss: 1.2429, Val Accuracy: 50.65%\n",
      "Epoch [14/20], Loss: 1.2016, Val Loss: 1.2161, Val Accuracy: 50.72%\n",
      "Epoch [15/20], Loss: 1.1821, Val Loss: 1.1977, Val Accuracy: 53.58%\n",
      "Epoch [16/20], Loss: 1.1640, Val Loss: 1.2185, Val Accuracy: 52.03%\n",
      "Epoch [17/20], Loss: 1.1456, Val Loss: 1.1489, Val Accuracy: 54.41%\n",
      "Epoch [18/20], Loss: 1.1323, Val Loss: 1.1399, Val Accuracy: 54.70%\n",
      "Epoch [19/20], Loss: 1.1195, Val Loss: 1.1288, Val Accuracy: 54.21%\n",
      "Epoch [20/20], Loss: 1.1059, Val Loss: 1.1138, Val Accuracy: 56.25%\n",
      "Training completed.\n",
      "Accuracy on test data: 55.47%\n",
      "Accuracy of class 0: 57.11%\n",
      "Accuracy of class 1: 38.10%\n",
      "Accuracy of class 2: 52.15%\n",
      "Accuracy of class 3: 38.54%\n",
      "Accuracy of class 4: 59.82%\n",
      "Accuracy of class 5: 51.50%\n",
      "Accuracy of class 6: 92.33%\n",
      "AUC of class 0: 0.88\n",
      "AUC of class 1: 0.85\n",
      "AUC of class 2: 0.87\n",
      "AUC of class 3: 0.85\n",
      "AUC of class 4: 0.89\n",
      "AUC of class 5: 0.88\n",
      "AUC of class 6: 0.99\n",
      "====round 2======\n",
      "Epoch [1/20], Loss: 1.4198, Val Loss: 1.2461, Val Accuracy: 48.86%\n",
      "Epoch [2/20], Loss: 1.2455, Val Loss: 1.2009, Val Accuracy: 51.24%\n",
      "Epoch [3/20], Loss: 1.1938, Val Loss: 1.2105, Val Accuracy: 51.06%\n",
      "Epoch [4/20], Loss: 1.1798, Val Loss: 1.2255, Val Accuracy: 50.42%\n",
      "Epoch [5/20], Loss: 1.1543, Val Loss: 1.1425, Val Accuracy: 53.05%\n",
      "Epoch [6/20], Loss: 1.1425, Val Loss: 1.1621, Val Accuracy: 51.70%\n",
      "Epoch [7/20], Loss: 1.1345, Val Loss: 1.1389, Val Accuracy: 53.33%\n",
      "Epoch [8/20], Loss: 1.1208, Val Loss: 1.1303, Val Accuracy: 54.50%\n",
      "Epoch [9/20], Loss: 1.1063, Val Loss: 1.2988, Val Accuracy: 49.99%\n",
      "Epoch [10/20], Loss: 1.0999, Val Loss: 1.1864, Val Accuracy: 51.72%\n",
      "Epoch [11/20], Loss: 1.1033, Val Loss: 1.0966, Val Accuracy: 55.33%\n",
      "Epoch [12/20], Loss: 1.0921, Val Loss: 1.1459, Val Accuracy: 53.74%\n",
      "Epoch [13/20], Loss: 1.0820, Val Loss: 1.2055, Val Accuracy: 51.29%\n",
      "Epoch [14/20], Loss: 1.0796, Val Loss: 1.0963, Val Accuracy: 54.97%\n",
      "Epoch [15/20], Loss: 1.0709, Val Loss: 1.0892, Val Accuracy: 55.76%\n",
      "Epoch [16/20], Loss: 1.0737, Val Loss: 1.1211, Val Accuracy: 54.87%\n",
      "Epoch [17/20], Loss: 1.0658, Val Loss: 1.1037, Val Accuracy: 54.54%\n",
      "Epoch [18/20], Loss: 1.0510, Val Loss: 1.0877, Val Accuracy: 56.02%\n",
      "Epoch [19/20], Loss: 1.0533, Val Loss: 1.1170, Val Accuracy: 55.06%\n",
      "Epoch [20/20], Loss: 1.0493, Val Loss: 1.1834, Val Accuracy: 52.92%\n",
      "Training completed.\n",
      "Accuracy on test data: 52.42%\n",
      "Accuracy of class 0: 52.20%\n",
      "Accuracy of class 1: 75.50%\n",
      "Accuracy of class 2: 54.25%\n",
      "Accuracy of class 3: 9.11%\n",
      "Accuracy of class 4: 24.05%\n",
      "Accuracy of class 5: 73.90%\n",
      "Accuracy of class 6: 78.76%\n",
      "AUC of class 0: 0.89\n",
      "AUC of class 1: 0.86\n",
      "AUC of class 2: 0.88\n",
      "AUC of class 3: 0.85\n",
      "AUC of class 4: 0.83\n",
      "AUC of class 5: 0.88\n",
      "AUC of class 6: 0.98\n",
      "Epoch [1/20], Loss: 1.1285, Val Loss: 1.0101, Val Accuracy: 60.18%\n",
      "Epoch [2/20], Loss: 0.9967, Val Loss: 0.9578, Val Accuracy: 62.55%\n",
      "Epoch [3/20], Loss: 0.9609, Val Loss: 0.9504, Val Accuracy: 63.05%\n",
      "Epoch [4/20], Loss: 0.9369, Val Loss: 0.9295, Val Accuracy: 64.46%\n",
      "Epoch [5/20], Loss: 0.9158, Val Loss: 0.9184, Val Accuracy: 63.96%\n",
      "Epoch [6/20], Loss: 0.9028, Val Loss: 0.9376, Val Accuracy: 62.42%\n",
      "Epoch [7/20], Loss: 0.8849, Val Loss: 0.9091, Val Accuracy: 64.67%\n",
      "Epoch [8/20], Loss: 0.8713, Val Loss: 0.9304, Val Accuracy: 64.47%\n",
      "Epoch [9/20], Loss: 0.8610, Val Loss: 0.9219, Val Accuracy: 63.52%\n",
      "Epoch [10/20], Loss: 0.8520, Val Loss: 0.8809, Val Accuracy: 65.94%\n",
      "Epoch [11/20], Loss: 0.8389, Val Loss: 0.9537, Val Accuracy: 64.06%\n",
      "Epoch [12/20], Loss: 0.8303, Val Loss: 0.8847, Val Accuracy: 65.92%\n",
      "Epoch [13/20], Loss: 0.8164, Val Loss: 0.9012, Val Accuracy: 64.37%\n",
      "Epoch [14/20], Loss: 0.8119, Val Loss: 0.8862, Val Accuracy: 65.42%\n",
      "Epoch [15/20], Loss: 0.7994, Val Loss: 0.8942, Val Accuracy: 66.40%\n",
      "Epoch [16/20], Loss: 0.7917, Val Loss: 0.8878, Val Accuracy: 66.25%\n",
      "Epoch [17/20], Loss: 0.7838, Val Loss: 0.8976, Val Accuracy: 66.08%\n",
      "Epoch [18/20], Loss: 0.7723, Val Loss: 0.8770, Val Accuracy: 67.16%\n",
      "Epoch [19/20], Loss: 0.7675, Val Loss: 0.8740, Val Accuracy: 66.90%\n",
      "Epoch [20/20], Loss: 0.7569, Val Loss: 0.8852, Val Accuracy: 65.68%\n",
      "Training completed.\n",
      "Accuracy on test data: 66.09%\n",
      "Accuracy of class 0: 81.16%\n",
      "Accuracy of class 1: 48.00%\n",
      "Accuracy of class 2: 60.96%\n",
      "Accuracy of class 3: 51.15%\n",
      "Accuracy of class 4: 58.72%\n",
      "Accuracy of class 5: 86.80%\n",
      "Accuracy of class 6: 76.17%\n",
      "AUC of class 0: 0.97\n",
      "AUC of class 1: 0.88\n",
      "AUC of class 2: 0.93\n",
      "AUC of class 3: 0.89\n",
      "AUC of class 4: 0.88\n",
      "AUC of class 5: 0.98\n",
      "AUC of class 6: 0.95\n",
      "Epoch [1/20], Loss: 1.2082, Val Loss: 1.0254, Val Accuracy: 60.42%\n",
      "Epoch [2/20], Loss: 0.9821, Val Loss: 0.9674, Val Accuracy: 62.66%\n",
      "Epoch [3/20], Loss: 0.9142, Val Loss: 0.9762, Val Accuracy: 62.43%\n",
      "Epoch [4/20], Loss: 0.8578, Val Loss: 0.9099, Val Accuracy: 64.89%\n",
      "Epoch [5/20], Loss: 0.8106, Val Loss: 0.9358, Val Accuracy: 63.90%\n",
      "Epoch [6/20], Loss: 0.7652, Val Loss: 0.9149, Val Accuracy: 65.02%\n",
      "Epoch [7/20], Loss: 0.7246, Val Loss: 0.9392, Val Accuracy: 63.77%\n",
      "Epoch [8/20], Loss: 0.6840, Val Loss: 0.9295, Val Accuracy: 64.72%\n",
      "Epoch [9/20], Loss: 0.6389, Val Loss: 0.9548, Val Accuracy: 64.56%\n",
      "Epoch [10/20], Loss: 0.5973, Val Loss: 0.9930, Val Accuracy: 63.14%\n",
      "Epoch [11/20], Loss: 0.5592, Val Loss: 0.9918, Val Accuracy: 63.50%\n",
      "Epoch [12/20], Loss: 0.5171, Val Loss: 1.0406, Val Accuracy: 63.71%\n",
      "Epoch [13/20], Loss: 0.4822, Val Loss: 1.1019, Val Accuracy: 62.81%\n",
      "Epoch [14/20], Loss: 0.4440, Val Loss: 1.1180, Val Accuracy: 63.04%\n",
      "Epoch [15/20], Loss: 0.4062, Val Loss: 1.2754, Val Accuracy: 63.01%\n",
      "Epoch [16/20], Loss: 0.3772, Val Loss: 1.2460, Val Accuracy: 62.89%\n",
      "Epoch [17/20], Loss: 0.3415, Val Loss: 1.3525, Val Accuracy: 62.78%\n",
      "Epoch [18/20], Loss: 0.3151, Val Loss: 1.4211, Val Accuracy: 61.54%\n",
      "Epoch [19/20], Loss: 0.2889, Val Loss: 1.4455, Val Accuracy: 61.89%\n",
      "Epoch [20/20], Loss: 0.2705, Val Loss: 1.5669, Val Accuracy: 61.41%\n",
      "Training completed.\n",
      "Accuracy on test data: 60.41%\n",
      "Accuracy of class 0: 75.05%\n",
      "Accuracy of class 1: 47.50%\n",
      "Accuracy of class 2: 42.84%\n",
      "Accuracy of class 3: 64.36%\n",
      "Accuracy of class 4: 56.61%\n",
      "Accuracy of class 5: 63.00%\n",
      "Accuracy of class 6: 73.99%\n",
      "AUC of class 0: 0.96\n",
      "AUC of class 1: 0.88\n",
      "AUC of class 2: 0.87\n",
      "AUC of class 3: 0.88\n",
      "AUC of class 4: 0.89\n",
      "AUC of class 5: 0.92\n",
      "AUC of class 6: 0.97\n",
      "Epoch [1/20], Loss: 1.6043, Val Loss: 1.4779, Val Accuracy: 42.54%\n",
      "Epoch [2/20], Loss: 1.4647, Val Loss: 1.4186, Val Accuracy: 41.84%\n",
      "Epoch [3/20], Loss: 1.4331, Val Loss: 1.4213, Val Accuracy: 41.94%\n",
      "Epoch [4/20], Loss: 1.4189, Val Loss: 1.4322, Val Accuracy: 42.50%\n",
      "Epoch [5/20], Loss: 1.4072, Val Loss: 1.3997, Val Accuracy: 43.95%\n",
      "Epoch [6/20], Loss: 1.3936, Val Loss: 1.3583, Val Accuracy: 44.94%\n",
      "Epoch [7/20], Loss: 1.3877, Val Loss: 1.3478, Val Accuracy: 46.00%\n",
      "Epoch [8/20], Loss: 1.3768, Val Loss: 1.3799, Val Accuracy: 43.25%\n",
      "Epoch [9/20], Loss: 1.3707, Val Loss: 1.3322, Val Accuracy: 46.38%\n",
      "Epoch [10/20], Loss: 1.3557, Val Loss: 1.3395, Val Accuracy: 46.51%\n",
      "Epoch [11/20], Loss: 1.3546, Val Loss: 1.3504, Val Accuracy: 46.11%\n",
      "Epoch [12/20], Loss: 1.3473, Val Loss: 1.3188, Val Accuracy: 46.82%\n",
      "Epoch [13/20], Loss: 1.3380, Val Loss: 1.3104, Val Accuracy: 47.64%\n",
      "Epoch [14/20], Loss: 1.3343, Val Loss: 1.3053, Val Accuracy: 47.90%\n",
      "Epoch [15/20], Loss: 1.3267, Val Loss: 1.2979, Val Accuracy: 47.86%\n",
      "Epoch [16/20], Loss: 1.3239, Val Loss: 1.2855, Val Accuracy: 47.89%\n",
      "Epoch [17/20], Loss: 1.3202, Val Loss: 1.2877, Val Accuracy: 48.05%\n",
      "Epoch [18/20], Loss: 1.3144, Val Loss: 1.3442, Val Accuracy: 46.32%\n",
      "Epoch [19/20], Loss: 1.3152, Val Loss: 1.2925, Val Accuracy: 47.56%\n",
      "Epoch [20/20], Loss: 1.3065, Val Loss: 1.2749, Val Accuracy: 48.92%\n",
      "Training completed.\n",
      "Accuracy on test data: 48.00%\n",
      "Accuracy of class 0: 39.68%\n",
      "Accuracy of class 1: 41.60%\n",
      "Accuracy of class 2: 50.25%\n",
      "Accuracy of class 3: 32.73%\n",
      "Accuracy of class 4: 25.85%\n",
      "Accuracy of class 5: 68.10%\n",
      "Accuracy of class 6: 78.76%\n",
      "AUC of class 0: 0.81\n",
      "AUC of class 1: 0.83\n",
      "AUC of class 2: 0.84\n",
      "AUC of class 3: 0.83\n",
      "AUC of class 4: 0.82\n",
      "AUC of class 5: 0.83\n",
      "AUC of class 6: 0.97\n",
      "Epoch [1/20], Loss: 1.7463, Val Loss: 1.6816, Val Accuracy: 28.63%\n",
      "Epoch [2/20], Loss: 1.6414, Val Loss: 1.5728, Val Accuracy: 36.85%\n",
      "Epoch [3/20], Loss: 1.5264, Val Loss: 1.4653, Val Accuracy: 40.66%\n",
      "Epoch [4/20], Loss: 1.4491, Val Loss: 1.4158, Val Accuracy: 42.61%\n",
      "Epoch [5/20], Loss: 1.4100, Val Loss: 1.3777, Val Accuracy: 42.94%\n",
      "Epoch [6/20], Loss: 1.3756, Val Loss: 1.3455, Val Accuracy: 43.96%\n",
      "Epoch [7/20], Loss: 1.3468, Val Loss: 1.3432, Val Accuracy: 44.57%\n",
      "Epoch [8/20], Loss: 1.3250, Val Loss: 1.3303, Val Accuracy: 45.40%\n",
      "Epoch [9/20], Loss: 1.3060, Val Loss: 1.2898, Val Accuracy: 47.50%\n",
      "Epoch [10/20], Loss: 1.2901, Val Loss: 1.2884, Val Accuracy: 45.99%\n",
      "Epoch [11/20], Loss: 1.2767, Val Loss: 1.2592, Val Accuracy: 48.59%\n",
      "Epoch [12/20], Loss: 1.2594, Val Loss: 1.2382, Val Accuracy: 50.00%\n",
      "Epoch [13/20], Loss: 1.2437, Val Loss: 1.2267, Val Accuracy: 49.50%\n",
      "Epoch [14/20], Loss: 1.2257, Val Loss: 1.2203, Val Accuracy: 49.31%\n",
      "Epoch [15/20], Loss: 1.2119, Val Loss: 1.1958, Val Accuracy: 52.47%\n",
      "Epoch [16/20], Loss: 1.1965, Val Loss: 1.1806, Val Accuracy: 52.37%\n",
      "Epoch [17/20], Loss: 1.1839, Val Loss: 1.1675, Val Accuracy: 51.97%\n",
      "Epoch [18/20], Loss: 1.1658, Val Loss: 1.1655, Val Accuracy: 51.87%\n",
      "Epoch [19/20], Loss: 1.1581, Val Loss: 1.1423, Val Accuracy: 53.87%\n",
      "Epoch [20/20], Loss: 1.1463, Val Loss: 1.1338, Val Accuracy: 53.16%\n",
      "Training completed.\n",
      "Accuracy on test data: 53.14%\n",
      "Accuracy of class 0: 66.33%\n",
      "Accuracy of class 1: 41.60%\n",
      "Accuracy of class 2: 49.35%\n",
      "Accuracy of class 3: 35.54%\n",
      "Accuracy of class 4: 33.57%\n",
      "Accuracy of class 5: 51.30%\n",
      "Accuracy of class 6: 95.75%\n",
      "AUC of class 0: 0.88\n",
      "AUC of class 1: 0.85\n",
      "AUC of class 2: 0.86\n",
      "AUC of class 3: 0.86\n",
      "AUC of class 4: 0.87\n",
      "AUC of class 5: 0.87\n",
      "AUC of class 6: 0.99\n",
      "====Print Accuracy======\n",
      "     class0  class1    class2    class3    class4  class5    class6\n",
      "0  0.683367   0.253  0.578579  0.569570  0.246493   0.680  0.861140\n",
      "1  0.522044   0.755  0.542543  0.091091  0.240481   0.739  0.787565\n",
      "\n",
      "\n",
      "     class0  class1    class2    class3    class4  class5    class6\n",
      "0  0.818637   0.622  0.833834  0.293293  0.458918   0.891  0.732642\n",
      "1  0.811623   0.480  0.609610  0.511512  0.587174   0.868  0.761658\n",
      "\n",
      "\n",
      "     class0  class1    class2    class3    class4  class5    class6\n",
      "0  0.762525   0.552  0.473473  0.503504  0.571142   0.696  0.756477\n",
      "1  0.750501   0.475  0.428428  0.643644  0.566132   0.630  0.739896\n",
      "\n",
      "\n",
      "     class0  class1    class2    class3    class4  class5    class6\n",
      "0  0.173347   0.115  0.724725  0.654655  0.308617   0.486  0.803109\n",
      "1  0.396794   0.416  0.502503  0.327327  0.258517   0.681  0.787565\n",
      "\n",
      "\n",
      "     class0  class1    class2    class3    class4  class5    class6\n",
      "0  0.571142   0.381  0.521522  0.385385  0.598196   0.515  0.923316\n",
      "1  0.663327   0.416  0.493493  0.355355  0.335671   0.513  0.957513\n",
      "====Print AUC======\n",
      "     class0    class1    class2    class3    class4    class5    class6\n",
      "0  0.903700  0.855453  0.883538  0.860071  0.858585  0.891535  0.988955\n",
      "1  0.888489  0.856810  0.882933  0.847804  0.825030  0.883945  0.982118\n",
      "\n",
      "\n",
      "     class0    class1    class2    class3    class4    class5    class6\n",
      "0  0.962838  0.890529  0.935653  0.886755  0.884557  0.986180  0.952715\n",
      "1  0.965568  0.882325  0.933957  0.890945  0.876902  0.984851  0.949267\n",
      "\n",
      "\n",
      "     class0    class1    class2    class3    class4    class5    class6\n",
      "0  0.950385  0.888555  0.877011  0.875635  0.889564  0.916227  0.975929\n",
      "1  0.956465  0.883430  0.873783  0.876334  0.888636  0.916144  0.969692\n",
      "\n",
      "\n",
      "     class0    class1    class2    class3    class4    class5    class6\n",
      "0  0.812720  0.830559  0.839954  0.817528  0.828616  0.843557  0.971965\n",
      "1  0.813811  0.830800  0.840253  0.831088  0.824507  0.834321  0.965726\n",
      "\n",
      "\n",
      "     class0    class1    class2    class3    class4    class5    class6\n",
      "0  0.881369  0.853952  0.868257  0.849562  0.894529  0.884412  0.993017\n",
      "1  0.879841  0.852626  0.861749  0.858273  0.865409  0.868237  0.993537\n",
      "CPU times: user 4min 45s, sys: 2.48 s, total: 4min 48s\n",
      "Wall time: 6min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def clear_df(df):\n",
    "    df=df.drop(df.index)\n",
    "    return df\n",
    "\n",
    "df_acc_nt      =clear_df(df_acc_nt)\n",
    "df_acc_gpn     =clear_df(df_acc_gpn)\n",
    "df_acc_dnabert2=clear_df(df_acc_dnabert2)\n",
    "df_acc_hyena   =clear_df(df_acc_hyena)\n",
    "df_acc_caduceus=clear_df(df_acc_caduceus)\n",
    "\n",
    "df_auc_nt      =clear_df(df_auc_nt)\n",
    "df_auc_gpn     =clear_df(df_auc_gpn)\n",
    "df_auc_dnabert2=clear_df(df_auc_dnabert2)\n",
    "df_auc_hyena   =clear_df(df_auc_hyena)\n",
    "df_auc_caduceus=clear_df(df_auc_caduceus)\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    print(\"====round \"+str(i+1)+\"======\")\n",
    "    \n",
    "    df_acc_nt, df_auc_nt, X_train_df, X_val_df, X_test_df = One_Run_NT(1280, df_acc_nt, df_auc_nt)\n",
    "\n",
    "    df_acc_gpn, df_auc_gpn = One_Run_GPN(768, df_acc_gpn, df_auc_gpn)\n",
    "\n",
    "    df_acc_dnabert2, df_auc_dnabert2 = One_Run_DNABERT2(768, df_acc_dnabert2, df_auc_dnabert2)\n",
    "\n",
    "    df_acc_hyena, df_auc_hyena = One_Run_HYENADNA(256, df_acc_hyena, df_auc_hyena)\n",
    "    \n",
    "    df_acc_caduceus, df_auc_caduceus = One_Run_CADUCEUS(256, df_acc_caduceus, df_auc_caduceus)\n",
    "\n",
    "\n",
    "print(\"====Print Accuracy======\")\n",
    "print(df_acc_nt)\n",
    "print('\\n')\n",
    "print(df_acc_gpn)\n",
    "print('\\n')\n",
    "print(df_acc_dnabert2)\n",
    "print('\\n')\n",
    "print(df_acc_hyena)\n",
    "print('\\n')\n",
    "print(df_acc_caduceus)\n",
    "\n",
    "print(\"====Print AUC======\")\n",
    "print(df_auc_nt)\n",
    "print('\\n')\n",
    "print(df_auc_gpn)\n",
    "print('\\n')\n",
    "print(df_auc_dnabert2)\n",
    "print('\\n')\n",
    "print(df_auc_hyena)\n",
    "print('\\n')\n",
    "print(df_auc_caduceus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "806407c5-0532-43e0-ae20-23b23b3e7d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_nt.to_csv('t_acc_nt.csv', index=False)\n",
    "df_acc_gpn.to_csv('t_acc_gpn.csv', index=False)\n",
    "df_acc_dnabert2.to_csv('t_acc_dnabert2.csv', index=False)\n",
    "df_acc_hyena.to_csv('t_acc_hyena.csv', index=False)\n",
    "df_acc_caduceus.to_csv('t_acc_caduceus.csv', index=False)\n",
    "\n",
    "df_auc_nt.to_csv('t_auc_nt.csv', index=False)\n",
    "df_auc_gpn.to_csv('t_auc_gpn.csv', index=False)\n",
    "df_auc_dnabert2.to_csv('t_auc_dnabert2.csv', index=False)\n",
    "df_auc_hyena.to_csv('t_auc_hyena.csv', index=False)\n",
    "df_auc_caduceus.to_csv('t_auc_caduceus.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76605d35-593d-4562-913a-9362cdda3774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class0</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "      <th>class5</th>\n",
       "      <th>class6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.841624</td>\n",
       "      <td>0.446339</td>\n",
       "      <td>0.765594</td>\n",
       "      <td>0.508577</td>\n",
       "      <td>0.611055</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.790863</td>\n",
       "      <td>0.351053</td>\n",
       "      <td>0.685111</td>\n",
       "      <td>0.686176</td>\n",
       "      <td>0.705528</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.601351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.847561</td>\n",
       "      <td>0.406219</td>\n",
       "      <td>0.597586</td>\n",
       "      <td>0.562059</td>\n",
       "      <td>0.639196</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.841892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.841624</td>\n",
       "      <td>0.558676</td>\n",
       "      <td>0.771630</td>\n",
       "      <td>0.426842</td>\n",
       "      <td>0.556784</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.824324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.821320</td>\n",
       "      <td>0.341023</td>\n",
       "      <td>0.629779</td>\n",
       "      <td>0.650858</td>\n",
       "      <td>0.744724</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.644595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.845685</td>\n",
       "      <td>0.408225</td>\n",
       "      <td>0.708249</td>\n",
       "      <td>0.577195</td>\n",
       "      <td>0.554774</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.809459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.861929</td>\n",
       "      <td>0.567703</td>\n",
       "      <td>0.584507</td>\n",
       "      <td>0.350151</td>\n",
       "      <td>0.774874</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.458108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.797970</td>\n",
       "      <td>0.473420</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.520686</td>\n",
       "      <td>0.604020</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.701351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.784772</td>\n",
       "      <td>0.343029</td>\n",
       "      <td>0.724346</td>\n",
       "      <td>0.650858</td>\n",
       "      <td>0.658291</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.737838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.808122</td>\n",
       "      <td>0.448345</td>\n",
       "      <td>0.724346</td>\n",
       "      <td>0.553986</td>\n",
       "      <td>0.665327</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.737838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class0    class1    class2    class3    class4  class5    class6\n",
       "0   0.841624  0.446339  0.765594  0.508577  0.611055   0.879  0.756757\n",
       "1   0.790863  0.351053  0.685111  0.686176  0.705528   0.882  0.601351\n",
       "2   0.847561  0.406219  0.597586  0.562059  0.639196   0.883  0.841892\n",
       "3   0.841624  0.558676  0.771630  0.426842  0.556784   0.907  0.824324\n",
       "4   0.821320  0.341023  0.629779  0.650858  0.744724   0.912  0.644595\n",
       "..       ...       ...       ...       ...       ...     ...       ...\n",
       "95  0.845685  0.408225  0.708249  0.577195  0.554774   0.897  0.809459\n",
       "96  0.861929  0.567703  0.584507  0.350151  0.774874   0.922  0.458108\n",
       "97  0.797970  0.473420  0.774648  0.520686  0.604020   0.856  0.701351\n",
       "98  0.784772  0.343029  0.724346  0.650858  0.658291   0.879  0.737838\n",
       "99  0.808122  0.448345  0.724346  0.553986  0.665327   0.870  0.737838\n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acc_gpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de5986c6-709b-4623-b91a-b9b65e676a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class0</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "      <th>class5</th>\n",
       "      <th>class6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.553299</td>\n",
       "      <td>0.492477</td>\n",
       "      <td>0.533199</td>\n",
       "      <td>0.373360</td>\n",
       "      <td>0.596985</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.979730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.597970</td>\n",
       "      <td>0.545637</td>\n",
       "      <td>0.449698</td>\n",
       "      <td>0.174571</td>\n",
       "      <td>0.413065</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.991892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.540102</td>\n",
       "      <td>0.484453</td>\n",
       "      <td>0.399396</td>\n",
       "      <td>0.372351</td>\n",
       "      <td>0.655276</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.987838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.596954</td>\n",
       "      <td>0.538616</td>\n",
       "      <td>0.501006</td>\n",
       "      <td>0.204844</td>\n",
       "      <td>0.449246</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.985135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.643655</td>\n",
       "      <td>0.480441</td>\n",
       "      <td>0.476861</td>\n",
       "      <td>0.187689</td>\n",
       "      <td>0.507538</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.975676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.557360</td>\n",
       "      <td>0.462387</td>\n",
       "      <td>0.462777</td>\n",
       "      <td>0.322906</td>\n",
       "      <td>0.617085</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.941892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.644670</td>\n",
       "      <td>0.436309</td>\n",
       "      <td>0.407445</td>\n",
       "      <td>0.256307</td>\n",
       "      <td>0.476382</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.985135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.635533</td>\n",
       "      <td>0.480441</td>\n",
       "      <td>0.498994</td>\n",
       "      <td>0.308779</td>\n",
       "      <td>0.454271</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.983784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.619289</td>\n",
       "      <td>0.509529</td>\n",
       "      <td>0.576459</td>\n",
       "      <td>0.258325</td>\n",
       "      <td>0.567839</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.971622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.529949</td>\n",
       "      <td>0.534604</td>\n",
       "      <td>0.435614</td>\n",
       "      <td>0.393542</td>\n",
       "      <td>0.481407</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.970270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class0    class1    class2    class3    class4  class5    class6\n",
       "0   0.553299  0.492477  0.533199  0.373360  0.596985   0.499  0.979730\n",
       "1   0.597970  0.545637  0.449698  0.174571  0.413065   0.653  0.991892\n",
       "2   0.540102  0.484453  0.399396  0.372351  0.655276   0.585  0.987838\n",
       "3   0.596954  0.538616  0.501006  0.204844  0.449246   0.675  0.985135\n",
       "4   0.643655  0.480441  0.476861  0.187689  0.507538   0.715  0.975676\n",
       "..       ...       ...       ...       ...       ...     ...       ...\n",
       "95  0.557360  0.462387  0.462777  0.322906  0.617085   0.601  0.941892\n",
       "96  0.644670  0.436309  0.407445  0.256307  0.476382   0.722  0.985135\n",
       "97  0.635533  0.480441  0.498994  0.308779  0.454271   0.589  0.983784\n",
       "98  0.619289  0.509529  0.576459  0.258325  0.567839   0.481  0.971622\n",
       "99  0.529949  0.534604  0.435614  0.393542  0.481407   0.654  0.970270\n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acc_caduceus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f80db092-5c5a-490c-a931-d57b37b3f092",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class0 p-value\n",
      "       nt  gpn dnabert2 hyena caduceus\n",
      "0     1.0  NaN      NaN   NaN      NaN\n",
      "1     0.0  1.0      NaN   NaN      NaN\n",
      "2     0.0  0.0      1.0   NaN      NaN\n",
      "3     0.0  0.0      0.0   1.0      NaN\n",
      "4  0.9243  0.0      0.0   0.0      1.0\n",
      "\n",
      "\n",
      "class1 p-value\n",
      "       nt     gpn dnabert2 hyena caduceus\n",
      "0     1.0     NaN      NaN   NaN      NaN\n",
      "1  0.0093     1.0      NaN   NaN      NaN\n",
      "2     0.0     0.0      1.0   NaN      NaN\n",
      "3  0.4548  0.0394      0.0   1.0      NaN\n",
      "4     0.0  0.0002   0.0007   0.0      1.0\n",
      "\n",
      "\n",
      "class2 p-value\n",
      "       nt  gpn dnabert2 hyena caduceus\n",
      "0     1.0  NaN      NaN   NaN      NaN\n",
      "1     0.0  1.0      NaN   NaN      NaN\n",
      "2     0.0  0.0      1.0   NaN      NaN\n",
      "3  0.0009  0.0   0.0801   1.0      NaN\n",
      "4     0.0  0.0      0.0   0.0      1.0\n",
      "\n",
      "\n",
      "class3 p-value\n",
      "    nt     gpn dnabert2   hyena caduceus\n",
      "0  1.0     NaN      NaN     NaN      NaN\n",
      "1  0.0     1.0      NaN     NaN      NaN\n",
      "2  0.0  0.0161      1.0     NaN      NaN\n",
      "3  0.0     0.0      0.0     1.0      NaN\n",
      "4  0.0     0.0      0.0  0.5658      1.0\n",
      "\n",
      "\n",
      "class4 p-value\n",
      "    nt     gpn dnabert2 hyena caduceus\n",
      "0  1.0     NaN      NaN   NaN      NaN\n",
      "1  0.0     1.0      NaN   NaN      NaN\n",
      "2  0.0  0.2689      1.0   NaN      NaN\n",
      "3  0.0     0.0      0.0   1.0      NaN\n",
      "4  0.0     0.0      0.0   0.0      1.0\n",
      "\n",
      "\n",
      "class5 p-value\n",
      "       nt  gpn dnabert2   hyena caduceus\n",
      "0     1.0  NaN      NaN     NaN      NaN\n",
      "1     0.0  1.0      NaN     NaN      NaN\n",
      "2  0.0957  0.0      1.0     NaN      NaN\n",
      "3  0.0069  0.0      0.0     1.0      NaN\n",
      "4  0.8746  0.0   0.0287  0.0007      1.0\n",
      "\n",
      "\n",
      "class6 p-value\n",
      "       nt  gpn dnabert2   hyena caduceus\n",
      "0     1.0  NaN      NaN     NaN      NaN\n",
      "1     0.0  1.0      NaN     NaN      NaN\n",
      "2     0.0  0.0      1.0     NaN      NaN\n",
      "3  0.0035  0.0      0.0     1.0      NaN\n",
      "4  0.0372  0.0      0.0  0.1105      1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir='./100-run-data'\n",
    "\n",
    "df_acc_nt=pd.read_csv(data_dir+'/t_acc_nt.csv')\n",
    "df_acc_gpn=pd.read_csv(data_dir+'/t_acc_gpn.csv')\n",
    "df_acc_dnabert2=pd.read_csv(data_dir+'/t_acc_dnabert2.csv')\n",
    "df_acc_hyena=pd.read_csv(data_dir+'/t_acc_hyena.csv')\n",
    "df_acc_caduceus=pd.read_csv(data_dir+'/t_acc_caduceus.csv')\n",
    "\n",
    "df_auc_nt=pd.read_csv(data_dir+'/t_auc_nt.csv')\n",
    "df_auc_gpn=pd.read_csv(data_dir+'/t_auc_gpn.csv')\n",
    "df_auc_dnabert2=pd.read_csv(data_dir+'/t_auc_dnabert2.csv')\n",
    "df_auc_hyena=pd.read_csv(data_dir+'/t_auc_hyena.csv')\n",
    "df_auc_caduceus=pd.read_csv(data_dir+'/t_auc_caduceus.csv')\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "df_p_value = pd.DataFrame(columns=['nt', 'gpn', 'dnabert2','hyena','caduceus'])\n",
    "\n",
    "for _ in range(5):\n",
    "    df_p_value.loc[len(df_p_value)] = [np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "\n",
    "\n",
    "for i in range(7):\n",
    "\n",
    "    classname='class'+str(i)\n",
    "    # new_df = pd.concat([df_auc_nt[classname], df_auc_gpn[classname], df_auc_dnabert2[classname], df_auc_hyena[classname], df_auc_caduceus[classname]], axis=1)\n",
    "    new_df = pd.concat([df_acc_nt[classname], df_acc_gpn[classname], df_acc_dnabert2[classname], df_acc_hyena[classname], df_acc_caduceus[classname]], axis=1)\n",
    "    new_df.columns = ['nt', 'gpn', 'dnabert2','hyena','caduceus']\n",
    "\n",
    "    df_p_value = df_p_value.drop(df_p_value.index)\n",
    "    for _ in range(5):\n",
    "        df_p_value.loc[len(df_p_value)] = [np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "\n",
    "    for j in range(5):\n",
    "        for k in range(5):\n",
    "            if j<k:\n",
    "                break \n",
    "            group1 =new_df.iloc[:, j].to_numpy()\n",
    "            group2 =new_df.iloc[:, k].to_numpy()\n",
    "            # u_stat, p_value = stats.mannwhitneyu(group1, group2)\n",
    "            t_stat, p_value = stats.ttest_ind(group1, group2)\n",
    "            df_p_value.iloc[j, k] = round(p_value, 4)  # p_value\n",
    "\n",
    "\n",
    "    print(classname + \" p-value\")\n",
    "    print(df_p_value)\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607bcf55-8e7a-4b20-9f8a-918839b31518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for two groups\n",
    "group1_scores = [88, 92, 85, 90, 79, 93, 87, 91]\n",
    "group2_scores = [78, 82, 84, 76, 80, 83, 77, 81]\n",
    "\n",
    "# Conducting an independent two-sample t-test\n",
    "t_stat, p_value = stats.ttest_ind(group1_scores, group2_scores)\n",
    "\n",
    "# Printing results\n",
    "print(\"T-statistic:\", t_stat)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05  # significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference between the groups.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant difference found between the groups.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02513768-f13e-4607-a15d-c8246f9cbe81",
   "metadata": {},
   "source": [
    "### Perform U-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5859e2ac-abed-483d-8e03-94671679c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Two independent samples\n",
    "group1 = [1.2, 1.9, 2.5, 2.7, 3.0]\n",
    "group2 = [2.8, 3.2, 3.5, 3.7, 4.0]\n",
    "\n",
    "# Perform Mann-Whitney U Test\n",
    "u_stat, p_value = stats.mannwhitneyu(group1, group2)\n",
    "\n",
    "print(f\"U-statistic: {u_stat}, p-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0090c2b-c200-4ac2-8d6c-4cd90b7a7587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_acc_nt.to_csv('acc_nt.csv', index=False)\n",
    "# df_acc_gpn.to_csv('acc_gpn.csv', index=False)\n",
    "# df_acc_dnabert2.to_csv('acc_dnabert2.csv', index=False)\n",
    "# df_acc_hyena.to_csv('acc_hyena.csv', index=False)\n",
    "# df_acc_caduceus.to_csv('acc_caduceus.csv', index=False)\n",
    "\n",
    "# df_auc_nt.to_csv('auc_nt.csv', index=False)\n",
    "# df_auc_gpn.to_csv('auc_gpn.csv', index=False)\n",
    "# df_auc_dnabert2.to_csv('auc_dnabert2.csv', index=False)\n",
    "# df_auc_hyena.to_csv('auc_hyena.csv', index=False)\n",
    "# df_auc_caduceus.to_csv('auc_caduceus.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a2501e-6ee2-4c23-ad80-d558879ed4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c88849-32f0-4c84-9f57-26c25d3dae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auc_nt=pd.read_csv('auc_nt.csv')\n",
    "df_auc_gpn=pd.read_csv('auc_gpn.csv')\n",
    "df_auc_dnabert2=pd.read_csv('auc_dnabert2.csv')\n",
    "df_auc_hyena=pd.read_csv('auc_hyena.csv')\n",
    "df_auc_caduceus=pd.read_csv('auc_caduceus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e182136-a37b-435f-bc4d-9694440eda81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31663327, 0.4488978 , 0.64228457, 0.57715431, 0.68737475,\n",
       "       0.73747495, 0.62124248, 0.7244489 , 0.78456914, 0.81663327])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acc_nt=pd.read_csv('acc_nt.csv')\n",
    "df_acc_nt['class0']\n",
    "\n",
    "array_class0  = df_acc_nt['class0'].to_numpy()\n",
    "array_class0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d04580-de55-4970-816a-96d6758c54c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c3d13ba-6aa4-48cd-8012-dcae914f9988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.0, 0.00364227850473983)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from scipy import stats\n",
    "\n",
    "group1 =df_auc_nt['class0'].to_numpy()\n",
    "group2 =df_auc_gpn['class0'].to_numpy()\n",
    "\n",
    "# Perform Mann-Whitney U Test\n",
    "u_stat, p_value = stats.mannwhitneyu(group1, group2)\n",
    "u_stat,p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b0bdf482-f7b2-46f7-8cb2-1a9b3caea2f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class0 p-value\n",
      "         nt       gpn  dnabert2     hyena  caduceus\n",
      "0  0.484868       NaN       NaN       NaN       NaN\n",
      "1  0.003642  0.484868       NaN       NaN       NaN\n",
      "2  0.000291  0.032011  0.484868       NaN       NaN\n",
      "3  0.015605  0.000091  0.000091  0.484868       NaN\n",
      "4  0.044487  0.000091  0.000091  0.012874  0.484868\n",
      "\n",
      "\n",
      "class1 p-value\n",
      "         nt       gpn  dnabert2     hyena  caduceus\n",
      "0  0.484868       NaN       NaN       NaN       NaN\n",
      "1  0.285375  0.484868       NaN       NaN       NaN\n",
      "2  0.005665  0.012874  0.484868       NaN       NaN\n",
      "3  0.015605  0.012874  0.000091  0.484868       NaN\n",
      "4  0.092938  0.052055  0.000091   0.00022  0.484868\n",
      "\n",
      "\n",
      "class2 p-value\n",
      "         nt       gpn  dnabert2     hyena  caduceus\n",
      "0  0.484868       NaN       NaN       NaN       NaN\n",
      "1  0.172352  0.484868       NaN       NaN       NaN\n",
      "2  0.015605  0.060612  0.484868       NaN       NaN\n",
      "3  0.032011  0.001101  0.000165  0.484868       NaN\n",
      "4  0.080986  0.005665  0.000853  0.004554  0.484868\n",
      "\n",
      "\n",
      "class3 p-value\n",
      "         nt       gpn  dnabert2     hyena  caduceus\n",
      "0  0.484868       NaN       NaN       NaN       NaN\n",
      "1  0.311588  0.484868       NaN       NaN       NaN\n",
      "2  0.010567  0.026951  0.484868       NaN       NaN\n",
      "3  0.008629  0.001414  0.000091  0.484868       NaN\n",
      "4  0.026951  0.010567  0.000291  0.001805  0.484868\n",
      "\n",
      "\n",
      "class4 p-value\n",
      "         nt       gpn  dnabert2     hyena  caduceus\n",
      "0  0.484868       NaN       NaN       NaN       NaN\n",
      "1  0.395668  0.484868       NaN       NaN       NaN\n",
      "2  0.002293  0.001101  0.484868       NaN       NaN\n",
      "3  0.037831  0.010567  0.000091  0.484868       NaN\n",
      "4  0.044487   0.00701  0.018818   0.00022  0.484868\n",
      "\n",
      "\n",
      "class5 p-value\n",
      "         nt       gpn  dnabert2     hyena  caduceus\n",
      "0  0.484868       NaN       NaN       NaN       NaN\n",
      "1  0.000504  0.484868       NaN       NaN       NaN\n",
      "2   0.00701  0.070233  0.484868       NaN       NaN\n",
      "3  0.008629  0.000091  0.000091  0.484868       NaN\n",
      "4  0.106147  0.000091  0.000504  0.000165  0.484868\n",
      "\n",
      "\n",
      "class6 p-value\n",
      "         nt       gpn  dnabert2     hyena  caduceus\n",
      "0  0.484868       NaN       NaN       NaN       NaN\n",
      "1  0.311588  0.484868       NaN       NaN       NaN\n",
      "2  0.000091  0.000091  0.484868       NaN       NaN\n",
      "3   0.00022   0.00022  0.000504  0.484868       NaN\n",
      "4  0.000091  0.000091  0.002293  0.000091  0.484868\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_p_value = pd.DataFrame(columns=['nt', 'gpn', 'dnabert2','hyena','caduceus'])\n",
    "\n",
    "for _ in range(5):\n",
    "    df_p_value.loc[len(df_p_value)] = [np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "\n",
    "for i in range(7):\n",
    "\n",
    "    classname='class'+str(i)\n",
    "    new_df = pd.concat([df_auc_nt[classname], df_auc_gpn[classname], df_auc_dnabert2[classname], df_auc_hyena[classname], df_auc_caduceus[classname]], axis=1)\n",
    "    new_df.columns = ['nt', 'gpn', 'dnabert2','hyena','caduceus']\n",
    "\n",
    "    df_p_value = df_p_value.drop(df_p_value.index)\n",
    "    for _ in range(5):\n",
    "        df_p_value.loc[len(df_p_value)] = [np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "\n",
    "    for j in range(5):\n",
    "        for k in range(5):\n",
    "            if j<k:\n",
    "                break \n",
    "            group1 =new_df.iloc[:, j].to_numpy()\n",
    "            group2 =new_df.iloc[:, k].to_numpy()\n",
    "            u_stat, p_value = stats.mannwhitneyu(group1, group2)\n",
    "            df_p_value.iloc[j, k] = p_value\n",
    "\n",
    "    print(classname + \" p-value\")\n",
    "    print(df_p_value)\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.7.1",
   "language": "python",
   "name": "pytorch-1.7.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
